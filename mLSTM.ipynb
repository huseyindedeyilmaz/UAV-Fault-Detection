{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topic_name(flight_name, file_name):\n",
    "    topic_name = file_name.split(flight_name)\n",
    "    topic_name =  topic_name[1].strip(\"-\") if len(topic_name)>1 else \"\"\n",
    "    topic_name = topic_name.split(\".csv\")[0]\n",
    "    return topic_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(full_path):\n",
    "    df_tmp = pd.read_csv(full_path,on_bad_lines=\"skip\")\n",
    "    df_tmp = df_tmp.rename(columns={\"%time\": \"timestamp\"})\n",
    "    \n",
    "    df_tmp[\"timestamp\"] = pd.to_datetime(df_tmp[\"timestamp\"], unit=\"ns\")\n",
    "    df_tmp.set_index(\"timestamp\", inplace=True) \n",
    "    return df_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_topic_list = [\"diagnostics\", \"emergency_responder-traj_file\",\"mavlink-from\",\"mavros-state\",\n",
    "                    \"global_position\",\n",
    "                     \"local_position\", \n",
    "                     \"mavctrl-rpy\",\n",
    "                     \"mavros-battery\", \"field_raw\",\n",
    "                     \"mavros-imu-mag\", \"mavros-mission-reached\",\n",
    "                     \"mavros-rc\",\n",
    "                      \"setpoint_raw\",\"mavros-imu-data_raw\"]\n",
    "\n",
    "unused_column_list = [\"field.header.seq\", \"field.header.stamp\", \"field.header.frame_id\", \n",
    "                      \"field.commanded\", \"field.variance\", \"%time\",\"field.x\",\"field.twist.angular.x\",\"field.twist.angular.y\",\"field.twist.angular.z\",\n",
    "                      'field.orientation_covariance0',\n",
    "       'field.orientation_covariance1',\n",
    "       'field.orientation_covariance2',\n",
    "       'field.orientation_covariance3',\n",
    "       'field.orientation_covariance4',\n",
    "       'field.orientation_covariance5',\n",
    "       'field.orientation_covariance6',\n",
    "       'field.orientation_covariance7',\n",
    "       'field.orientation_covariance8',\n",
    "\n",
    "       'field.angular_velocity_covariance0',\n",
    "       'field.angular_velocity_covariance1',\n",
    "       'field.angular_velocity_covariance2',\n",
    "       'field.angular_velocity_covariance3',\n",
    "       'field.angular_velocity_covariance4',\n",
    "       'field.angular_velocity_covariance5',\n",
    "       'field.angular_velocity_covariance6',\n",
    "       'field.angular_velocity_covariance7',\n",
    "       'field.angular_velocity_covariance8',\n",
    "\n",
    "       'field.linear_acceleration_covariance0',\n",
    "       'field.linear_acceleration_covariance1',\n",
    "       'field.linear_acceleration_covariance2',\n",
    "       'field.linear_acceleration_covariance3',\n",
    "       'field.linear_acceleration_covariance4',\n",
    "       'field.linear_acceleration_covariance5',\n",
    "       'field.linear_acceleration_covariance6',\n",
    "       'field.linear_acceleration_covariance7',\n",
    "       'field.linear_acceleration_covariance8',\n",
    "       \"field.coordinate_frame\",\"field.source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hy138\\Desktop\\UAV\n",
      "['.vscode', 'best_model.pth', 'BiLSTM.ipynb', 'BiLSTMs.ipynb', 'CNN1D.ipynb', 'CNN1Ds.ipynb', 'data', 'LSTM copy.ipynb', 'LSTM.ipynb', 'LSTMAutoEncoder.ipynb', 'LSTMs.ipynb', 'mLSTM.ipynb', 'sLSTM.ipynb', 'xLSTM.ipynb', 'Yeni klas√∂r']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}\n",
    "flight_topic_list = []\n",
    "topic_list = []\n",
    "all_columns = []\n",
    "df_dict = {}\n",
    "failure_status_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbonZ_2018-07-18-15-53-31_1_engine_failure\n",
      "carbonZ_2018-07-18-15-53-31_2_engine_failure\n",
      "carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-16-39-00_1_engine_failure\n",
      "carbonZ_2018-07-30-16-39-00_2_engine_failure\n",
      "carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj\n",
      "carbonZ_2018-09-11-11-56-30_engine_failure\n",
      "carbonZ_2018-09-11-14-22-07_1_engine_failure\n",
      "carbonZ_2018-09-11-14-22-07_2_engine_failure\n",
      "carbonZ_2018-09-11-14-41-51_elevator_failure\n",
      "carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure\n",
      "carbonZ_2018-09-11-15-05-11_1_elevator_failure\n",
      "carbonZ_2018-09-11-15-06-34_1_rudder_right_failure\n",
      "carbonZ_2018-09-11-15-06-34_2_rudder_right_failure\n",
      "carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure\n",
      "carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure\n",
      "carbonZ_2018-09-11-17-55-30_1_right_aileron_failure\n",
      "carbonZ_2018-09-11-17-55-30_2_left_aileron_failure\n",
      "carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-14-37-22_2_right_aileron_failure\n",
      "carbonZ_2018-10-05-14-37-22_3_left_aileron_failure\n",
      "carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj\n"
     ]
    }
   ],
   "source": [
    "for i,flight in enumerate(glob.glob(data_path+\"*\")):\n",
    "    \n",
    "    flight_name = os.path.basename(flight)\n",
    "    \n",
    "    if \"no_ground_truth\" in flight_name:\n",
    "        continue\n",
    "    if \"no_failure\" in flight_name:\n",
    "            continue\n",
    "    # This folder has not path-dev csv file\n",
    "    if \"carbonZ_2018-09-11-15-06-34_3_rudder_left_failure\" in flight_name:\n",
    "        continue\n",
    "    print(flight_name)\n",
    "\n",
    "    if flight_name not in flight_topic_list:\n",
    "        flight_topic_list.append(flight_name)\n",
    "    \n",
    "\n",
    "    df_failure = None\n",
    "    failure_duration_start = pd.Timestamp('1970-01-01')\n",
    "    failure_duration_finish = pd.Timestamp('1970-01-01')\n",
    "\n",
    "    dfs = list()\n",
    "    for i , file in enumerate(glob.glob(os.path.join(data_path,flight_name,\"*.csv\"))):\n",
    "        \n",
    "        if any(x in file for x in unused_topic_list):\n",
    "            continue\n",
    "        \n",
    "\n",
    "        if \"failure_status\" in os.path.basename(file):\n",
    "            file_name = os.path.basename(file)\n",
    "            \n",
    "            df = read_data(file)\n",
    "            topic_name = extract_topic_name(flight_name,file_name)\n",
    "\n",
    "            \n",
    "            failure_duration_start = min(df.index)\n",
    "            failure_duration_end = max(df.index)\n",
    "\n",
    "            failure_status_dict[flight_name] = (failure_duration_start,failure_duration_end)\n",
    "\n",
    "            continue\n",
    "        \n",
    "        file_name = os.path.basename(file)\n",
    "\n",
    "        df = read_data(file)\n",
    "        topic_name = extract_topic_name(flight_name,file_name)\n",
    "        for col in unused_column_list:\n",
    "            if col in df.columns:\n",
    "                df.drop(col,axis=1,inplace=True)\n",
    "        new_columns = list(map(lambda x: f\"{topic_name}.{x.replace('field.', '')}\", df.columns))\n",
    "        df = df.set_axis(new_columns, axis=1)\n",
    "       \n",
    "     \n",
    "        \n",
    "        dfs.append(df)\n",
    "\n",
    "   \n",
    "    df_dict[flight_name] = dfs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dict[\"carbonZ_2018-07-18-15-53-31_1_engine_failure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6619,\n",
       " mavctrl-path_dev.y    0\n",
       " mavctrl-path_dev.z    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_dict[\"carbonZ_2018-07-18-15-53-31_1_engine_failure\"][0]),df_dict[\"carbonZ_2018-07-18-15-53-31_1_engine_failure\"][0].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'carbonZ_2018-07-18-15-53-31_1_engine_failure': (Timestamp('2018-07-18 19:58:47.129305993'),\n",
       "  Timestamp('2018-07-18 19:59:03.134074845')),\n",
       " 'carbonZ_2018-07-18-15-53-31_2_engine_failure': (Timestamp('2018-07-18 20:01:44.729304590'),\n",
       "  Timestamp('2018-07-18 20:01:59.928010526')),\n",
       " 'carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj': (Timestamp('2018-07-18 20:32:26.878396465'),\n",
       "  Timestamp('2018-07-18 20:32:42.672828037')),\n",
       " 'carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj': (Timestamp('2018-07-18 20:46:37.888445250'),\n",
       "  Timestamp('2018-07-18 20:46:54.288954056')),\n",
       " 'carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj': (Timestamp('2018-07-21 00:35:22.170194'),\n",
       "  Timestamp('2018-07-21 00:35:41.166058768')),\n",
       " 'carbonZ_2018-07-30-16-39-00_1_engine_failure': (Timestamp('2018-07-21 01:00:21.380769776'),\n",
       "  Timestamp('2018-07-21 01:00:36.175981200')),\n",
       " 'carbonZ_2018-07-30-16-39-00_2_engine_failure': (Timestamp('2018-07-21 01:04:00.575490608'),\n",
       "  Timestamp('2018-07-21 01:04:15.194122640')),\n",
       " 'carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj': (Timestamp('2018-07-30 21:16:33.314179152'),\n",
       "  Timestamp('2018-07-30 21:16:49.124017251')),\n",
       " 'carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj': (Timestamp('2018-07-30 21:25:25.757112162'),\n",
       "  Timestamp('2018-07-30 21:25:44.754748978')),\n",
       " 'carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj': (Timestamp('2018-07-30 21:41:15.634859201'),\n",
       "  Timestamp('2018-07-30 21:41:39.036278834')),\n",
       " 'carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj': (Timestamp('2018-07-30 21:49:47.539406723'),\n",
       "  Timestamp('2018-07-30 21:50:09.732858508')),\n",
       " 'carbonZ_2018-09-11-11-56-30_engine_failure': (Timestamp('2018-09-11 16:05:02.419301184'),\n",
       "  Timestamp('2018-09-11 16:05:22.921275104')),\n",
       " 'carbonZ_2018-09-11-14-22-07_1_engine_failure': (Timestamp('2018-09-11 18:26:14.324825782'),\n",
       "  Timestamp('2018-09-11 18:26:23.326658597')),\n",
       " 'carbonZ_2018-09-11-14-22-07_2_engine_failure': (Timestamp('2018-09-11 18:28:20.325374057'),\n",
       "  Timestamp('2018-09-11 18:28:32.326442789')),\n",
       " 'carbonZ_2018-09-11-14-41-51_elevator_failure': (Timestamp('2018-09-11 18:48:33.193239864'),\n",
       "  Timestamp('2018-09-11 18:48:43.702938424')),\n",
       " 'carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure': (Timestamp('2018-09-11 18:57:29.985030040'),\n",
       "  Timestamp('2018-09-11 18:59:37.993673016')),\n",
       " 'carbonZ_2018-09-11-15-05-11_1_elevator_failure': (Timestamp('2018-09-11 19:12:08.654835256'),\n",
       "  Timestamp('2018-09-11 19:12:21.172710456')),\n",
       " 'carbonZ_2018-09-11-15-06-34_1_rudder_right_failure': (Timestamp('2018-09-11 19:17:55.038442264'),\n",
       "  Timestamp('2018-09-11 19:18:09.537019480')),\n",
       " 'carbonZ_2018-09-11-15-06-34_2_rudder_right_failure': (Timestamp('2018-09-11 19:19:58.533612056'),\n",
       "  Timestamp('2018-09-11 19:20:15.542582552')),\n",
       " 'carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure': (Timestamp('2018-09-11 21:36:15.255535472'),\n",
       "  Timestamp('2018-09-11 21:36:42.254787570')),\n",
       " 'carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure': (Timestamp('2018-09-11 21:38:23.751688384'),\n",
       "  Timestamp('2018-09-11 21:38:59.249605331')),\n",
       " 'carbonZ_2018-09-11-17-55-30_1_right_aileron_failure': (Timestamp('2018-09-11 22:04:29.915932200'),\n",
       "  Timestamp('2018-09-11 22:04:50.916117253')),\n",
       " 'carbonZ_2018-09-11-17-55-30_2_left_aileron_failure': (Timestamp('2018-09-11 22:06:18.909972946'),\n",
       "  Timestamp('2018-09-11 22:06:49.930133544')),\n",
       " 'carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj': (Timestamp('2018-10-05 18:58:10.456220968'),\n",
       "  Timestamp('2018-10-05 18:58:19.953767048')),\n",
       " 'carbonZ_2018-10-05-14-37-22_2_right_aileron_failure': (Timestamp('2018-10-05 19:41:12.176343271'),\n",
       "  Timestamp('2018-10-05 19:42:23.177067207')),\n",
       " 'carbonZ_2018-10-05-14-37-22_3_left_aileron_failure': (Timestamp('2018-10-05 19:43:36.175449735'),\n",
       "  Timestamp('2018-10-05 19:44:00.176733447')),\n",
       " 'carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj': (Timestamp('2018-10-05 20:07:04.743298528'),\n",
       "  Timestamp('2018-10-05 20:07:21.746703360')),\n",
       " 'carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj': (Timestamp('2018-10-05 19:59:59.479181792'),\n",
       "  Timestamp('2018-10-05 20:00:12.477307424')),\n",
       " 'carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj': (Timestamp('2018-10-05 20:09:30.477759008'),\n",
       "  Timestamp('2018-10-05 20:09:46.474778400')),\n",
       " 'carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj': (Timestamp('2018-10-18 15:09:31.419064456'),\n",
       "  Timestamp('2018-10-18 15:09:43.416809576')),\n",
       " 'carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj': (Timestamp('2018-10-18 15:09:27.628350888'),\n",
       "  Timestamp('2018-10-18 15:09:38.630940104')),\n",
       " 'carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj': (Timestamp('2018-10-18 15:09:39.270985672'),\n",
       "  Timestamp('2018-10-18 15:09:53.269556136')),\n",
       " 'carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj': (Timestamp('2018-10-18 15:19:45.268859464'),\n",
       "  Timestamp('2018-10-18 15:20:04.768932520')),\n",
       " 'carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj': (Timestamp('2018-10-18 15:08:37.878232904'),\n",
       "  Timestamp('2018-10-18 15:08:45.380344968')),\n",
       " 'carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj': (Timestamp('2018-10-18 15:12:17.734694408'),\n",
       "  Timestamp('2018-10-18 15:12:31.237794664'))}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failure_status_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,data in df_dict.items():\n",
    "#     df_list = []\n",
    "#     for df in data:\n",
    "#         for col in df.columns:\n",
    "#             df[f'{col}_copy'] = df[col] \n",
    "    \n",
    "#         df_list.append(df)\n",
    "#     df_dict[key] = df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbonZ_2018-07-18-15-53-31_1_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-18-15-53-31_2_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-16-39-00_1_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-30-16-39-00_2_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-09-11-11-56-30_engine_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-22-07_1_engine_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-22-07_2_engine_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-41-51_elevator_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure\n",
      "13\n",
      "carbonZ_2018-09-11-15-05-11_1_elevator_failure\n",
      "13\n",
      "carbonZ_2018-09-11-15-06-34_1_rudder_right_failure\n",
      "13\n",
      "carbonZ_2018-09-11-15-06-34_2_rudder_right_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-55-30_1_right_aileron_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-55-30_2_left_aileron_failure\n",
      "13\n",
      "carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-05-14-37-22_2_right_aileron_failure\n",
      "13\n",
      "carbonZ_2018-10-05-14-37-22_3_left_aileron_failure\n",
      "13\n",
      "carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for key, df in df_dict.items():\n",
    "    print(key)\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, data in df_dict.items():\n",
    "    if \"rudder_zero__left_aileron_failure\" in key:\n",
    "        \n",
    "\n",
    "        df_dict[\"carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\"] = df_dict['carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure'].copy()\n",
    " \n",
    " \n",
    "\n",
    "        df_dict[\"carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\"] = df_dict['carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure'].copy()\n",
    "\n",
    "   \n",
    "\n",
    "        del df_dict['carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure']\n",
    "\n",
    "\n",
    "        break\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbonZ_2018-07-18-15-53-31_1_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-18-15-53-31_2_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-16-39-00_1_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-30-16-39-00_2_engine_failure\n",
      "13\n",
      "carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-09-11-11-56-30_engine_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-22-07_1_engine_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-22-07_2_engine_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-41-51_elevator_failure\n",
      "13\n",
      "carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure\n",
      "13\n",
      "carbonZ_2018-09-11-15-05-11_1_elevator_failure\n",
      "13\n",
      "carbonZ_2018-09-11-15-06-34_1_rudder_right_failure\n",
      "13\n",
      "carbonZ_2018-09-11-15-06-34_2_rudder_right_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-55-30_1_right_aileron_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-55-30_2_left_aileron_failure\n",
      "13\n",
      "carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-05-14-37-22_2_right_aileron_failure\n",
      "13\n",
      "carbonZ_2018-10-05-14-37-22_3_left_aileron_failure\n",
      "13\n",
      "carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj\n",
      "13\n",
      "carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\n",
      "13\n",
      "carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "for key, df in df_dict.items():\n",
    "    print(key)\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, data in failure_status_dict.items():\n",
    "    if \"rudder_zero__left_aileron_failure\" in key:\n",
    "        failure_status_dict[\"carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\"] = failure_status_dict[\"carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure\"]\n",
    "        failure_status_dict[\"carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\"] = failure_status_dict[\"carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure\"]\n",
    "        del failure_status_dict[\"carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure\"]\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mavros-imu-atm_pressure.fluid_pressure'], dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[\"carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\"][1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mavctrl-path_dev.y</th>\n",
       "      <th>mavctrl-path_dev.z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:50.820860792</th>\n",
       "      <td>141.284886</td>\n",
       "      <td>14.438259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:50.840917944</th>\n",
       "      <td>141.284886</td>\n",
       "      <td>14.438259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:50.861388914</th>\n",
       "      <td>141.284886</td>\n",
       "      <td>14.438259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:50.880812090</th>\n",
       "      <td>141.284886</td>\n",
       "      <td>14.438259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:50.901712334</th>\n",
       "      <td>144.798264</td>\n",
       "      <td>14.394005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:03.108804965</th>\n",
       "      <td>8.337481</td>\n",
       "      <td>21.670137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:03.130722624</th>\n",
       "      <td>8.337481</td>\n",
       "      <td>21.670137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:03.149511356</th>\n",
       "      <td>8.337481</td>\n",
       "      <td>21.670137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:03.171009244</th>\n",
       "      <td>8.337481</td>\n",
       "      <td>21.670137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:03.190838957</th>\n",
       "      <td>8.337481</td>\n",
       "      <td>21.670137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6619 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mavctrl-path_dev.y  mavctrl-path_dev.z\n",
       "timestamp                                                            \n",
       "2018-07-18 19:56:50.820860792          141.284886           14.438259\n",
       "2018-07-18 19:56:50.840917944          141.284886           14.438259\n",
       "2018-07-18 19:56:50.861388914          141.284886           14.438259\n",
       "2018-07-18 19:56:50.880812090          141.284886           14.438259\n",
       "2018-07-18 19:56:50.901712334          144.798264           14.394005\n",
       "...                                           ...                 ...\n",
       "2018-07-18 19:59:03.108804965            8.337481           21.670137\n",
       "2018-07-18 19:59:03.130722624            8.337481           21.670137\n",
       "2018-07-18 19:59:03.149511356            8.337481           21.670137\n",
       "2018-07-18 19:59:03.171009244            8.337481           21.670137\n",
       "2018-07-18 19:59:03.190838957            8.337481           21.670137\n",
       "\n",
       "[6619 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[\"carbonZ_2018-07-18-15-53-31_1_engine_failure\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_topic_list.append(\"carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\")\n",
    "flight_topic_list.append(\"carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\")\n",
    "flight_topic_list.remove(\"carbonZ_2018-09-11-17-27-13_1_rudder_zero__left_aileron_failure\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flight_topic_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2018-07-18 19:58:47.129305993'),\n",
       " Timestamp('2018-07-18 19:59:03.134074845'))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failure_status_dict[\"carbonZ_2018-07-18-15-53-31_1_engine_failure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                               mavctrl-path_dev.y  mavctrl-path_dev.z\n",
       " timestamp                                                            \n",
       " 2018-09-11 18:55:44.748852696          226.349940          -16.530594\n",
       " 2018-09-11 18:55:44.768693912          226.349940          -16.530594\n",
       " 2018-09-11 18:55:44.793884088          207.499653          -16.530594\n",
       " 2018-09-11 18:55:44.809683352          207.499366          -16.530594\n",
       " 2018-09-11 18:55:44.831660792          207.499366          -16.530594\n",
       " ...                                           ...                 ...\n",
       " 2018-09-11 18:59:38.029159576            5.033987            3.622774\n",
       " 2018-09-11 18:59:38.049874936            5.033987            3.622774\n",
       " 2018-09-11 18:59:38.073666904            5.033987            3.622774\n",
       " 2018-09-11 18:59:38.089277368            4.698973            4.732197\n",
       " 2018-09-11 18:59:38.109449304            4.698973            4.732197\n",
       " \n",
       " [11669 rows x 2 columns],\n",
       "                                mavros-imu-atm_pressure.fluid_pressure\n",
       " timestamp                                                            \n",
       " 2018-09-11 18:55:44.739465240                            97497.888184\n",
       " 2018-09-11 18:55:44.821564344                            97497.888184\n",
       " 2018-09-11 18:55:44.938280408                            97485.864258\n",
       " 2018-09-11 18:55:45.038424536                            97479.797363\n",
       " 2018-09-11 18:55:45.123441848                            97479.797363\n",
       " ...                                                               ...\n",
       " 2018-09-11 18:59:37.626786712                            97689.019775\n",
       " 2018-09-11 18:59:37.734683928                            97696.691895\n",
       " 2018-09-11 18:59:37.833203736                            97704.296875\n",
       " 2018-09-11 18:59:37.924305528                            97704.296875\n",
       " 2018-09-11 18:59:38.018054744                            97711.303711\n",
       " \n",
       " [2334 rows x 1 columns],\n",
       "                                mavros-imu-data.orientation.x  \\\n",
       " timestamp                                                      \n",
       " 2018-09-11 18:55:44.815328696                      -0.005702   \n",
       " 2018-09-11 18:55:45.302239320                      -0.027779   \n",
       " 2018-09-11 18:55:45.691413272                      -0.004409   \n",
       " 2018-09-11 18:55:46.060852152                       0.022710   \n",
       " 2018-09-11 18:55:46.443526008                       0.048855   \n",
       " ...                                                      ...   \n",
       " 2018-09-11 18:59:36.240079096                      -0.120860   \n",
       " 2018-09-11 18:59:36.683336696                      -0.126285   \n",
       " 2018-09-11 18:59:37.197629496                      -0.091700   \n",
       " 2018-09-11 18:59:37.632176952                      -0.057563   \n",
       " 2018-09-11 18:59:37.978509688                      -0.021296   \n",
       " \n",
       "                                mavros-imu-data.orientation.y  \\\n",
       " timestamp                                                      \n",
       " 2018-09-11 18:55:44.815328696                      -0.024376   \n",
       " 2018-09-11 18:55:45.302239320                      -0.232940   \n",
       " 2018-09-11 18:55:45.691413272                      -0.276876   \n",
       " 2018-09-11 18:55:46.060852152                      -0.314628   \n",
       " 2018-09-11 18:55:46.443526008                      -0.314407   \n",
       " ...                                                      ...   \n",
       " 2018-09-11 18:59:36.240079096                      -0.012206   \n",
       " 2018-09-11 18:59:36.683336696                      -0.054971   \n",
       " 2018-09-11 18:59:37.197629496                      -0.115521   \n",
       " 2018-09-11 18:59:37.632176952                      -0.169438   \n",
       " 2018-09-11 18:59:37.978509688                      -0.193174   \n",
       " \n",
       "                                mavros-imu-data.orientation.z  \\\n",
       " timestamp                                                      \n",
       " 2018-09-11 18:55:44.815328696                      -0.986004   \n",
       " 2018-09-11 18:55:45.302239320                      -0.958538   \n",
       " 2018-09-11 18:55:45.691413272                      -0.941414   \n",
       " 2018-09-11 18:55:46.060852152                      -0.920235   \n",
       " 2018-09-11 18:55:46.443526008                      -0.909142   \n",
       " ...                                                      ...   \n",
       " 2018-09-11 18:59:36.240079096                      -0.003183   \n",
       " 2018-09-11 18:59:36.683336696                       0.015267   \n",
       " 2018-09-11 18:59:37.197629496                       0.006238   \n",
       " 2018-09-11 18:59:37.632176952                       0.018558   \n",
       " 2018-09-11 18:59:37.978509688                       0.032839   \n",
       " \n",
       "                                mavros-imu-data.orientation.w  \\\n",
       " timestamp                                                      \n",
       " 2018-09-11 18:55:44.815328696                      -0.164833   \n",
       " 2018-09-11 18:55:45.302239320                      -0.161779   \n",
       " 2018-09-11 18:55:45.691413272                      -0.192508   \n",
       " 2018-09-11 18:55:46.060852152                      -0.231648   \n",
       " 2018-09-11 18:55:46.443526008                      -0.268742   \n",
       " ...                                                      ...   \n",
       " 2018-09-11 18:59:36.240079096                      -0.992589   \n",
       " 2018-09-11 18:59:36.683336696                      -0.990352   \n",
       " 2018-09-11 18:59:37.197629496                      -0.989044   \n",
       " 2018-09-11 18:59:37.632176952                      -0.983683   \n",
       " 2018-09-11 18:59:37.978509688                      -0.980384   \n",
       " \n",
       "                                mavros-imu-data.angular_velocity.x  \\\n",
       " timestamp                                                           \n",
       " 2018-09-11 18:55:44.815328696                            1.198352   \n",
       " 2018-09-11 18:55:45.302239320                            0.344504   \n",
       " 2018-09-11 18:55:45.691413272                            0.204759   \n",
       " 2018-09-11 18:55:46.060852152                           -0.013796   \n",
       " 2018-09-11 18:55:46.443526008                           -0.006801   \n",
       " ...                                                           ...   \n",
       " 2018-09-11 18:59:36.240079096                            0.044647   \n",
       " 2018-09-11 18:59:36.683336696                            0.073532   \n",
       " 2018-09-11 18:59:37.197629496                           -0.298716   \n",
       " 2018-09-11 18:59:37.632176952                           -0.146525   \n",
       " 2018-09-11 18:59:37.978509688                           -0.147029   \n",
       " \n",
       "                                mavros-imu-data.angular_velocity.y  \\\n",
       " timestamp                                                           \n",
       " 2018-09-11 18:55:44.815328696                           -0.003927   \n",
       " 2018-09-11 18:55:45.302239320                            0.093244   \n",
       " 2018-09-11 18:55:45.691413272                            0.108409   \n",
       " 2018-09-11 18:55:46.060852152                            0.087250   \n",
       " 2018-09-11 18:55:46.443526008                            0.039049   \n",
       " ...                                                           ...   \n",
       " 2018-09-11 18:59:36.240079096                            0.161116   \n",
       " 2018-09-11 18:59:36.683336696                            0.198077   \n",
       " 2018-09-11 18:59:37.197629496                            0.236909   \n",
       " 2018-09-11 18:59:37.632176952                            0.182599   \n",
       " 2018-09-11 18:59:37.978509688                            0.090268   \n",
       " \n",
       "                                mavros-imu-data.angular_velocity.z  \\\n",
       " timestamp                                                           \n",
       " 2018-09-11 18:55:44.815328696                           -0.046569   \n",
       " 2018-09-11 18:55:45.302239320                           -0.081719   \n",
       " 2018-09-11 18:55:45.691413272                           -0.277471   \n",
       " 2018-09-11 18:55:46.060852152                           -0.250878   \n",
       " 2018-09-11 18:55:46.443526008                           -0.169687   \n",
       " ...                                                           ...   \n",
       " 2018-09-11 18:59:36.240079096                           -0.134020   \n",
       " 2018-09-11 18:59:36.683336696                           -0.064672   \n",
       " 2018-09-11 18:59:37.197629496                            0.000992   \n",
       " 2018-09-11 18:59:37.632176952                           -0.147860   \n",
       " 2018-09-11 18:59:37.978509688                           -0.082429   \n",
       " \n",
       "                                mavros-imu-data.linear_acceleration.x  \\\n",
       " timestamp                                                              \n",
       " 2018-09-11 18:55:44.815328696                              -0.402073   \n",
       " 2018-09-11 18:55:45.302239320                              -1.353318   \n",
       " 2018-09-11 18:55:45.691413272                              -1.637711   \n",
       " 2018-09-11 18:55:46.060852152                              -1.980943   \n",
       " 2018-09-11 18:55:46.443526008                              -2.216303   \n",
       " ...                                                              ...   \n",
       " 2018-09-11 18:59:36.240079096                              -0.529559   \n",
       " 2018-09-11 18:59:36.683336696                              -1.108151   \n",
       " 2018-09-11 18:59:37.197629496                              -1.353318   \n",
       " 2018-09-11 18:59:37.632176952                              -1.520031   \n",
       " 2018-09-11 18:59:37.978509688                              -1.696550   \n",
       " \n",
       "                                mavros-imu-data.linear_acceleration.y  \\\n",
       " timestamp                                                              \n",
       " 2018-09-11 18:55:44.815328696                               0.127486   \n",
       " 2018-09-11 18:55:45.302239320                               0.539366   \n",
       " 2018-09-11 18:55:45.691413272                               0.480526   \n",
       " 2018-09-11 18:55:46.060852152                               0.647239   \n",
       " 2018-09-11 18:55:46.443526008                               0.931632   \n",
       " ...                                                              ...   \n",
       " 2018-09-11 18:59:36.240079096                               0.323619   \n",
       " 2018-09-11 18:59:36.683336696                               0.421686   \n",
       " 2018-09-11 18:59:37.197629496                               0.823759   \n",
       " 2018-09-11 18:59:37.632176952                               0.657046   \n",
       " 2018-09-11 18:59:37.978509688                               0.049033   \n",
       " \n",
       "                                mavros-imu-data.linear_acceleration.z  \n",
       " timestamp                                                             \n",
       " 2018-09-11 18:55:44.815328696                               8.463139  \n",
       " 2018-09-11 18:55:45.302239320                               7.874740  \n",
       " 2018-09-11 18:55:45.691413272                               4.138406  \n",
       " 2018-09-11 18:55:46.060852152                               5.864377  \n",
       " 2018-09-11 18:55:46.443526008                               7.757060  \n",
       " ...                                                              ...  \n",
       " 2018-09-11 18:59:36.240079096                               7.678607  \n",
       " 2018-09-11 18:59:36.683336696                               6.246836  \n",
       " 2018-09-11 18:59:37.197629496                               5.060231  \n",
       " 2018-09-11 18:59:37.632176952                               4.501252  \n",
       " 2018-09-11 18:59:37.978509688                               7.139241  \n",
       " \n",
       " [574 rows x 10 columns],\n",
       "                                mavros-imu-temperature.temperature\n",
       " timestamp                                                        \n",
       " 2018-09-11 18:55:44.739417624                               41.89\n",
       " 2018-09-11 18:55:44.821516824                               41.89\n",
       " 2018-09-11 18:55:44.938254904                               41.88\n",
       " 2018-09-11 18:55:45.038322712                               41.87\n",
       " 2018-09-11 18:55:45.123392344                               41.87\n",
       " ...                                                           ...\n",
       " 2018-09-11 18:59:37.626645912                               37.06\n",
       " 2018-09-11 18:59:37.734617272                               37.05\n",
       " 2018-09-11 18:59:37.833124216                               37.05\n",
       " 2018-09-11 18:59:37.924084376                               37.05\n",
       " 2018-09-11 18:59:38.018026488                               37.06\n",
       " \n",
       " [2334 rows x 1 columns],\n",
       "                                mavros-nav_info-airspeed.measured\n",
       " timestamp                                                       \n",
       " 2018-09-11 18:55:44.751156440                                0.0\n",
       " 2018-09-11 18:55:44.811619032                                0.0\n",
       " 2018-09-11 18:55:44.837812728                                0.0\n",
       " 2018-09-11 18:55:44.900119192                                0.0\n",
       " 2018-09-11 18:55:44.965182744                                0.0\n",
       " ...                                                          ...\n",
       " 2018-09-11 18:59:37.860557656                                0.0\n",
       " 2018-09-11 18:59:37.920680280                                0.0\n",
       " 2018-09-11 18:59:37.974660856                                0.0\n",
       " 2018-09-11 18:59:38.013118776                                0.0\n",
       " 2018-09-11 18:59:38.073726968                                0.0\n",
       " \n",
       " [4348 rows x 1 columns],\n",
       "                                mavros-nav_info-errors.alt_error  \\\n",
       " timestamp                                                         \n",
       " 2018-09-11 18:55:44.733756664                         -0.300000   \n",
       " 2018-09-11 18:55:44.747403736                         -0.300000   \n",
       " 2018-09-11 18:55:44.786480952                         -0.300000   \n",
       " 2018-09-11 18:55:44.836539000                         -0.430000   \n",
       " 2018-09-11 18:55:44.898553720                         -0.430000   \n",
       " ...                                                         ...   \n",
       " 2018-09-11 18:59:37.860320760                         20.289999   \n",
       " 2018-09-11 18:59:37.917356952                         20.289999   \n",
       " 2018-09-11 18:59:37.969003608                         20.859999   \n",
       " 2018-09-11 18:59:38.011773848                         20.859999   \n",
       " 2018-09-11 18:59:38.057258392                         21.469999   \n",
       " \n",
       "                                mavros-nav_info-errors.aspd_error  \\\n",
       " timestamp                                                          \n",
       " 2018-09-11 18:55:44.733756664                        -681.648438   \n",
       " 2018-09-11 18:55:44.747403736                        -681.648438   \n",
       " 2018-09-11 18:55:44.786480952                        -681.648438   \n",
       " 2018-09-11 18:55:44.836539000                        -684.812134   \n",
       " 2018-09-11 18:55:44.898553720                        -684.812134   \n",
       " ...                                                          ...   \n",
       " 2018-09-11 18:59:37.860320760                         -41.753960   \n",
       " 2018-09-11 18:59:37.917356952                         -41.753960   \n",
       " 2018-09-11 18:59:37.969003608                         -41.753960   \n",
       " 2018-09-11 18:59:38.011773848                         -41.753960   \n",
       " 2018-09-11 18:59:38.057258392                         -42.135429   \n",
       " \n",
       "                                mavros-nav_info-errors.xtrack_error  \\\n",
       " timestamp                                                            \n",
       " 2018-09-11 18:55:44.733756664                           -40.078075   \n",
       " 2018-09-11 18:55:44.747403736                           -40.078075   \n",
       " 2018-09-11 18:55:44.786480952                           -40.078075   \n",
       " 2018-09-11 18:55:44.836539000                           -37.936432   \n",
       " 2018-09-11 18:55:44.898553720                           -37.936432   \n",
       " ...                                                            ...   \n",
       " 2018-09-11 18:59:37.860320760                             5.042744   \n",
       " 2018-09-11 18:59:37.917356952                             5.042744   \n",
       " 2018-09-11 18:59:37.969003608                             4.909161   \n",
       " 2018-09-11 18:59:38.011773848                             4.909161   \n",
       " 2018-09-11 18:59:38.057258392                             4.764447   \n",
       " \n",
       "                                mavros-nav_info-errors.wp_dist  \n",
       " timestamp                                                      \n",
       " 2018-09-11 18:55:44.733756664                               4  \n",
       " 2018-09-11 18:55:44.747403736                               4  \n",
       " 2018-09-11 18:55:44.786480952                               4  \n",
       " 2018-09-11 18:55:44.836539000                               6  \n",
       " 2018-09-11 18:55:44.898553720                               6  \n",
       " ...                                                       ...  \n",
       " 2018-09-11 18:59:37.860320760                             165  \n",
       " 2018-09-11 18:59:37.917356952                             165  \n",
       " 2018-09-11 18:59:37.969003608                             165  \n",
       " 2018-09-11 18:59:38.011773848                             165  \n",
       " 2018-09-11 18:59:38.057258392                             165  \n",
       " \n",
       " [4440 rows x 4 columns],\n",
       "                                mavros-nav_info-pitch.measured\n",
       " timestamp                                                    \n",
       " 2018-09-11 18:55:44.733683000                        0.797831\n",
       " 2018-09-11 18:55:44.747360408                        0.797831\n",
       " 2018-09-11 18:55:44.786440792                        0.797831\n",
       " 2018-09-11 18:55:44.836514104                        0.183815\n",
       " 2018-09-11 18:55:44.898461464                        0.183815\n",
       " ...                                                       ...\n",
       " 2018-09-11 18:59:37.860291352                      -19.601870\n",
       " 2018-09-11 18:59:37.917281208                      -19.601870\n",
       " 2018-09-11 18:59:37.967814840                      -19.601870\n",
       " 2018-09-11 18:59:38.011744568                      -22.344082\n",
       " 2018-09-11 18:59:38.057027960                      -22.344082\n",
       " \n",
       " [4440 rows x 1 columns],\n",
       "                                mavros-nav_info-roll.measured\n",
       " timestamp                                                   \n",
       " 2018-09-11 18:55:44.733653240                     -11.961676\n",
       " 2018-09-11 18:55:44.747348664                     -11.961676\n",
       " 2018-09-11 18:55:44.785582360                     -11.961676\n",
       " 2018-09-11 18:55:44.836487064                       2.863091\n",
       " 2018-09-11 18:55:44.898428952                       2.863091\n",
       " ...                                                      ...\n",
       " 2018-09-11 18:59:37.917263992                       6.519372\n",
       " 2018-09-11 18:59:37.967593688                       6.519372\n",
       " 2018-09-11 18:59:38.011726584                       1.801064\n",
       " 2018-09-11 18:59:38.056942072                       1.801064\n",
       " 2018-09-11 18:59:38.118799704                       1.801064\n",
       " \n",
       " [4441 rows x 1 columns],\n",
       "                                mavros-nav_info-velocity.des_x  \\\n",
       " timestamp                                                       \n",
       " 2018-09-11 18:55:44.751172664                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.811629816                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.837833816                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.900179000                    1.600000e+01   \n",
       " 2018-09-11 18:55:44.964750008                    1.600000e+01   \n",
       " ...                                                       ...   \n",
       " 2018-09-11 18:59:37.860689592                    3.199951e-15   \n",
       " 2018-09-11 18:59:37.920835864                    3.169954e-15   \n",
       " 2018-09-11 18:59:37.974727832                    3.169954e-15   \n",
       " 2018-09-11 18:59:38.013186072                    3.169954e-15   \n",
       " 2018-09-11 18:59:38.073708088                    3.169954e-15   \n",
       " \n",
       "                                mavros-nav_info-velocity.des_y  \\\n",
       " timestamp                                                       \n",
       " 2018-09-11 18:55:44.751172664                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.811629816                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.837833816                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.900179000                   -3.552714e-15   \n",
       " 2018-09-11 18:55:44.964750008                   -3.552714e-15   \n",
       " ...                                                       ...   \n",
       " 2018-09-11 18:59:37.860689592                    1.580050e+01   \n",
       " 2018-09-11 18:59:37.920835864                    1.576931e+01   \n",
       " 2018-09-11 18:59:37.974727832                    1.576931e+01   \n",
       " 2018-09-11 18:59:38.013186072                    1.576931e+01   \n",
       " 2018-09-11 18:59:38.073708088                    1.576931e+01   \n",
       " \n",
       "                                mavros-nav_info-velocity.des_z  \\\n",
       " timestamp                                                       \n",
       " 2018-09-11 18:55:44.751172664                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.811629816                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.837833816                    0.000000e+00   \n",
       " 2018-09-11 18:55:44.900179000                    1.959435e-15   \n",
       " 2018-09-11 18:55:44.964750008                    1.959435e-15   \n",
       " ...                                                       ...   \n",
       " 2018-09-11 18:59:37.860689592                    2.518796e+00   \n",
       " 2018-09-11 18:59:37.920835864                    2.707196e+00   \n",
       " 2018-09-11 18:59:37.974727832                    2.707196e+00   \n",
       " 2018-09-11 18:59:38.013186072                    2.707196e+00   \n",
       " 2018-09-11 18:59:38.073708088                    2.707196e+00   \n",
       " \n",
       "                                mavros-nav_info-velocity.meas_x  \\\n",
       " timestamp                                                        \n",
       " 2018-09-11 18:55:44.751172664                         5.448525   \n",
       " 2018-09-11 18:55:44.811629816                         5.435284   \n",
       " 2018-09-11 18:55:44.837833816                         5.446200   \n",
       " 2018-09-11 18:55:44.900179000                         5.503401   \n",
       " 2018-09-11 18:55:44.964750008                         5.601675   \n",
       " ...                                                        ...   \n",
       " 2018-09-11 18:59:37.860689592                        -1.700567   \n",
       " 2018-09-11 18:59:37.920835864                        -1.696898   \n",
       " 2018-09-11 18:59:37.974727832                        -1.686711   \n",
       " 2018-09-11 18:59:38.013186072                        -1.687362   \n",
       " 2018-09-11 18:59:38.073708088                        -1.674494   \n",
       " \n",
       "                                mavros-nav_info-velocity.meas_y  \\\n",
       " timestamp                                                        \n",
       " 2018-09-11 18:55:44.751172664                       -20.630127   \n",
       " 2018-09-11 18:55:44.811629816                       -20.569389   \n",
       " 2018-09-11 18:55:44.837833816                       -20.520662   \n",
       " 2018-09-11 18:55:44.900179000                       -20.415331   \n",
       " 2018-09-11 18:55:44.964750008                       -20.283449   \n",
       " ...                                                        ...   \n",
       " 2018-09-11 18:59:37.860689592                        16.762850   \n",
       " 2018-09-11 18:59:37.920835864                        16.808422   \n",
       " 2018-09-11 18:59:37.974727832                        16.851337   \n",
       " 2018-09-11 18:59:38.013186072                        16.912659   \n",
       " 2018-09-11 18:59:38.073708088                        17.052553   \n",
       " \n",
       "                                mavros-nav_info-velocity.meas_z  \n",
       " timestamp                                                       \n",
       " 2018-09-11 18:55:44.751172664                        -1.310496  \n",
       " 2018-09-11 18:55:44.811629816                        -1.264987  \n",
       " 2018-09-11 18:55:44.837833816                        -1.268989  \n",
       " 2018-09-11 18:55:44.900179000                        -1.315569  \n",
       " 2018-09-11 18:55:44.964750008                        -1.351536  \n",
       " ...                                                        ...  \n",
       " 2018-09-11 18:59:37.860689592                         5.994641  \n",
       " 2018-09-11 18:59:37.920835864                         6.185676  \n",
       " 2018-09-11 18:59:37.974727832                         6.284477  \n",
       " 2018-09-11 18:59:38.013186072                         6.342451  \n",
       " 2018-09-11 18:59:38.073708088                         6.416114  \n",
       " \n",
       " [4348 rows x 6 columns],\n",
       "                                mavros-nav_info-yaw.measured\n",
       " timestamp                                                  \n",
       " 2018-09-11 18:55:44.733721848                    -70.156189\n",
       " 2018-09-11 18:55:44.747371832                    -70.156189\n",
       " 2018-09-11 18:55:44.786465720                    -70.156189\n",
       " 2018-09-11 18:55:44.836527032                    -71.014297\n",
       " 2018-09-11 18:55:44.898478872                    -71.014297\n",
       " ...                                                     ...\n",
       " 2018-09-11 18:59:37.860307032                     91.034180\n",
       " 2018-09-11 18:59:37.917339416                     91.034180\n",
       " 2018-09-11 18:59:37.967848504                     91.034180\n",
       " 2018-09-11 18:59:38.011759000                     93.481194\n",
       " 2018-09-11 18:59:38.057181560                     93.481194\n",
       " \n",
       " [4440 rows x 1 columns],\n",
       "                                mavros-time_reference.time_ref\n",
       " timestamp                                                    \n",
       " 2018-09-11 18:55:44.736821976             1536692377361000000\n",
       " 2018-09-11 18:55:45.206083608             1536692377841000000\n",
       " 2018-09-11 18:55:45.815905752             1536692378440000000\n",
       " 2018-09-11 18:55:46.251725048             1536692378879000000\n",
       " 2018-09-11 18:55:46.631150328             1536692379261000000\n",
       " ...                                                       ...\n",
       " 2018-09-11 18:59:35.671488152             1536692608301000000\n",
       " 2018-09-11 18:59:36.138563064             1536692608778000000\n",
       " 2018-09-11 18:59:36.746569464             1536692609360000000\n",
       " 2018-09-11 18:59:37.272394168             1536692609917000000\n",
       " 2018-09-11 18:59:37.862205048             1536692610500000000\n",
       " \n",
       " [477 rows x 1 columns],\n",
       "                                mavros-vfr_hud.airspeed  \\\n",
       " timestamp                                                \n",
       " 2018-09-11 18:55:44.813606648                      0.0   \n",
       " 2018-09-11 18:55:45.288424728                      0.0   \n",
       " 2018-09-11 18:55:45.689541272                      0.0   \n",
       " 2018-09-11 18:55:46.059403576                      0.0   \n",
       " 2018-09-11 18:55:46.439877208                      0.0   \n",
       " ...                                                ...   \n",
       " 2018-09-11 18:59:36.236687256                      0.0   \n",
       " 2018-09-11 18:59:36.682041176                      0.0   \n",
       " 2018-09-11 18:59:37.193585176                      0.0   \n",
       " 2018-09-11 18:59:37.628674168                      0.0   \n",
       " 2018-09-11 18:59:37.976107736                      0.0   \n",
       " \n",
       "                                mavros-vfr_hud.groundspeed  \\\n",
       " timestamp                                                   \n",
       " 2018-09-11 18:55:44.813606648                   21.275387   \n",
       " 2018-09-11 18:55:45.288424728                   20.532625   \n",
       " 2018-09-11 18:55:45.689541272                   19.939848   \n",
       " 2018-09-11 18:55:46.059403576                   19.413969   \n",
       " 2018-09-11 18:55:46.439877208                   19.055178   \n",
       " ...                                                   ...   \n",
       " 2018-09-11 18:59:36.236687256                   17.511122   \n",
       " 2018-09-11 18:59:36.682041176                   17.207243   \n",
       " 2018-09-11 18:59:37.193585176                   16.966467   \n",
       " 2018-09-11 18:59:37.628674168                   16.777716   \n",
       " 2018-09-11 18:59:37.976107736                   16.935541   \n",
       " \n",
       "                                mavros-vfr_hud.heading  \\\n",
       " timestamp                                               \n",
       " 2018-09-11 18:55:44.813606648                     288   \n",
       " 2018-09-11 18:55:45.288424728                     288   \n",
       " 2018-09-11 18:55:45.689541272                     291   \n",
       " 2018-09-11 18:55:46.059403576                     294   \n",
       " 2018-09-11 18:55:46.439877208                     298   \n",
       " ...                                               ...   \n",
       " 2018-09-11 18:59:36.236687256                      89   \n",
       " 2018-09-11 18:59:36.682041176                      90   \n",
       " 2018-09-11 18:59:37.193585176                      89   \n",
       " 2018-09-11 18:59:37.628674168                      91   \n",
       " 2018-09-11 18:59:37.976107736                      93   \n",
       " \n",
       "                                mavros-vfr_hud.throttle  \\\n",
       " timestamp                                                \n",
       " 2018-09-11 18:55:44.813606648                     0.42   \n",
       " 2018-09-11 18:55:45.288424728                     0.31   \n",
       " 2018-09-11 18:55:45.689541272                     0.19   \n",
       " 2018-09-11 18:55:46.059403576                     0.13   \n",
       " 2018-09-11 18:55:46.439877208                     0.07   \n",
       " ...                                                ...   \n",
       " 2018-09-11 18:59:36.236687256                     0.28   \n",
       " 2018-09-11 18:59:36.682041176                     0.13   \n",
       " 2018-09-11 18:59:37.193585176                     0.02   \n",
       " 2018-09-11 18:59:37.628674168                     0.00   \n",
       " 2018-09-11 18:59:37.976107736                     0.00   \n",
       " \n",
       "                                mavros-vfr_hud.altitude  mavros-vfr_hud.climb  \n",
       " timestamp                                                                     \n",
       " 2018-09-11 18:55:44.813606648               410.979980              2.028334  \n",
       " 2018-09-11 18:55:45.288424728               411.619995              5.472738  \n",
       " 2018-09-11 18:55:45.689541272               411.729980              2.834411  \n",
       " 2018-09-11 18:55:46.059403576               411.119995             -0.804450  \n",
       " 2018-09-11 18:55:46.439877208               409.899994             -2.400985  \n",
       " ...                                                ...                   ...  \n",
       " 2018-09-11 18:59:36.236687256               393.539978              3.508874  \n",
       " 2018-09-11 18:59:36.682041176               393.690002              2.542262  \n",
       " 2018-09-11 18:59:37.193585176               393.039978              0.578386  \n",
       " 2018-09-11 18:59:37.628674168               391.380005             -2.801878  \n",
       " 2018-09-11 18:59:37.976107736               389.500000             -4.096410  \n",
       " \n",
       " [574 rows x 6 columns],\n",
       "                                mavros-wind_estimation.twist.linear.x  \\\n",
       " timestamp                                                              \n",
       " 2018-09-11 18:55:44.735729400                              -0.244657   \n",
       " 2018-09-11 18:55:45.204481688                              -0.246626   \n",
       " 2018-09-11 18:55:45.815334840                              -0.256024   \n",
       " 2018-09-11 18:55:46.251742712                              -0.263208   \n",
       " 2018-09-11 18:55:46.630086456                              -0.272890   \n",
       " ...                                                              ...   \n",
       " 2018-09-11 18:59:35.669880760                              -0.392364   \n",
       " 2018-09-11 18:59:36.137095000                              -0.391501   \n",
       " 2018-09-11 18:59:36.745169944                              -0.392030   \n",
       " 2018-09-11 18:59:37.272128440                              -0.391855   \n",
       " 2018-09-11 18:59:37.860959800                              -0.388418   \n",
       " \n",
       "                                mavros-wind_estimation.twist.linear.y  \\\n",
       " timestamp                                                              \n",
       " 2018-09-11 18:55:44.735729400                               1.064529   \n",
       " 2018-09-11 18:55:45.204481688                               1.066408   \n",
       " 2018-09-11 18:55:45.815334840                               1.059074   \n",
       " 2018-09-11 18:55:46.251742712                               1.054658   \n",
       " 2018-09-11 18:55:46.630086456                               1.050315   \n",
       " ...                                                              ...   \n",
       " 2018-09-11 18:59:35.669880760                               1.266036   \n",
       " 2018-09-11 18:59:36.137095000                               1.265149   \n",
       " 2018-09-11 18:59:36.745169944                               1.257739   \n",
       " 2018-09-11 18:59:37.272128440                               1.251944   \n",
       " 2018-09-11 18:59:37.860959800                               1.251336   \n",
       " \n",
       "                                mavros-wind_estimation.twist.linear.z  \n",
       " timestamp                                                             \n",
       " 2018-09-11 18:55:44.735729400                                    0.0  \n",
       " 2018-09-11 18:55:45.204481688                                    0.0  \n",
       " 2018-09-11 18:55:45.815334840                                    0.0  \n",
       " 2018-09-11 18:55:46.251742712                                    0.0  \n",
       " 2018-09-11 18:55:46.630086456                                    0.0  \n",
       " ...                                                              ...  \n",
       " 2018-09-11 18:59:35.669880760                                    0.0  \n",
       " 2018-09-11 18:59:36.137095000                                    0.0  \n",
       " 2018-09-11 18:59:36.745169944                                    0.0  \n",
       " 2018-09-11 18:59:37.272128440                                    0.0  \n",
       " 2018-09-11 18:59:37.860959800                                    0.0  \n",
       " \n",
       " [477 rows x 3 columns]]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_dict[\"carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Failure Status:\n",
    "    \n",
    "    Engine     = 1\n",
    "    Rudder     = 2\n",
    "    Aileron    = 3\n",
    "    Elevator   = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_failure(flight_name,df_failure,failure_duration_start,failure_duration_end):\n",
    "    if \"engine\" in flight_name:\n",
    "        failure_status = [\n",
    "        1 if (x > failure_duration_start and x < failure_duration_end) else 0 \n",
    "        for x in df_failure.index\n",
    "                ]\n",
    "    elif \"rudder\" in flight_name:\n",
    "        failure_status = [\n",
    "        2 if (x > failure_duration_start and x < failure_duration_end) else 0 \n",
    "        for x in df_failure.index\n",
    "                ]\n",
    "    elif \"aileron\" in flight_name:\n",
    "        failure_status = [\n",
    "        3 if (x > failure_duration_start and x < failure_duration_end) else 0 \n",
    "        for x in df_failure.index\n",
    "                ]\n",
    "    elif \"elevator\" in flight_name:\n",
    "        failure_status = [\n",
    "        4 if (x > failure_duration_start and x < failure_duration_end) else 0 \n",
    "        for x in df_failure.index\n",
    "                ]\n",
    "        \n",
    "    df_failure[\"failure_status\"] = failure_status\n",
    "        \n",
    "    return df_failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carbonZ_2018-07-18-15-53-31_1_engine_failure',\n",
       " 'carbonZ_2018-07-18-15-53-31_2_engine_failure',\n",
       " 'carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-07-30-16-39-00_1_engine_failure',\n",
       " 'carbonZ_2018-07-30-16-39-00_2_engine_failure',\n",
       " 'carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-09-11-11-56-30_engine_failure',\n",
       " 'carbonZ_2018-09-11-14-22-07_1_engine_failure',\n",
       " 'carbonZ_2018-09-11-14-22-07_2_engine_failure',\n",
       " 'carbonZ_2018-09-11-14-41-51_elevator_failure',\n",
       " 'carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure',\n",
       " 'carbonZ_2018-09-11-15-05-11_1_elevator_failure',\n",
       " 'carbonZ_2018-09-11-15-06-34_1_rudder_right_failure',\n",
       " 'carbonZ_2018-09-11-15-06-34_2_rudder_right_failure',\n",
       " 'carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure',\n",
       " 'carbonZ_2018-09-11-17-55-30_1_right_aileron_failure',\n",
       " 'carbonZ_2018-09-11-17-55-30_2_left_aileron_failure',\n",
       " 'carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-05-14-37-22_2_right_aileron_failure',\n",
       " 'carbonZ_2018-10-05-14-37-22_3_left_aileron_failure',\n",
       " 'carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj',\n",
       " 'carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure',\n",
       " 'carbonZ_2018-09-11-17-27-13_1_left_aileron_failure']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbonZ_2018-07-18-15-53-31_1_engine_failure\n",
      "carbonZ_2018-07-18-15-53-31_2_engine_failure\n",
      "carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-16-39-00_1_engine_failure\n",
      "carbonZ_2018-07-30-16-39-00_2_engine_failure\n",
      "carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj\n",
      "carbonZ_2018-09-11-11-56-30_engine_failure\n",
      "carbonZ_2018-09-11-14-22-07_1_engine_failure\n",
      "carbonZ_2018-09-11-14-22-07_2_engine_failure\n",
      "carbonZ_2018-09-11-14-41-51_elevator_failure\n",
      "carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure\n",
      "carbonZ_2018-09-11-15-05-11_1_elevator_failure\n",
      "carbonZ_2018-09-11-15-06-34_1_rudder_right_failure\n",
      "carbonZ_2018-09-11-15-06-34_2_rudder_right_failure\n",
      "carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure\n",
      "carbonZ_2018-09-11-17-55-30_1_right_aileron_failure\n",
      "carbonZ_2018-09-11-17-55-30_2_left_aileron_failure\n",
      "carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-14-37-22_2_right_aileron_failure\n",
      "carbonZ_2018-10-05-14-37-22_3_left_aileron_failure\n",
      "carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj\n",
      "carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\n",
      "carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\n"
     ]
    }
   ],
   "source": [
    "for flight_name in flight_topic_list:\n",
    "    print(flight_name)\n",
    "    dfs = df_dict[flight_name] \n",
    "    \n",
    "    start_time = min(min(dfs[0].index),min(dfs[1].index),min(dfs[2].index),min(dfs[3].index),min(dfs[4].index),min(dfs[5].index),min(dfs[6].index),min(dfs[7].index),min(dfs[8].index),min(dfs[9].index),min(dfs[10].index),min(dfs[11].index),min(dfs[12].index))\n",
    "    end_time = max(max(dfs[0].index),max(dfs[1].index),max(dfs[2].index),max(dfs[3].index),max(dfs[4].index),max(dfs[5].index),max(dfs[6].index),max(dfs[7].index),max(dfs[8].index),max(dfs[9].index),max(dfs[10].index),max(dfs[11].index),max(dfs[12].index))\n",
    "    \n",
    "    time_index = pd.date_range(start=start_time, end=end_time, freq=\"200ms\")  \n",
    "    data = [0] * len(time_index)\n",
    "\n",
    "    df_failure = pd.DataFrame(data, index=time_index, columns=[\"failure_status\"])\n",
    "\n",
    "    failure_duration_start = failure_status_dict[flight_name][0]\n",
    "    failure_duration_end   = failure_status_dict[flight_name][1]\n",
    "    \n",
    "    \n",
    "    df_dict[flight_name].append(add_failure(flight_name,df_failure,failure_duration_start,failure_duration_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mavros-wind_estimation.twist.linear.x</th>\n",
       "      <th>mavros-wind_estimation.twist.linear.y</th>\n",
       "      <th>mavros-wind_estimation.twist.linear.z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:19.188548395</th>\n",
       "      <td>0.360470</td>\n",
       "      <td>1.439026</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:19.566847897</th>\n",
       "      <td>0.352583</td>\n",
       "      <td>1.463511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:19.954091484</th>\n",
       "      <td>0.345375</td>\n",
       "      <td>1.496819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:20.421941571</th>\n",
       "      <td>0.328750</td>\n",
       "      <td>1.548180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:20.868431200</th>\n",
       "      <td>0.321009</td>\n",
       "      <td>1.588851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:40.589048991</th>\n",
       "      <td>-0.256345</td>\n",
       "      <td>2.252147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:40.936268682</th>\n",
       "      <td>-0.255210</td>\n",
       "      <td>2.252631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:41.422716742</th>\n",
       "      <td>-0.253657</td>\n",
       "      <td>2.253724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:41.785506158</th>\n",
       "      <td>-0.252744</td>\n",
       "      <td>2.256600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:42.286168071</th>\n",
       "      <td>-0.252200</td>\n",
       "      <td>2.260911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mavros-wind_estimation.twist.linear.x  \\\n",
       "timestamp                                                              \n",
       "2018-09-11 21:34:19.188548395                               0.360470   \n",
       "2018-09-11 21:34:19.566847897                               0.352583   \n",
       "2018-09-11 21:34:19.954091484                               0.345375   \n",
       "2018-09-11 21:34:20.421941571                               0.328750   \n",
       "2018-09-11 21:34:20.868431200                               0.321009   \n",
       "...                                                              ...   \n",
       "2018-09-11 21:36:40.589048991                              -0.256345   \n",
       "2018-09-11 21:36:40.936268682                              -0.255210   \n",
       "2018-09-11 21:36:41.422716742                              -0.253657   \n",
       "2018-09-11 21:36:41.785506158                              -0.252744   \n",
       "2018-09-11 21:36:42.286168071                              -0.252200   \n",
       "\n",
       "                               mavros-wind_estimation.twist.linear.y  \\\n",
       "timestamp                                                              \n",
       "2018-09-11 21:34:19.188548395                               1.439026   \n",
       "2018-09-11 21:34:19.566847897                               1.463511   \n",
       "2018-09-11 21:34:19.954091484                               1.496819   \n",
       "2018-09-11 21:34:20.421941571                               1.548180   \n",
       "2018-09-11 21:34:20.868431200                               1.588851   \n",
       "...                                                              ...   \n",
       "2018-09-11 21:36:40.589048991                               2.252147   \n",
       "2018-09-11 21:36:40.936268682                               2.252631   \n",
       "2018-09-11 21:36:41.422716742                               2.253724   \n",
       "2018-09-11 21:36:41.785506158                               2.256600   \n",
       "2018-09-11 21:36:42.286168071                               2.260911   \n",
       "\n",
       "                               mavros-wind_estimation.twist.linear.z  \n",
       "timestamp                                                             \n",
       "2018-09-11 21:34:19.188548395                                    0.0  \n",
       "2018-09-11 21:34:19.566847897                                    0.0  \n",
       "2018-09-11 21:34:19.954091484                                    0.0  \n",
       "2018-09-11 21:34:20.421941571                                    0.0  \n",
       "2018-09-11 21:34:20.868431200                                    0.0  \n",
       "...                                                              ...  \n",
       "2018-09-11 21:36:40.589048991                                    0.0  \n",
       "2018-09-11 21:36:40.936268682                                    0.0  \n",
       "2018-09-11 21:36:41.422716742                                    0.0  \n",
       "2018-09-11 21:36:41.785506158                                    0.0  \n",
       "2018-09-11 21:36:42.286168071                                    0.0  \n",
       "\n",
       "[311 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_dict[\"carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\"]\n",
    "df[12].iloc[: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mavros-wind_estimation.twist.linear.x</th>\n",
       "      <th>mavros-wind_estimation.twist.linear.y</th>\n",
       "      <th>mavros-wind_estimation.twist.linear.z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:19.188548395</th>\n",
       "      <td>0.360470</td>\n",
       "      <td>1.439026</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:19.566847897</th>\n",
       "      <td>0.352583</td>\n",
       "      <td>1.463511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:19.954091484</th>\n",
       "      <td>0.345375</td>\n",
       "      <td>1.496819</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:20.421941571</th>\n",
       "      <td>0.328750</td>\n",
       "      <td>1.548180</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:34:20.868431200</th>\n",
       "      <td>0.321009</td>\n",
       "      <td>1.588851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:40.589048991</th>\n",
       "      <td>-0.256345</td>\n",
       "      <td>2.252147</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:40.936268682</th>\n",
       "      <td>-0.255210</td>\n",
       "      <td>2.252631</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:41.422716742</th>\n",
       "      <td>-0.253657</td>\n",
       "      <td>2.253724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:41.785506158</th>\n",
       "      <td>-0.252744</td>\n",
       "      <td>2.256600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-11 21:36:42.286168071</th>\n",
       "      <td>-0.252200</td>\n",
       "      <td>2.260911</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mavros-wind_estimation.twist.linear.x  \\\n",
       "timestamp                                                              \n",
       "2018-09-11 21:34:19.188548395                               0.360470   \n",
       "2018-09-11 21:34:19.566847897                               0.352583   \n",
       "2018-09-11 21:34:19.954091484                               0.345375   \n",
       "2018-09-11 21:34:20.421941571                               0.328750   \n",
       "2018-09-11 21:34:20.868431200                               0.321009   \n",
       "...                                                              ...   \n",
       "2018-09-11 21:36:40.589048991                              -0.256345   \n",
       "2018-09-11 21:36:40.936268682                              -0.255210   \n",
       "2018-09-11 21:36:41.422716742                              -0.253657   \n",
       "2018-09-11 21:36:41.785506158                              -0.252744   \n",
       "2018-09-11 21:36:42.286168071                              -0.252200   \n",
       "\n",
       "                               mavros-wind_estimation.twist.linear.y  \\\n",
       "timestamp                                                              \n",
       "2018-09-11 21:34:19.188548395                               1.439026   \n",
       "2018-09-11 21:34:19.566847897                               1.463511   \n",
       "2018-09-11 21:34:19.954091484                               1.496819   \n",
       "2018-09-11 21:34:20.421941571                               1.548180   \n",
       "2018-09-11 21:34:20.868431200                               1.588851   \n",
       "...                                                              ...   \n",
       "2018-09-11 21:36:40.589048991                               2.252147   \n",
       "2018-09-11 21:36:40.936268682                               2.252631   \n",
       "2018-09-11 21:36:41.422716742                               2.253724   \n",
       "2018-09-11 21:36:41.785506158                               2.256600   \n",
       "2018-09-11 21:36:42.286168071                               2.260911   \n",
       "\n",
       "                               mavros-wind_estimation.twist.linear.z  \n",
       "timestamp                                                             \n",
       "2018-09-11 21:34:19.188548395                                    0.0  \n",
       "2018-09-11 21:34:19.566847897                                    0.0  \n",
       "2018-09-11 21:34:19.954091484                                    0.0  \n",
       "2018-09-11 21:34:20.421941571                                    0.0  \n",
       "2018-09-11 21:34:20.868431200                                    0.0  \n",
       "...                                                              ...  \n",
       "2018-09-11 21:36:40.589048991                                    0.0  \n",
       "2018-09-11 21:36:40.936268682                                    0.0  \n",
       "2018-09-11 21:36:41.422716742                                    0.0  \n",
       "2018-09-11 21:36:41.785506158                                    0.0  \n",
       "2018-09-11 21:36:42.286168071                                    0.0  \n",
       "\n",
       "[311 rows x 3 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_dict[\"carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\"]\n",
    "df[12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbonZ_2018-07-18-15-53-31_1_engine_failure\n",
      "14\n",
      "carbonZ_2018-07-18-15-53-31_2_engine_failure\n",
      "14\n",
      "carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-07-30-16-39-00_1_engine_failure\n",
      "14\n",
      "carbonZ_2018-07-30-16-39-00_2_engine_failure\n",
      "14\n",
      "carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-09-11-11-56-30_engine_failure\n",
      "14\n",
      "carbonZ_2018-09-11-14-22-07_1_engine_failure\n",
      "14\n",
      "carbonZ_2018-09-11-14-22-07_2_engine_failure\n",
      "14\n",
      "carbonZ_2018-09-11-14-41-51_elevator_failure\n",
      "14\n",
      "carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure\n",
      "14\n",
      "carbonZ_2018-09-11-15-05-11_1_elevator_failure\n",
      "14\n",
      "carbonZ_2018-09-11-15-06-34_1_rudder_right_failure\n",
      "14\n",
      "carbonZ_2018-09-11-15-06-34_2_rudder_right_failure\n",
      "14\n",
      "carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure\n",
      "14\n",
      "carbonZ_2018-09-11-17-55-30_1_right_aileron_failure\n",
      "14\n",
      "carbonZ_2018-09-11-17-55-30_2_left_aileron_failure\n",
      "14\n",
      "carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-05-14-37-22_2_right_aileron_failure\n",
      "14\n",
      "carbonZ_2018-10-05-14-37-22_3_left_aileron_failure\n",
      "14\n",
      "carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj\n",
      "14\n",
      "carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\n",
      "14\n",
      "carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "for key, df in df_dict.items():\n",
    "    print(key)\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birle≈ütirme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mavros-imu-atm_pressure.fluid_pressure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:50.883316762</th>\n",
       "      <td>97310.498047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:50.958577559</th>\n",
       "      <td>97310.498047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:51.062952770</th>\n",
       "      <td>97329.193115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:51.153503583</th>\n",
       "      <td>97341.693115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:56:51.245127118</th>\n",
       "      <td>97329.223633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:02.784104260</th>\n",
       "      <td>97410.662842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:02.886696084</th>\n",
       "      <td>97414.984131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:02.954867820</th>\n",
       "      <td>97414.984131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:03.072783613</th>\n",
       "      <td>97418.975830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18 19:59:03.128568663</th>\n",
       "      <td>97418.975830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1323 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mavros-imu-atm_pressure.fluid_pressure\n",
       "timestamp                                                            \n",
       "2018-07-18 19:56:50.883316762                            97310.498047\n",
       "2018-07-18 19:56:50.958577559                            97310.498047\n",
       "2018-07-18 19:56:51.062952770                            97329.193115\n",
       "2018-07-18 19:56:51.153503583                            97341.693115\n",
       "2018-07-18 19:56:51.245127118                            97329.223633\n",
       "...                                                               ...\n",
       "2018-07-18 19:59:02.784104260                            97410.662842\n",
       "2018-07-18 19:59:02.886696084                            97414.984131\n",
       "2018-07-18 19:59:02.954867820                            97414.984131\n",
       "2018-07-18 19:59:03.072783613                            97418.975830\n",
       "2018-07-18 19:59:03.128568663                            97418.975830\n",
       "\n",
       "[1323 rows x 1 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_dict[\"carbonZ_2018-07-18-15-53-31_1_engine_failure\"][1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carbonZ_2018-07-18-15-53-31_1_engine_failure\n",
      "carbonZ_2018-07-18-15-53-31_2_engine_failure\n",
      "carbonZ_2018-07-18-16-22-01_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-18-16-37-39_2_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-16-29-45_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-16-39-00_1_engine_failure\n",
      "carbonZ_2018-07-30-16-39-00_2_engine_failure\n",
      "carbonZ_2018-07-30-17-10-45_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-20-01_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-36-35_engine_failure_with_emr_traj\n",
      "carbonZ_2018-07-30-17-46-31_engine_failure_with_emr_traj\n",
      "carbonZ_2018-09-11-11-56-30_engine_failure\n",
      "carbonZ_2018-09-11-14-22-07_1_engine_failure\n",
      "carbonZ_2018-09-11-14-22-07_2_engine_failure\n",
      "carbonZ_2018-09-11-14-41-51_elevator_failure\n",
      "carbonZ_2018-09-11-14-52-54_left_aileron__right_aileron__failure\n",
      "carbonZ_2018-09-11-15-05-11_1_elevator_failure\n",
      "carbonZ_2018-09-11-15-06-34_1_rudder_right_failure\n",
      "carbonZ_2018-09-11-15-06-34_2_rudder_right_failure\n",
      "carbonZ_2018-09-11-17-27-13_2_both_ailerons_failure\n",
      "carbonZ_2018-09-11-17-55-30_1_right_aileron_failure\n",
      "carbonZ_2018-09-11-17-55-30_2_left_aileron_failure\n",
      "carbonZ_2018-10-05-14-34-20_2_right_aileron_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-14-37-22_2_right_aileron_failure\n",
      "carbonZ_2018-10-05-14-37-22_3_left_aileron_failure\n",
      "carbonZ_2018-10-05-15-52-12_3_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-15-55-10_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-05-16-04-46_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-03-57_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-00_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-08_1_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-08_2_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-04-35_engine_failure_with_emr_traj\n",
      "carbonZ_2018-10-18-11-06-06_engine_failure_with_emr_traj\n",
      "carbonZ_2018-09-11-17-27-13_1_rudder_zero_failure\n",
      "carbonZ_2018-09-11-17-27-13_1_left_aileron_failure\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "w_label = 66\n",
    "s_label = 6\n",
    "\n",
    "window_sizes = [661, 132, 32, 132, 247, 253, 253, 253, 247, 253, 27, 32, 27]\n",
    "step_sizes =   [66, 13, 3, 13, 24, 25, 25, 25, 24, 25, 2, 3, 2]\n",
    "\n",
    "x_arrays = [np.zeros((0, w, c)) for w, c in zip(window_sizes, [2, 1, 10, 1, 1, 4, 1, 1, 6, 1, 1, 6, 3])]\n",
    "y = []\n",
    "\n",
    "for key, data in df_dict.items():\n",
    "    print(key)\n",
    "    \n",
    "    scaled_data = [pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index).dropna() for df in data[:-1]]\n",
    "    labels_data = data[-1]\n",
    "\n",
    "    len_label = len(labels_data)\n",
    "    len_data = [len(df) for df in scaled_data]\n",
    "\n",
    "    while all(len_d - w >= 0 for len_d, w in zip(len_data, window_sizes)):\n",
    "        labels = labels_data[len_label - w_label : len_label].values\n",
    "        len_label -= s_label\n",
    "\n",
    "        slices = [df[len_d - w : len_d].values for df, len_d, w in zip(scaled_data, len_data, window_sizes)]\n",
    "        reshaped_slices = [\n",
    "            sl.reshape(-1, w, c) for sl, w, c in zip(slices, window_sizes, [2, 1, 10, 1, 1, 4, 1, 1, 6, 1, 1, 6, 3])\n",
    "        ]\n",
    "        len_data = [len_d - s for len_d, s in zip(len_data, step_sizes)]\n",
    "\n",
    "        if 2 in labels:\n",
    "            repeat_count = 4\n",
    "        elif 3 in labels:\n",
    "            repeat_count = 3\n",
    "        elif 4 in labels:\n",
    "            repeat_count = 5\n",
    "        else:\n",
    "            repeat_count = 1\n",
    "        \n",
    "        for _ in range(repeat_count):\n",
    "            for i, sl in enumerate(reshaped_slices):\n",
    "                x_arrays[i] = np.vstack((x_arrays[i], sl))\n",
    "            y.append(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3666, 661, 2),\n",
       " (3666, 132, 1),\n",
       " (3666, 32, 10),\n",
       " (3666, 132, 1),\n",
       " (3666, 247, 1),\n",
       " (3666, 253, 4),\n",
       " (3666, 253, 1),\n",
       " (3666, 253, 1),\n",
       " (3666, 247, 6),\n",
       " (3666, 253, 1),\n",
       " (3666, 27, 1),\n",
       " (3666, 32, 6),\n",
       " (3666, 27, 3)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shapes = [x.shape for x in x_arrays]\n",
    "shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.2548107])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_arrays[9][495][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3666"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3666, 1), (3666, 66, 1))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(y)\n",
    "y_ = np.array([max(m) for m in y])\n",
    "y_.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch shapes: torch.Size([32, 661, 2]) torch.Size([32, 132, 1]) torch.Size([32, 32, 10]) torch.Size([32, 132, 1]) torch.Size([32, 247, 1]) torch.Size([32, 253, 4]) torch.Size([32, 253, 1]) torch.Size([32, 253, 1]) torch.Size([32, 247, 6]) torch.Size([32, 253, 1]) torch.Size([32, 27, 1]) torch.Size([32, 32, 6]) torch.Size([32, 27, 3]) torch.Size([32])\n",
      "Test batch shapes: torch.Size([32, 661, 2]) torch.Size([32, 132, 1]) torch.Size([32, 32, 10]) torch.Size([32, 132, 1]) torch.Size([32, 247, 1]) torch.Size([32, 253, 4]) torch.Size([32, 253, 1]) torch.Size([32, 253, 1]) torch.Size([32, 247, 6]) torch.Size([32, 253, 1]) torch.Size([32, 27, 1]) torch.Size([32, 32, 6]) torch.Size([32, 27, 3]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_arrays, y):\n",
    "        self.x0 = torch.tensor(x_arrays[0], dtype=torch.float32)\n",
    "        self.x1 = torch.tensor(x_arrays[1], dtype=torch.float32)\n",
    "        self.x2 = torch.tensor(x_arrays[2], dtype=torch.float32)\n",
    "        self.x3 = torch.tensor(x_arrays[3], dtype=torch.float32)\n",
    "        self.x4 = torch.tensor(x_arrays[4], dtype=torch.float32)\n",
    "        self.x5 = torch.tensor(x_arrays[5], dtype=torch.float32)\n",
    "        self.x6 = torch.tensor(x_arrays[6], dtype=torch.float32)\n",
    "        self.x7 = torch.tensor(x_arrays[7], dtype=torch.float32)\n",
    "        self.x8 = torch.tensor(x_arrays[8], dtype=torch.float32)\n",
    "        self.x9 = torch.tensor(x_arrays[9], dtype=torch.float32)\n",
    "        self.x10 = torch.tensor(x_arrays[10], dtype=torch.float32)\n",
    "        self.x11 = torch.tensor(x_arrays[11], dtype=torch.float32)\n",
    "        self.x12 = torch.tensor(x_arrays[12], dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long).squeeze()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.x0[idx], self.x1[idx], self.x2[idx], self.x3[idx], self.x4[idx],\n",
    "            self.x5[idx], self.x6[idx], self.x7[idx], self.x8[idx], self.x9[idx],\n",
    "            self.x10[idx], self.x11[idx], self.x12[idx], self.y[idx]\n",
    "        )\n",
    "\n",
    "dataset = CustomDataset(x_arrays, y_)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    (\n",
    "        x0_batch, x1_batch, x2_batch, x3_batch, x4_batch, \n",
    "        x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, \n",
    "        x10_batch, x11_batch, x12_batch, y_batch\n",
    "    ) = batch\n",
    "    print(\"Train batch shapes:\", x0_batch.shape, x1_batch.shape, x2_batch.shape, x3_batch.shape, \n",
    "          x4_batch.shape, x5_batch.shape, x6_batch.shape, x7_batch.shape, x8_batch.shape, \n",
    "          x9_batch.shape, x10_batch.shape, x11_batch.shape, x12_batch.shape, y_batch.shape)\n",
    "    break\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    (\n",
    "        x0_batch, x1_batch, x2_batch, x3_batch, x4_batch, \n",
    "        x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, \n",
    "        x10_batch, x11_batch, x12_batch, y_batch\n",
    "    ) = batch\n",
    "    print(\"Test batch shapes:\", x0_batch.shape, x1_batch.shape, x2_batch.shape, x3_batch.shape, \n",
    "          x4_batch.shape, x5_batch.shape, x6_batch.shape, x7_batch.shape, x8_batch.shape, \n",
    "          x9_batch.shape, x10_batch.shape, x11_batch.shape, x12_batch.shape, y_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CausalConv1D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, **kwargs):\n",
    "        super(CausalConv1D, self).__init__()\n",
    "        self.padding = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=self.padding, dilation=dilation, **kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x[:, :, :-self.padding]\n",
    "\n",
    "class BlockDiagonal(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_blocks):\n",
    "        super(BlockDiagonal, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_blocks = num_blocks\n",
    "\n",
    "        assert out_features % num_blocks == 0\n",
    "        \n",
    "        block_out_features = out_features // num_blocks\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.Linear(in_features, block_out_features)\n",
    "            for _ in range(num_blocks)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = [block(x) for block in self.blocks]\n",
    "        x = torch.cat(x, dim=-1)\n",
    "        return x\n",
    "\n",
    "class sLSTMBlock(nn.Module):\n",
    "    def __init__(self, input_size, head_size, num_heads, proj_factor=4/3):\n",
    "        super(sLSTMBlock, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = head_size * num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.proj_factor = proj_factor\n",
    "\n",
    "        assert proj_factor > 0\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(input_size)\n",
    "        self.causal_conv = CausalConv1D(1, 1, 4)\n",
    "\n",
    "        self.Wz = BlockDiagonal(input_size, self.hidden_size, num_heads)\n",
    "        self.Wi = BlockDiagonal(input_size, self.hidden_size, num_heads)\n",
    "        self.Wf = BlockDiagonal(input_size, self.hidden_size, num_heads)\n",
    "        self.Wo = BlockDiagonal(input_size, self.hidden_size, num_heads)\n",
    "\n",
    "        self.Rz = BlockDiagonal(self.hidden_size, self.hidden_size, num_heads)\n",
    "        self.Ri = BlockDiagonal(self.hidden_size, self.hidden_size, num_heads)\n",
    "        self.Rf = BlockDiagonal(self.hidden_size, self.hidden_size, num_heads)\n",
    "        self.Ro = BlockDiagonal(self.hidden_size, self.hidden_size, num_heads)\n",
    "\n",
    "        self.group_norm = nn.GroupNorm(num_heads, self.hidden_size)\n",
    "\n",
    "        self.up_proj_left = nn.Linear(self.hidden_size, int(self.hidden_size * proj_factor))\n",
    "        self.up_proj_right = nn.Linear(self.hidden_size, int(self.hidden_size * proj_factor))\n",
    "        self.down_proj = nn.Linear(int(self.hidden_size * proj_factor), input_size)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        assert x.size(-1) == self.input_size\n",
    "        h_prev, c_prev, n_prev, m_prev = prev_state\n",
    "\n",
    "        h_prev = h_prev\n",
    "        c_prev = c_prev\n",
    "        n_prev = n_prev\n",
    "        m_prev = m_prev\n",
    "        \n",
    "        x_norm = self.layer_norm(x)\n",
    "        x_conv = F.silu(self.causal_conv(x_norm.unsqueeze(1)).squeeze(1))\n",
    "\n",
    "        z = torch.tanh(self.Wz(x_norm) + self.Rz(h_prev))\n",
    "        o = torch.sigmoid(self.Wo(x_norm) + self.Ro(h_prev))\n",
    "        i_tilde = self.Wi(x_conv) + self.Ri(h_prev)\n",
    "        f_tilde = self.Wf(x_conv) + self.Rf(h_prev)\n",
    "\n",
    "        m_t = torch.max(f_tilde + m_prev, i_tilde)\n",
    "        i = torch.exp(i_tilde - m_t)\n",
    "        f = torch.exp(f_tilde + m_prev - m_t)\n",
    "\n",
    "        c_t = f * c_prev + i * z\n",
    "        n_t = f * n_prev + i\n",
    "        h_t = o * c_t / n_t\n",
    "\n",
    "        output = h_t\n",
    "        output_norm = self.group_norm(output)\n",
    "        output_left = self.up_proj_left(output_norm)\n",
    "        output_right = self.up_proj_right(output_norm)\n",
    "        output_gated = F.gelu(output_right)\n",
    "        output = output_left * output_gated\n",
    "        output = self.down_proj(output)\n",
    "        final_output = output + x\n",
    "\n",
    "        return final_output, (h_t, c_t, n_t, m_t)\n",
    "    \n",
    "class sLSTM(nn.Module):\n",
    "    # TODO: Add bias, dropout, bidirectional\n",
    "    def __init__(self, input_size, head_size, num_heads, num_layers=1, batch_first=False, proj_factor=4/3):\n",
    "        super(sLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = head_size * num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.proj_factor_slstm = proj_factor\n",
    "\n",
    "        self.layers = nn.ModuleList([sLSTMBlock(input_size, head_size, num_heads, proj_factor) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        assert x.ndim == 3\n",
    "        if self.batch_first: x = x.transpose(0, 1)\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "        \n",
    "        if state is not None:\n",
    "            state = torch.stack(list(state)).to(x.device)\n",
    "            assert state.ndim == 4\n",
    "            num_hidden, state_num_layers, state_batch_size, state_input_size = state.size()\n",
    "            assert num_hidden == 4\n",
    "            assert state_num_layers == self.num_layers\n",
    "            assert state_batch_size == batch_size\n",
    "            assert state_input_size == self.input_size\n",
    "            state = state.transpose(0, 1)\n",
    "        else:\n",
    "            state = torch.zeros(self.num_layers, 4, batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        output = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t]\n",
    "            for layer in range(self.num_layers):\n",
    "                x_t, state_tuple = self.layers[layer](x_t, tuple(state[layer].clone()))\n",
    "                state[layer] = torch.stack(list(state_tuple))\n",
    "            output.append(x_t)\n",
    "        \n",
    "        output = torch.stack(output)\n",
    "        if self.batch_first:\n",
    "            output = output.transpose(0, 1)\n",
    "        state = tuple(state.transpose(0, 1))\n",
    "        return output, state\n",
    "\n",
    "class mLSTMBlock(nn.Module):\n",
    "    def __init__(self, input_size, head_size, num_heads, proj_factor=2):\n",
    "        super(mLSTMBlock, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = head_size * num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.proj_factor = proj_factor\n",
    "\n",
    "        assert proj_factor > 0\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(input_size)\n",
    "        self.up_proj_left = nn.Linear(input_size, int(input_size * proj_factor))\n",
    "        self.up_proj_right = nn.Linear(input_size, self.hidden_size)\n",
    "        self.down_proj = nn.Linear(self.hidden_size, input_size)\n",
    "\n",
    "        self.causal_conv = CausalConv1D(1, 1, 4)\n",
    "        self.skip_connection = nn.Linear(int(input_size * proj_factor), self.hidden_size)\n",
    "\n",
    "        self.Wq = BlockDiagonal(int(input_size * proj_factor), self.hidden_size, num_heads)\n",
    "        self.Wk = BlockDiagonal(int(input_size * proj_factor), self.hidden_size, num_heads)\n",
    "        self.Wv = BlockDiagonal(int(input_size * proj_factor), self.hidden_size, num_heads)\n",
    "        self.Wi = nn.Linear(int(input_size * proj_factor), self.hidden_size)\n",
    "        self.Wf = nn.Linear(int(input_size * proj_factor), self.hidden_size)\n",
    "        self.Wo = nn.Linear(int(input_size * proj_factor), self.hidden_size)\n",
    "\n",
    "        self.group_norm = nn.GroupNorm(num_heads, self.hidden_size)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        h_prev, c_prev, n_prev, m_prev = prev_state\n",
    "\n",
    "        h_prev = h_prev\n",
    "        c_prev = c_prev\n",
    "        n_prev = n_prev\n",
    "        m_prev = m_prev\n",
    "        \n",
    "        assert x.size(-1) == self.input_size\n",
    "        x_norm = self.layer_norm(x)\n",
    "        x_up_left = self.up_proj_left(x_norm)\n",
    "        x_up_right = self.up_proj_right(x_norm)\n",
    "\n",
    "        x_conv = F.silu(self.causal_conv(x_up_left.unsqueeze(1)).squeeze(1))\n",
    "        x_skip = self.skip_connection(x_conv)\n",
    "\n",
    "        q = self.Wq(x_conv)\n",
    "        k = self.Wk(x_conv) / (self.head_size ** 0.5)\n",
    "        v = self.Wv(x_up_left)\n",
    "\n",
    "        i_tilde = self.Wi(x_conv)\n",
    "        f_tilde = self.Wf(x_conv)\n",
    "        o = torch.sigmoid(self.Wo(x_up_left))\n",
    "\n",
    "        m_t = torch.max(f_tilde + m_prev, i_tilde)\n",
    "        i = torch.exp(i_tilde - m_t)\n",
    "        f = torch.exp(f_tilde + m_prev - m_t)\n",
    "\n",
    "        c_t = f * c_prev + i * (v * k) # v @ k.T\n",
    "        n_t = f * n_prev + i * k\n",
    "        h_t = o * (c_t * q) / torch.max(torch.abs(n_t.T @ q), 1)[0] # o * (c @ q) / max{|n.T @ q|, 1}\n",
    "\n",
    "        output = h_t\n",
    "        output_norm = self.group_norm(output)\n",
    "        output = output_norm + x_skip\n",
    "        output = output * F.silu(x_up_right)\n",
    "        output = self.down_proj(output)\n",
    "        final_output = output + x\n",
    "\n",
    "        return final_output, (h_t, c_t, n_t, m_t)\n",
    "    \n",
    "class mLSTM(nn.Module):\n",
    "    # TODO: Add bias, dropout, bidirectional\n",
    "    def __init__(self, input_size, head_size, num_heads, num_layers=1, batch_first=False, proj_factor=2):\n",
    "        super(mLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = head_size * num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.proj_factor_slstm = proj_factor\n",
    "\n",
    "        self.layers = nn.ModuleList([mLSTMBlock(input_size, head_size, num_heads, proj_factor) for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        assert x.ndim == 3\n",
    "        if self.batch_first: x = x.transpose(0, 1)\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "        \n",
    "        if state is not None:\n",
    "            state = torch.stack(list(state))\n",
    "            assert state.ndim == 4\n",
    "            num_hidden, state_num_layers, state_batch_size, state_input_size = state.size()\n",
    "            assert num_hidden == 4\n",
    "            assert state_num_layers == self.num_layers\n",
    "            assert state_batch_size == batch_size\n",
    "            assert state_input_size == self.input_size\n",
    "            state = state.transpose(0, 1)\n",
    "        else:\n",
    "            state = torch.zeros(self.num_layers, 4, batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        output = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t]\n",
    "            for layer in range(self.num_layers):\n",
    "                x_t, state_tuple = self.layers[layer](x_t, tuple(state[layer].clone()))\n",
    "                state[layer] = torch.stack(list(state_tuple))\n",
    "            output.append(x_t)\n",
    "        \n",
    "        output = torch.stack(output)\n",
    "        if self.batch_first:\n",
    "            output = output.transpose(0, 1)\n",
    "        state = tuple(state.transpose(0, 1))\n",
    "        return output, state\n",
    "\n",
    "\n",
    "\n",
    "class xLSTM(nn.Module):\n",
    "    # Added dropout and bias options\n",
    "    def __init__(self, input_size, head_size, num_heads, layers, batch_first=False, \n",
    "                 proj_factor_slstm=4/3, proj_factor_mlstm=2, dropout=0.0):\n",
    "        super(xLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.head_size = head_size\n",
    "        self.hidden_size = head_size * num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.batch_first = batch_first\n",
    "        self.proj_factor_slstm = proj_factor_slstm\n",
    "        self.proj_factor_mlstm = proj_factor_mlstm\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for layer_type in layers:\n",
    "            if layer_type == 's':\n",
    "                layer = sLSTMBlock(input_size, head_size, num_heads, proj_factor_slstm)\n",
    "            elif layer_type == 'm':\n",
    "                layer = mLSTMBlock(input_size, head_size, num_heads, proj_factor_mlstm)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid layer type: {layer_type}. Choose 's' for sLSTM or 'm' for mLSTM.\")\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        self.dropout_layer = nn.Dropout(dropout) if dropout > 0 else None\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        assert x.ndim == 3\n",
    "        if self.batch_first: \n",
    "            x = x.transpose(0, 1)\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "        \n",
    "        if state is not None:\n",
    "            state = torch.stack(list(state))\n",
    "            assert state.ndim == 4\n",
    "            num_hidden, state_num_layers, state_batch_size, state_input_size = state.size()\n",
    "            assert num_hidden == 4\n",
    "            assert state_num_layers == self.num_layers\n",
    "            assert state_batch_size == batch_size\n",
    "            assert state_input_size == self.input_size\n",
    "            state = state.transpose(0, 1)\n",
    "        else:\n",
    "            state = torch.zeros(self.num_layers, 4, batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        output = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t]\n",
    "            for layer in range(self.num_layers):\n",
    "                x_t, state_tuple = self.layers[layer](x_t, tuple(state[layer].clone()))\n",
    "                state[layer] = torch.stack(list(state_tuple))\n",
    "                if self.dropout_layer is not None:\n",
    "                    x_t = self.dropout_layer(x_t)\n",
    "            output.append(x_t)\n",
    "        \n",
    "        output = torch.stack(output)\n",
    "        if self.batch_first:\n",
    "            output = output.transpose(0, 1)\n",
    "        state = tuple(state.transpose(0, 1))\n",
    "        return output, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm_layers): ModuleList(\n",
      "    (0): xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=2, out_features=4, bias=True)\n",
      "          (up_proj_right): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=2, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=4, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=4, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=4, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=4, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=4, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (1): xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=1, out_features=2, bias=True)\n",
      "          (up_proj_right): Linear(in_features=1, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=1, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (2): xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=10, out_features=20, bias=True)\n",
      "          (up_proj_right): Linear(in_features=10, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=10, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=20, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=20, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=20, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=20, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=20, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=20, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=20, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (3-4): 2 x xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=1, out_features=2, bias=True)\n",
      "          (up_proj_right): Linear(in_features=1, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=1, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (5): xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=4, out_features=8, bias=True)\n",
      "          (up_proj_right): Linear(in_features=4, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=4, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=8, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=8, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=8, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=8, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=8, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=8, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=8, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (6-7): 2 x xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=1, out_features=2, bias=True)\n",
      "          (up_proj_right): Linear(in_features=1, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=1, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (8): xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=6, out_features=12, bias=True)\n",
      "          (up_proj_right): Linear(in_features=6, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=6, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=12, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=12, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=12, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (9-10): 2 x xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=1, out_features=2, bias=True)\n",
      "          (up_proj_right): Linear(in_features=1, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=1, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=2, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=2, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (11): xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=6, out_features=12, bias=True)\n",
      "          (up_proj_right): Linear(in_features=6, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=6, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=12, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=12, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=12, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=12, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (12): xLSTM(\n",
      "      (layers): ModuleList(\n",
      "        (0): mLSTMBlock(\n",
      "          (layer_norm): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "          (up_proj_left): Linear(in_features=3, out_features=6, bias=True)\n",
      "          (up_proj_right): Linear(in_features=3, out_features=16, bias=True)\n",
      "          (down_proj): Linear(in_features=16, out_features=3, bias=True)\n",
      "          (causal_conv): CausalConv1D(\n",
      "            (conv): Conv1d(1, 1, kernel_size=(4,), stride=(1,), padding=(3,))\n",
      "          )\n",
      "          (skip_connection): Linear(in_features=6, out_features=16, bias=True)\n",
      "          (Wq): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wk): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wv): BlockDiagonal(\n",
      "            (blocks): ModuleList(\n",
      "              (0): Linear(in_features=6, out_features=16, bias=True)\n",
      "            )\n",
      "          )\n",
      "          (Wi): Linear(in_features=6, out_features=16, bias=True)\n",
      "          (Wf): Linear(in_features=6, out_features=16, bias=True)\n",
      "          (Wo): Linear(in_features=6, out_features=16, bias=True)\n",
      "          (group_norm): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=38, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=5, bias=True)\n",
      "    (3): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_shapes, hidden_sizes, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            xLSTM(input_shapes[i][2], hidden_sizes[i], layers=\"m\", num_heads=1, batch_first=True, dropout=0.2)\n",
    "            for i in range(13)\n",
    "        ])\n",
    "\n",
    "        self.flatten_size = self.get_flatten_size(input_shapes)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flatten_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def get_flatten_size(self, input_shapes):\n",
    "        with torch.no_grad():\n",
    "            x = [torch.zeros(1, input_shapes[i][1], input_shapes[i][2]) for i in range(13)]\n",
    "         \n",
    "            outputs = [self.lstm_layers[i](x[i])[0][:, -1, :].view(1, -1) for i in range(13)]\n",
    "          \n",
    "            flat_sizes = [output.shape[1] for output in outputs]\n",
    "            return sum(flat_sizes)\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        \n",
    "        lstm_outputs = [self.lstm_layers[i](inputs[i])[0][:, -1, :] for i in range(13)]\n",
    "\n",
    "        out = torch.cat(lstm_outputs, dim=1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "hidden_sizes = [16 for _ in range(13)]\n",
    "input_shapes = [\n",
    "    (3666, 661, 2),\n",
    "    (3666, 132, 1),\n",
    "    (3666, 32, 10),\n",
    "    (3666, 132, 1),\n",
    "    (3666, 247, 1),\n",
    "    (3666, 253, 4),\n",
    "    (3666, 253, 1),\n",
    "    (3666, 253, 1),\n",
    "    (3666, 247, 6),\n",
    "    (3666, 253, 1),\n",
    "    (3666, 27, 1),\n",
    "    (3666, 32, 6),\n",
    "    (3666, 27, 3)\n",
    "]\n",
    "num_classes = 5\n",
    "\n",
    "model = LSTMModel(input_shapes, hidden_sizes, num_classes).to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3382, 2.3500, 3.5941, 0.8313, 7.3320])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Assuming y is a NumPy array or can be converted to one\n",
    "\n",
    "\n",
    "num_samples_per_class = [np.sum(y_ == i) for i in range(5)]\n",
    "\n",
    "total_samples = sum(num_samples_per_class)\n",
    "class_weights = [total_samples / (5 * num_samples) for num_samples in num_samples_per_class]\n",
    "\n",
    "weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ModelCheckpoint:\n",
    "    def __init__(self, filepath, monitor='val_loss', mode='min'):\n",
    "        self.filepath = filepath\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.best_score = None\n",
    "        self.best_state_dict = None\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.best_score = float('inf')\n",
    "        else:\n",
    "            self.best_score = float('-inf')\n",
    "\n",
    "    def __call__(self, score, model_state_dict):\n",
    "        if (self.mode == 'min' and score < self.best_score) or (self.mode == 'max' and score > self.best_score):\n",
    "            print(f\"Saving model with {self.monitor}: {score}\")\n",
    "            self.best_score = score\n",
    "            self.best_state_dict = model_state_dict\n",
    "            torch.save(model_state_dict, self.filepath)\n",
    "\n",
    "    def get_best_state_dict(self):\n",
    "        return self.best_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# criterion = nn.CrossEntropyLoss(weight=weights)  # Assuming you're using CrossEntropyLoss for classification\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\",patience=30,factor=0.1)\n",
    "# # scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[150,200], gamma=0.5)\n",
    "# checkpoint = ModelCheckpoint(filepath='best_model.pth', monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\",patience=5,factor=0.1)\n",
    "checkpoint = ModelCheckpoint(filepath='best_mlstm_model.pth', monitor='val_loss', mode='min')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 10, Training Loss: 1.606615388393402, Training Accuracy: 15.312500000000002%\n",
      "Epoch 1, Batch 20, Training Loss: 1.590995454788208, Training Accuracy: 22.1875%\n",
      "Epoch 1, Batch 30, Training Loss: 1.585866101582845, Training Accuracy: 25.833333333333336%\n",
      "Epoch 1, Batch 40, Training Loss: 1.576762041449547, Training Accuracy: 28.4375%\n",
      "Epoch 1, Batch 50, Training Loss: 1.568616440296173, Training Accuracy: 30.562499999999996%\n",
      "Epoch 1, Batch 60, Training Loss: 1.5559734463691712, Training Accuracy: 32.55208333333333%\n",
      "Epoch 1, Batch 70, Training Loss: 1.543296480178833, Training Accuracy: 33.705357142857146%\n",
      "Epoch 1, Batch 80, Training Loss: 1.530800649523735, Training Accuracy: 35.2734375%\n",
      "Epoch 1, Batch 90, Training Loss: 1.5187525775697497, Training Accuracy: 36.388888888888886%\n",
      "Epoch 1, Validation Loss: 1.355296518491662, Validation Accuracy: 52.58855585831063%\n",
      "Epoch 1: Adam lr 0.0010\n",
      "Epoch 2, Batch 10, Training Loss: 1.3370459794998169, Training Accuracy: 54.6875%\n",
      "Epoch 2, Batch 20, Training Loss: 1.327398133277893, Training Accuracy: 57.49999999999999%\n",
      "Epoch 2, Batch 30, Training Loss: 1.3300797740618389, Training Accuracy: 58.75%\n",
      "Epoch 2, Batch 40, Training Loss: 1.3198997646570205, Training Accuracy: 58.359375%\n",
      "Epoch 2, Batch 50, Training Loss: 1.313309621810913, Training Accuracy: 58.12500000000001%\n",
      "Epoch 2, Batch 60, Training Loss: 1.3062519530455272, Training Accuracy: 57.65625%\n",
      "Epoch 2, Batch 70, Training Loss: 1.3042838777814592, Training Accuracy: 58.392857142857146%\n",
      "Epoch 2, Batch 80, Training Loss: 1.2964321956038476, Training Accuracy: 60.07812500000001%\n",
      "Epoch 2, Batch 90, Training Loss: 1.287527867158254, Training Accuracy: 61.28472222222222%\n",
      "Epoch 2, Validation Loss: 1.15392353742019, Validation Accuracy: 73.56948228882834%\n",
      "Epoch 2: Adam lr 0.0010\n",
      "Epoch 3, Batch 10, Training Loss: 1.181607472896576, Training Accuracy: 69.0625%\n",
      "Epoch 3, Batch 20, Training Loss: 1.1644179761409759, Training Accuracy: 67.34375%\n",
      "Epoch 3, Batch 30, Training Loss: 1.1555450916290284, Training Accuracy: 70.41666666666667%\n",
      "Epoch 3, Batch 40, Training Loss: 1.156534704566002, Training Accuracy: 70.546875%\n",
      "Epoch 3, Batch 50, Training Loss: 1.1506161189079285, Training Accuracy: 71.25%\n",
      "Epoch 3, Batch 60, Training Loss: 1.1475456794102987, Training Accuracy: 71.09375%\n",
      "Epoch 3, Batch 70, Training Loss: 1.1435915316854204, Training Accuracy: 70.98214285714286%\n",
      "Epoch 3, Batch 80, Training Loss: 1.1371923014521599, Training Accuracy: 71.796875%\n",
      "Epoch 3, Batch 90, Training Loss: 1.133946128686269, Training Accuracy: 71.77083333333333%\n",
      "Epoch 3, Validation Loss: 1.064871355243351, Validation Accuracy: 80.92643051771117%\n",
      "Epoch 3: Adam lr 0.0010\n",
      "Epoch 4, Batch 10, Training Loss: 1.083176702260971, Training Accuracy: 76.5625%\n",
      "Epoch 4, Batch 20, Training Loss: 1.0731640666723252, Training Accuracy: 78.59375%\n",
      "Epoch 4, Batch 30, Training Loss: 1.074553507566452, Training Accuracy: 77.5%\n",
      "Epoch 4, Batch 40, Training Loss: 1.0803926333785057, Training Accuracy: 76.875%\n",
      "Epoch 4, Batch 50, Training Loss: 1.0780377221107482, Training Accuracy: 76.3125%\n",
      "Epoch 4, Batch 60, Training Loss: 1.0769686222076416, Training Accuracy: 76.77083333333333%\n",
      "Epoch 4, Batch 70, Training Loss: 1.0742760913712637, Training Accuracy: 77.32142857142857%\n",
      "Epoch 4, Batch 80, Training Loss: 1.0747518934309483, Training Accuracy: 77.5%\n",
      "Epoch 4, Batch 90, Training Loss: 1.070186753405465, Training Accuracy: 77.8125%\n",
      "Epoch 4, Validation Loss: 1.0296363571415776, Validation Accuracy: 84.60490463215258%\n",
      "Epoch 4: Adam lr 0.0010\n",
      "Epoch 5, Batch 10, Training Loss: 1.0469915449619294, Training Accuracy: 81.5625%\n",
      "Epoch 5, Batch 20, Training Loss: 1.0443428486585618, Training Accuracy: 80.9375%\n",
      "Epoch 5, Batch 30, Training Loss: 1.0431577682495117, Training Accuracy: 81.14583333333333%\n",
      "Epoch 5, Batch 40, Training Loss: 1.0442710235714912, Training Accuracy: 81.015625%\n",
      "Epoch 5, Batch 50, Training Loss: 1.0418374061584472, Training Accuracy: 81.625%\n",
      "Epoch 5, Batch 60, Training Loss: 1.040202964345614, Training Accuracy: 81.45833333333333%\n",
      "Epoch 5, Batch 70, Training Loss: 1.038565559898104, Training Accuracy: 82.00892857142857%\n",
      "Epoch 5, Batch 80, Training Loss: 1.0384734638035298, Training Accuracy: 82.4609375%\n",
      "Epoch 5, Batch 90, Training Loss: 1.0355556547641753, Training Accuracy: 82.46527777777779%\n",
      "Epoch 5, Validation Loss: 1.0112163916878079, Validation Accuracy: 87.60217983651226%\n",
      "Epoch 5: Adam lr 0.0010\n",
      "Epoch 6, Batch 10, Training Loss: 1.0118323147296906, Training Accuracy: 85.9375%\n",
      "Epoch 6, Batch 20, Training Loss: 1.0317416459321975, Training Accuracy: 84.21875%\n",
      "Epoch 6, Batch 30, Training Loss: 1.0275961975256602, Training Accuracy: 84.16666666666667%\n",
      "Epoch 6, Batch 40, Training Loss: 1.0218400582671165, Training Accuracy: 84.0625%\n",
      "Epoch 6, Batch 50, Training Loss: 1.0210263168811797, Training Accuracy: 83.8125%\n",
      "Epoch 6, Batch 60, Training Loss: 1.0231210321187973, Training Accuracy: 84.16666666666667%\n",
      "Epoch 6, Batch 70, Training Loss: 1.0233714384692056, Training Accuracy: 83.97321428571428%\n",
      "Epoch 6, Batch 80, Training Loss: 1.0231576897203922, Training Accuracy: 84.140625%\n",
      "Epoch 6, Batch 90, Training Loss: 1.0273445884386698, Training Accuracy: 83.78472222222221%\n",
      "Epoch 6, Validation Loss: 0.9975852240686831, Validation Accuracy: 87.19346049046321%\n",
      "Epoch 6: Adam lr 0.0010\n",
      "Epoch 7, Batch 10, Training Loss: 1.0053855776786804, Training Accuracy: 86.25%\n",
      "Epoch 7, Batch 20, Training Loss: 1.0200073271989822, Training Accuracy: 84.84375%\n",
      "Epoch 7, Batch 30, Training Loss: 1.0127712527910868, Training Accuracy: 84.79166666666667%\n",
      "Epoch 7, Batch 40, Training Loss: 1.0131582766771317, Training Accuracy: 84.609375%\n",
      "Epoch 7, Batch 50, Training Loss: 1.0091049754619599, Training Accuracy: 85.1875%\n",
      "Epoch 7, Batch 60, Training Loss: 1.010963436961174, Training Accuracy: 85.52083333333333%\n",
      "Epoch 7, Batch 70, Training Loss: 1.012580852849143, Training Accuracy: 85.08928571428571%\n",
      "Epoch 7, Batch 80, Training Loss: 1.0134891465306282, Training Accuracy: 84.9609375%\n",
      "Epoch 7, Batch 90, Training Loss: 1.0114406605561574, Training Accuracy: 85.24305555555556%\n",
      "Epoch 7, Validation Loss: 0.9901423661605172, Validation Accuracy: 90.32697547683924%\n",
      "Epoch 7: Adam lr 0.0010\n",
      "Epoch 8, Batch 10, Training Loss: 0.9870384752750396, Training Accuracy: 88.125%\n",
      "Epoch 8, Batch 20, Training Loss: 0.9856446355581283, Training Accuracy: 88.90625%\n",
      "Epoch 8, Batch 30, Training Loss: 0.9856225828329722, Training Accuracy: 88.64583333333333%\n",
      "Epoch 8, Batch 40, Training Loss: 0.9848419561982155, Training Accuracy: 88.515625%\n",
      "Epoch 8, Batch 50, Training Loss: 0.9893472003936767, Training Accuracy: 88.625%\n",
      "Epoch 8, Batch 60, Training Loss: 0.9897817413012187, Training Accuracy: 88.38541666666667%\n",
      "Epoch 8, Batch 70, Training Loss: 0.9925408269677843, Training Accuracy: 88.125%\n",
      "Epoch 8, Batch 80, Training Loss: 0.9909750439226628, Training Accuracy: 87.96875%\n",
      "Epoch 8, Batch 90, Training Loss: 0.9928764786985186, Training Accuracy: 87.8125%\n",
      "Epoch 8, Validation Loss: 0.9854031982629196, Validation Accuracy: 90.87193460490464%\n",
      "Epoch 8: Adam lr 0.0010\n",
      "Epoch 9, Batch 10, Training Loss: 0.9966537237167359, Training Accuracy: 90.0%\n",
      "Epoch 9, Batch 20, Training Loss: 0.9944168239831924, Training Accuracy: 88.125%\n",
      "Epoch 9, Batch 30, Training Loss: 0.9899946908156078, Training Accuracy: 88.33333333333333%\n",
      "Epoch 9, Batch 40, Training Loss: 0.9917544767260551, Training Accuracy: 88.515625%\n",
      "Epoch 9, Batch 50, Training Loss: 0.9912452781200409, Training Accuracy: 88.4375%\n",
      "Epoch 9, Batch 60, Training Loss: 0.9882398933172226, Training Accuracy: 88.75%\n",
      "Epoch 9, Batch 70, Training Loss: 0.9882019996643067, Training Accuracy: 88.25892857142857%\n",
      "Epoch 9, Batch 80, Training Loss: 0.9905529536306859, Training Accuracy: 88.0078125%\n",
      "Epoch 9, Batch 90, Training Loss: 0.9901045282681783, Training Accuracy: 88.33333333333333%\n",
      "Epoch 9, Validation Loss: 0.9724391387856525, Validation Accuracy: 89.64577656675749%\n",
      "Epoch 9: Adam lr 0.0010\n",
      "Epoch 10, Batch 10, Training Loss: 0.9991769134998322, Training Accuracy: 88.125%\n",
      "Epoch 10, Batch 20, Training Loss: 0.9901897877454757, Training Accuracy: 88.28125%\n",
      "Epoch 10, Batch 30, Training Loss: 1.0019165774186451, Training Accuracy: 87.8125%\n",
      "Epoch 10, Batch 40, Training Loss: 0.9964329689741135, Training Accuracy: 88.046875%\n",
      "Epoch 10, Batch 50, Training Loss: 0.9943787658214569, Training Accuracy: 88.375%\n",
      "Epoch 10, Batch 60, Training Loss: 0.9915576706329982, Training Accuracy: 88.85416666666667%\n",
      "Epoch 10, Batch 70, Training Loss: 0.9885675915649959, Training Accuracy: 89.01785714285714%\n",
      "Epoch 10, Batch 80, Training Loss: 0.9856923282146454, Training Accuracy: 89.2578125%\n",
      "Epoch 10, Batch 90, Training Loss: 0.9879007273250155, Training Accuracy: 89.0625%\n",
      "Epoch 10, Validation Loss: 0.9713373987571053, Validation Accuracy: 90.05449591280654%\n",
      "Epoch 10: Adam lr 0.0010\n",
      "Epoch 11, Batch 10, Training Loss: 1.0021231114864348, Training Accuracy: 85.0%\n",
      "Epoch 11, Batch 20, Training Loss: 0.9837756097316742, Training Accuracy: 88.28125%\n",
      "Epoch 11, Batch 30, Training Loss: 0.9890068451563517, Training Accuracy: 88.125%\n",
      "Epoch 11, Batch 40, Training Loss: 0.9859120696783066, Training Accuracy: 88.90625%\n",
      "Epoch 11, Batch 50, Training Loss: 0.9799481630325317, Training Accuracy: 89.5625%\n",
      "Epoch 11, Batch 60, Training Loss: 0.9781898587942124, Training Accuracy: 89.6875%\n",
      "Epoch 11, Batch 70, Training Loss: 0.9787059315613338, Training Accuracy: 89.64285714285715%\n",
      "Epoch 11, Batch 80, Training Loss: 0.9747773744165897, Training Accuracy: 90.0390625%\n",
      "Epoch 11, Batch 90, Training Loss: 0.9732875062359704, Training Accuracy: 90.34722222222223%\n",
      "Epoch 11, Validation Loss: 0.9699151230895001, Validation Accuracy: 93.46049046321527%\n",
      "Epoch 11: Adam lr 0.0010\n",
      "Epoch 12, Batch 10, Training Loss: 1.0083553433418273, Training Accuracy: 89.375%\n",
      "Epoch 12, Batch 20, Training Loss: 0.9821500360965729, Training Accuracy: 90.9375%\n",
      "Epoch 12, Batch 30, Training Loss: 0.9771005868911743, Training Accuracy: 90.625%\n",
      "Epoch 12, Batch 40, Training Loss: 0.9699679717421532, Training Accuracy: 91.015625%\n",
      "Epoch 12, Batch 50, Training Loss: 0.9675313520431519, Training Accuracy: 91.25%\n",
      "Epoch 12, Batch 60, Training Loss: 0.9668311913808186, Training Accuracy: 91.35416666666667%\n",
      "Epoch 12, Batch 70, Training Loss: 0.9682199622903551, Training Accuracy: 91.33928571428571%\n",
      "Epoch 12, Batch 80, Training Loss: 0.9696223683655262, Training Accuracy: 91.2890625%\n",
      "Epoch 12, Batch 90, Training Loss: 0.969009393453598, Training Accuracy: 91.42361111111111%\n",
      "Epoch 12, Validation Loss: 0.962409838386204, Validation Accuracy: 94.6866485013624%\n",
      "Epoch 12: Adam lr 0.0010\n",
      "Epoch 13, Batch 10, Training Loss: 0.9617694795131684, Training Accuracy: 92.5%\n",
      "Epoch 13, Batch 20, Training Loss: 0.9675706595182418, Training Accuracy: 91.875%\n",
      "Epoch 13, Batch 30, Training Loss: 0.9633590201536815, Training Accuracy: 92.39583333333333%\n",
      "Epoch 13, Batch 40, Training Loss: 0.9572253733873367, Training Accuracy: 93.046875%\n",
      "Epoch 13, Batch 50, Training Loss: 0.9598236405849456, Training Accuracy: 92.5%\n",
      "Epoch 13, Batch 60, Training Loss: 0.9653621623913448, Training Accuracy: 92.34375%\n",
      "Epoch 13, Batch 70, Training Loss: 0.9664565980434418, Training Accuracy: 92.45535714285714%\n",
      "Epoch 13, Batch 80, Training Loss: 0.9649483323097229, Training Accuracy: 92.5390625%\n",
      "Epoch 13, Batch 90, Training Loss: 0.9628763801521725, Training Accuracy: 92.70833333333334%\n",
      "Epoch 13, Validation Loss: 0.9570529098096101, Validation Accuracy: 93.59673024523161%\n",
      "Epoch 13: Adam lr 0.0010\n",
      "Epoch 14, Batch 10, Training Loss: 0.9512609481811524, Training Accuracy: 93.75%\n",
      "Epoch 14, Batch 20, Training Loss: 0.9493147790431976, Training Accuracy: 93.90625%\n",
      "Epoch 14, Batch 30, Training Loss: 0.9564714948336284, Training Accuracy: 93.22916666666666%\n",
      "Epoch 14, Batch 40, Training Loss: 0.9622251838445663, Training Accuracy: 92.578125%\n",
      "Epoch 14, Batch 50, Training Loss: 0.9654397785663604, Training Accuracy: 92.25%\n",
      "Epoch 14, Batch 60, Training Loss: 0.9648096452156703, Training Accuracy: 92.5%\n",
      "Epoch 14, Batch 70, Training Loss: 0.9608679473400116, Training Accuracy: 93.125%\n",
      "Epoch 14, Batch 80, Training Loss: 0.9588638231158256, Training Accuracy: 93.1640625%\n",
      "Epoch 14, Batch 90, Training Loss: 0.9599376254611545, Training Accuracy: 93.02083333333333%\n",
      "Epoch 14, Validation Loss: 0.9585099505341571, Validation Accuracy: 94.4141689373297%\n",
      "Epoch 14: Adam lr 0.0010\n",
      "Epoch 15, Batch 10, Training Loss: 0.9757255136966705, Training Accuracy: 94.375%\n",
      "Epoch 15, Batch 20, Training Loss: 0.9674523115158081, Training Accuracy: 93.125%\n",
      "Epoch 15, Batch 30, Training Loss: 0.9608456194400787, Training Accuracy: 93.02083333333333%\n",
      "Epoch 15, Batch 40, Training Loss: 0.9625288873910904, Training Accuracy: 92.734375%\n",
      "Epoch 15, Batch 50, Training Loss: 0.9580945575237274, Training Accuracy: 93.25%\n",
      "Epoch 15, Batch 60, Training Loss: 0.9613822360833486, Training Accuracy: 92.91666666666667%\n",
      "Epoch 15, Batch 70, Training Loss: 0.9597190414156233, Training Accuracy: 93.21428571428572%\n",
      "Epoch 15, Batch 80, Training Loss: 0.9570576891303062, Training Accuracy: 93.3203125%\n",
      "Epoch 15, Batch 90, Training Loss: 0.955839231941435, Training Accuracy: 93.57638888888889%\n",
      "Epoch 15, Validation Loss: 0.9584647209747977, Validation Accuracy: 93.73297002724796%\n",
      "Epoch 15: Adam lr 0.0010\n",
      "Epoch 16, Batch 10, Training Loss: 0.9589391350746155, Training Accuracy: 90.3125%\n",
      "Epoch 16, Batch 20, Training Loss: 0.9478538751602172, Training Accuracy: 93.125%\n",
      "Epoch 16, Batch 30, Training Loss: 0.9506953676541646, Training Accuracy: 93.4375%\n",
      "Epoch 16, Batch 40, Training Loss: 0.9536186918616295, Training Accuracy: 93.203125%\n",
      "Epoch 16, Batch 50, Training Loss: 0.9583759617805481, Training Accuracy: 92.75%\n",
      "Epoch 16, Batch 60, Training Loss: 0.9593134760856629, Training Accuracy: 92.65625%\n",
      "Epoch 16, Batch 70, Training Loss: 0.9574991864817483, Training Accuracy: 92.90178571428571%\n",
      "Epoch 16, Batch 80, Training Loss: 0.9566409178078175, Training Accuracy: 93.0859375%\n",
      "Epoch 16, Batch 90, Training Loss: 0.9574840174780952, Training Accuracy: 93.22916666666666%\n",
      "Epoch 16, Validation Loss: 0.9520711665568145, Validation Accuracy: 94.82288828337875%\n",
      "Epoch 16: Adam lr 0.0010\n",
      "Epoch 17, Batch 10, Training Loss: 0.951724511384964, Training Accuracy: 94.375%\n",
      "Epoch 17, Batch 20, Training Loss: 0.954854816198349, Training Accuracy: 93.90625%\n",
      "Epoch 17, Batch 30, Training Loss: 0.9500808874766032, Training Accuracy: 94.375%\n",
      "Epoch 17, Batch 40, Training Loss: 0.9533644825220108, Training Accuracy: 93.515625%\n",
      "Epoch 17, Batch 50, Training Loss: 0.9548193371295929, Training Accuracy: 93.4375%\n",
      "Epoch 17, Batch 60, Training Loss: 0.9564396142959595, Training Accuracy: 93.64583333333333%\n",
      "Epoch 17, Batch 70, Training Loss: 0.9546455272606441, Training Accuracy: 93.75%\n",
      "Epoch 17, Batch 80, Training Loss: 0.9556310780346393, Training Accuracy: 93.671875%\n",
      "Epoch 17, Batch 90, Training Loss: 0.9586068133513133, Training Accuracy: 93.54166666666667%\n",
      "Epoch 17, Validation Loss: 0.9701926086259924, Validation Accuracy: 91.82561307901908%\n",
      "Epoch 17: Adam lr 0.0010\n",
      "Epoch 18, Batch 10, Training Loss: 0.957111793756485, Training Accuracy: 91.5625%\n",
      "Epoch 18, Batch 20, Training Loss: 0.9516233235597611, Training Accuracy: 93.28125%\n",
      "Epoch 18, Batch 30, Training Loss: 0.952845448255539, Training Accuracy: 93.33333333333333%\n",
      "Epoch 18, Batch 40, Training Loss: 0.9553144305944443, Training Accuracy: 93.828125%\n",
      "Epoch 18, Batch 50, Training Loss: 0.955896121263504, Training Accuracy: 93.8125%\n",
      "Epoch 18, Batch 60, Training Loss: 0.9531705816586812, Training Accuracy: 93.90625%\n",
      "Epoch 18, Batch 70, Training Loss: 0.9570968338421413, Training Accuracy: 93.48214285714286%\n",
      "Epoch 18, Batch 80, Training Loss: 0.9556231558322906, Training Accuracy: 93.6328125%\n",
      "Epoch 18, Batch 90, Training Loss: 0.9561726053555807, Training Accuracy: 93.68055555555556%\n",
      "Epoch 18, Validation Loss: 0.9566666121068208, Validation Accuracy: 94.4141689373297%\n",
      "Epoch 18: Adam lr 0.0010\n",
      "Epoch 19, Batch 10, Training Loss: 0.9338882803916931, Training Accuracy: 95.9375%\n",
      "Epoch 19, Batch 20, Training Loss: 0.9546647191047668, Training Accuracy: 94.6875%\n",
      "Epoch 19, Batch 30, Training Loss: 0.9502929985523224, Training Accuracy: 94.58333333333333%\n",
      "Epoch 19, Batch 40, Training Loss: 0.9494020149111748, Training Accuracy: 94.765625%\n",
      "Epoch 19, Batch 50, Training Loss: 0.9518899917602539, Training Accuracy: 94.4375%\n",
      "Epoch 19, Batch 60, Training Loss: 0.9494301537672679, Training Accuracy: 94.6875%\n",
      "Epoch 19, Batch 70, Training Loss: 0.952033155305045, Training Accuracy: 94.33035714285715%\n",
      "Epoch 19, Batch 80, Training Loss: 0.9499030210077762, Training Accuracy: 94.609375%\n",
      "Epoch 19, Batch 90, Training Loss: 0.9510347922643025, Training Accuracy: 94.54861111111111%\n",
      "Epoch 19, Validation Loss: 0.9532968220503434, Validation Accuracy: 94.55040871934605%\n",
      "Epoch 19: Adam lr 0.0010\n",
      "Epoch 20, Batch 10, Training Loss: 0.943648636341095, Training Accuracy: 94.375%\n",
      "Epoch 20, Batch 20, Training Loss: 0.945515587925911, Training Accuracy: 94.6875%\n",
      "Epoch 20, Batch 30, Training Loss: 0.9416207015514374, Training Accuracy: 94.6875%\n",
      "Epoch 20, Batch 40, Training Loss: 0.9447653725743294, Training Accuracy: 94.609375%\n",
      "Epoch 20, Batch 50, Training Loss: 0.9468296301364899, Training Accuracy: 94.3125%\n",
      "Epoch 20, Batch 60, Training Loss: 0.9476478735605876, Training Accuracy: 94.42708333333333%\n",
      "Epoch 20, Batch 70, Training Loss: 0.9513548135757446, Training Accuracy: 93.75%\n",
      "Epoch 20, Batch 80, Training Loss: 0.9520079724490642, Training Accuracy: 93.7109375%\n",
      "Epoch 20, Batch 90, Training Loss: 0.9518183271090189, Training Accuracy: 93.64583333333333%\n",
      "Epoch 20, Validation Loss: 0.9550902869390405, Validation Accuracy: 94.141689373297%\n",
      "Epoch 20: Adam lr 0.0010\n",
      "Epoch 21, Batch 10, Training Loss: 0.9420100510120392, Training Accuracy: 94.6875%\n",
      "Epoch 21, Batch 20, Training Loss: 0.9449996083974839, Training Accuracy: 94.0625%\n",
      "Epoch 21, Batch 30, Training Loss: 0.9465519229571024, Training Accuracy: 94.47916666666667%\n",
      "Epoch 21, Batch 40, Training Loss: 0.9486256331205368, Training Accuracy: 94.21875%\n",
      "Epoch 21, Batch 50, Training Loss: 0.9458497583866119, Training Accuracy: 94.6875%\n",
      "Epoch 21, Batch 60, Training Loss: 0.9470120181639989, Training Accuracy: 94.53125%\n",
      "Epoch 21, Batch 70, Training Loss: 0.9503656940800803, Training Accuracy: 94.50892857142857%\n",
      "Epoch 21, Batch 80, Training Loss: 0.9515148095786572, Training Accuracy: 94.140625%\n",
      "Epoch 21, Batch 90, Training Loss: 0.9513457298278809, Training Accuracy: 94.20138888888889%\n",
      "Epoch 21, Validation Loss: 0.9470530852027561, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 21: Adam lr 0.0010\n",
      "Epoch 22, Batch 10, Training Loss: 0.9436753928661347, Training Accuracy: 95.625%\n",
      "Epoch 22, Batch 20, Training Loss: 0.9466697603464127, Training Accuracy: 94.375%\n",
      "Epoch 22, Batch 30, Training Loss: 0.9424766679604848, Training Accuracy: 95.3125%\n",
      "Epoch 22, Batch 40, Training Loss: 0.9453800201416016, Training Accuracy: 95.15625%\n",
      "Epoch 22, Batch 50, Training Loss: 0.9476693761348725, Training Accuracy: 94.875%\n",
      "Epoch 22, Batch 60, Training Loss: 0.948459662993749, Training Accuracy: 94.94791666666667%\n",
      "Epoch 22, Batch 70, Training Loss: 0.9481701850891113, Training Accuracy: 94.77678571428572%\n",
      "Epoch 22, Batch 80, Training Loss: 0.949334180355072, Training Accuracy: 94.609375%\n",
      "Epoch 22, Batch 90, Training Loss: 0.948713152938419, Training Accuracy: 94.82638888888889%\n",
      "Epoch 22, Validation Loss: 0.9510195436684982, Validation Accuracy: 93.46049046321527%\n",
      "Epoch 22: Adam lr 0.0010\n",
      "Epoch 23, Batch 10, Training Loss: 0.9357901573181152, Training Accuracy: 95.0%\n",
      "Epoch 23, Batch 20, Training Loss: 0.9413046032190323, Training Accuracy: 94.53125%\n",
      "Epoch 23, Batch 30, Training Loss: 0.9404215693473816, Training Accuracy: 94.79166666666666%\n",
      "Epoch 23, Batch 40, Training Loss: 0.9446428477764129, Training Accuracy: 94.84375%\n",
      "Epoch 23, Batch 50, Training Loss: 0.9481058585643768, Training Accuracy: 94.9375%\n",
      "Epoch 23, Batch 60, Training Loss: 0.948842320839564, Training Accuracy: 94.42708333333333%\n",
      "Epoch 23, Batch 70, Training Loss: 0.9496239040579114, Training Accuracy: 94.10714285714286%\n",
      "Epoch 23, Batch 80, Training Loss: 0.9494117870926857, Training Accuracy: 94.0234375%\n",
      "Epoch 23, Batch 90, Training Loss: 0.948737539185418, Training Accuracy: 94.16666666666667%\n",
      "Epoch 23, Validation Loss: 0.9490081020023512, Validation Accuracy: 95.2316076294278%\n",
      "Epoch 23: Adam lr 0.0010\n",
      "Epoch 24, Batch 10, Training Loss: 0.9586902439594269, Training Accuracy: 94.375%\n",
      "Epoch 24, Batch 20, Training Loss: 0.9559146374464035, Training Accuracy: 94.53125%\n",
      "Epoch 24, Batch 30, Training Loss: 0.9564900656541189, Training Accuracy: 93.95833333333333%\n",
      "Epoch 24, Batch 40, Training Loss: 0.955228504538536, Training Accuracy: 93.59375%\n",
      "Epoch 24, Batch 50, Training Loss: 0.951306916475296, Training Accuracy: 94.125%\n",
      "Epoch 24, Batch 60, Training Loss: 0.9487010518709819, Training Accuracy: 94.42708333333333%\n",
      "Epoch 24, Batch 70, Training Loss: 0.9500049318586077, Training Accuracy: 94.41964285714286%\n",
      "Epoch 24, Batch 80, Training Loss: 0.9525305829942227, Training Accuracy: 94.1796875%\n",
      "Epoch 24, Batch 90, Training Loss: 0.9522402571307288, Training Accuracy: 94.0625%\n",
      "Epoch 24, Validation Loss: 0.9538625038188436, Validation Accuracy: 94.4141689373297%\n",
      "Epoch 24: Adam lr 0.0010\n",
      "Epoch 25, Batch 10, Training Loss: 0.9325838088989258, Training Accuracy: 95.625%\n",
      "Epoch 25, Batch 20, Training Loss: 0.9429860383272171, Training Accuracy: 94.6875%\n",
      "Epoch 25, Batch 30, Training Loss: 0.9522276043891906, Training Accuracy: 93.33333333333333%\n",
      "Epoch 25, Batch 40, Training Loss: 0.9516202971339226, Training Accuracy: 93.515625%\n",
      "Epoch 25, Batch 50, Training Loss: 0.9521564173698426, Training Accuracy: 93.8125%\n",
      "Epoch 25, Batch 60, Training Loss: 0.9514752785364787, Training Accuracy: 94.01041666666666%\n",
      "Epoch 25, Batch 70, Training Loss: 0.9529118205819811, Training Accuracy: 93.79464285714286%\n",
      "Epoch 25, Batch 80, Training Loss: 0.9534234330058098, Training Accuracy: 93.828125%\n",
      "Epoch 25, Batch 90, Training Loss: 0.9520086354679531, Training Accuracy: 93.95833333333333%\n",
      "Epoch 25, Validation Loss: 0.9476115962733394, Validation Accuracy: 95.09536784741145%\n",
      "Epoch 25: Adam lr 0.0010\n",
      "Epoch 26, Batch 10, Training Loss: 0.9449249982833863, Training Accuracy: 96.5625%\n",
      "Epoch 26, Batch 20, Training Loss: 0.9411039501428604, Training Accuracy: 96.09375%\n",
      "Epoch 26, Batch 30, Training Loss: 0.936230621735255, Training Accuracy: 96.14583333333333%\n",
      "Epoch 26, Batch 40, Training Loss: 0.9395916074514389, Training Accuracy: 95.625%\n",
      "Epoch 26, Batch 50, Training Loss: 0.944528945684433, Training Accuracy: 95.0625%\n",
      "Epoch 26, Batch 60, Training Loss: 0.942655082543691, Training Accuracy: 95.15625%\n",
      "Epoch 26, Batch 70, Training Loss: 0.9459160557815007, Training Accuracy: 94.6875%\n",
      "Epoch 26, Batch 80, Training Loss: 0.9448152422904968, Training Accuracy: 94.765625%\n",
      "Epoch 26, Batch 90, Training Loss: 0.9466436723868052, Training Accuracy: 94.72222222222221%\n",
      "Epoch 26, Validation Loss: 0.9528398617454197, Validation Accuracy: 95.2316076294278%\n",
      "Epoch 26: Adam lr 0.0010\n",
      "Epoch 27, Batch 10, Training Loss: 0.9471818923950195, Training Accuracy: 94.6875%\n",
      "Epoch 27, Batch 20, Training Loss: 0.9497449696063995, Training Accuracy: 94.375%\n",
      "Epoch 27, Batch 30, Training Loss: 0.9519122640291849, Training Accuracy: 94.27083333333334%\n",
      "Epoch 27, Batch 40, Training Loss: 0.9495520815253258, Training Accuracy: 94.609375%\n",
      "Epoch 27, Batch 50, Training Loss: 0.9470782065391541, Training Accuracy: 94.9375%\n",
      "Epoch 27, Batch 60, Training Loss: 0.9483268757661184, Training Accuracy: 94.94791666666667%\n",
      "Epoch 27, Batch 70, Training Loss: 0.9492059980119978, Training Accuracy: 94.46428571428571%\n",
      "Epoch 27, Batch 80, Training Loss: 0.9501367524266243, Training Accuracy: 94.1796875%\n",
      "Epoch 27, Batch 90, Training Loss: 0.9487622790866428, Training Accuracy: 94.40972222222223%\n",
      "Epoch 27, Validation Loss: 0.9465307904326398, Validation Accuracy: 95.64032697547684%\n",
      "Epoch 27: Adam lr 0.0010\n",
      "Epoch 28, Batch 10, Training Loss: 0.9782015800476074, Training Accuracy: 92.5%\n",
      "Epoch 28, Batch 20, Training Loss: 0.9660384953022003, Training Accuracy: 92.1875%\n",
      "Epoch 28, Batch 30, Training Loss: 0.9559722065925598, Training Accuracy: 93.33333333333333%\n",
      "Epoch 28, Batch 40, Training Loss: 0.9527722403407097, Training Accuracy: 94.140625%\n",
      "Epoch 28, Batch 50, Training Loss: 0.9509518587589264, Training Accuracy: 94.5625%\n",
      "Epoch 28, Batch 60, Training Loss: 0.9513883143663406, Training Accuracy: 94.53125%\n",
      "Epoch 28, Batch 70, Training Loss: 0.9487509284700666, Training Accuracy: 94.6875%\n",
      "Epoch 28, Batch 80, Training Loss: 0.9514393627643585, Training Accuracy: 94.2578125%\n",
      "Epoch 28, Batch 90, Training Loss: 0.9496180964840784, Training Accuracy: 94.47916666666667%\n",
      "Epoch 28, Validation Loss: 0.9480554591054502, Validation Accuracy: 94.95912806539509%\n",
      "Epoch 28: Adam lr 0.0010\n",
      "Epoch 29, Batch 10, Training Loss: 0.9434812903404236, Training Accuracy: 95.3125%\n",
      "Epoch 29, Batch 20, Training Loss: 0.9438358575105668, Training Accuracy: 95.0%\n",
      "Epoch 29, Batch 30, Training Loss: 0.9406096657117208, Training Accuracy: 95.20833333333333%\n",
      "Epoch 29, Batch 40, Training Loss: 0.9454207390546798, Training Accuracy: 94.84375%\n",
      "Epoch 29, Batch 50, Training Loss: 0.94656125664711, Training Accuracy: 94.625%\n",
      "Epoch 29, Batch 60, Training Loss: 0.9454912722110749, Training Accuracy: 94.89583333333333%\n",
      "Epoch 29, Batch 70, Training Loss: 0.9427711052553994, Training Accuracy: 95.08928571428571%\n",
      "Epoch 29, Batch 80, Training Loss: 0.9419549278914928, Training Accuracy: 95.234375%\n",
      "Epoch 29, Batch 90, Training Loss: 0.9420686370796627, Training Accuracy: 95.3125%\n",
      "Epoch 29, Validation Loss: 0.9483681217483853, Validation Accuracy: 94.4141689373297%\n",
      "Epoch 29: Adam lr 0.0010\n",
      "Epoch 30, Batch 10, Training Loss: 0.9360606968402863, Training Accuracy: 96.5625%\n",
      "Epoch 30, Batch 20, Training Loss: 0.9399859338998795, Training Accuracy: 95.9375%\n",
      "Epoch 30, Batch 30, Training Loss: 0.9380938152472178, Training Accuracy: 96.14583333333333%\n",
      "Epoch 30, Batch 40, Training Loss: 0.9396084561944008, Training Accuracy: 96.25%\n",
      "Epoch 30, Batch 50, Training Loss: 0.9449186992645263, Training Accuracy: 95.5%\n",
      "Epoch 30, Batch 60, Training Loss: 0.9419853746891022, Training Accuracy: 95.9375%\n",
      "Epoch 30, Batch 70, Training Loss: 0.9429752290248871, Training Accuracy: 95.75892857142857%\n",
      "Epoch 30, Batch 80, Training Loss: 0.9413962751626969, Training Accuracy: 95.859375%\n",
      "Epoch 30, Batch 90, Training Loss: 0.941985140244166, Training Accuracy: 95.76388888888889%\n",
      "Epoch 30, Validation Loss: 0.946814881718677, Validation Accuracy: 95.36784741144415%\n",
      "Epoch 30: Adam lr 0.0010\n",
      "Epoch 31, Batch 10, Training Loss: 0.9566736936569213, Training Accuracy: 95.625%\n",
      "Epoch 31, Batch 20, Training Loss: 0.9473091781139373, Training Accuracy: 95.625%\n",
      "Epoch 31, Batch 30, Training Loss: 0.9391786436239878, Training Accuracy: 96.25%\n",
      "Epoch 31, Batch 40, Training Loss: 0.9353230342268943, Training Accuracy: 96.640625%\n",
      "Epoch 31, Batch 50, Training Loss: 0.9347459590435028, Training Accuracy: 96.75%\n",
      "Epoch 31, Batch 60, Training Loss: 0.9377181301514308, Training Accuracy: 96.35416666666666%\n",
      "Epoch 31, Batch 70, Training Loss: 0.9406794931207384, Training Accuracy: 96.07142857142857%\n",
      "Epoch 31, Batch 80, Training Loss: 0.9411062143743039, Training Accuracy: 95.8984375%\n",
      "Epoch 31, Batch 90, Training Loss: 0.9399683879481422, Training Accuracy: 95.9375%\n",
      "Epoch 31, Validation Loss: 0.9473643898963928, Validation Accuracy: 95.2316076294278%\n",
      "Epoch 31: Adam lr 0.0010\n",
      "Epoch 32, Batch 10, Training Loss: 0.9405667245388031, Training Accuracy: 96.5625%\n",
      "Epoch 32, Batch 20, Training Loss: 0.9404420465230942, Training Accuracy: 96.71875%\n",
      "Epoch 32, Batch 30, Training Loss: 0.9411279201507569, Training Accuracy: 96.77083333333333%\n",
      "Epoch 32, Batch 40, Training Loss: 0.9379243716597557, Training Accuracy: 96.71875%\n",
      "Epoch 32, Batch 50, Training Loss: 0.9394803833961487, Training Accuracy: 96.4375%\n",
      "Epoch 32, Batch 60, Training Loss: 0.9374707897504171, Training Accuracy: 96.5625%\n",
      "Epoch 32, Batch 70, Training Loss: 0.9383337829794203, Training Accuracy: 96.33928571428572%\n",
      "Epoch 32, Batch 80, Training Loss: 0.9395550668239594, Training Accuracy: 96.0546875%\n",
      "Epoch 32, Batch 90, Training Loss: 0.9393537468380398, Training Accuracy: 96.04166666666667%\n",
      "Epoch 32, Validation Loss: 0.9503562502239061, Validation Accuracy: 95.36784741144415%\n",
      "Epoch 32: Adam lr 0.0010\n",
      "Epoch 33, Batch 10, Training Loss: 0.9357933580875397, Training Accuracy: 96.25%\n",
      "Epoch 33, Batch 20, Training Loss: 0.9390795886516571, Training Accuracy: 95.3125%\n",
      "Epoch 33, Batch 30, Training Loss: 0.9457900206247966, Training Accuracy: 95.20833333333333%\n",
      "Epoch 33, Batch 40, Training Loss: 0.942429906129837, Training Accuracy: 95.3125%\n",
      "Epoch 33, Batch 50, Training Loss: 0.9423943340778351, Training Accuracy: 95.5625%\n",
      "Epoch 33, Batch 60, Training Loss: 0.9420302699009577, Training Accuracy: 95.625%\n",
      "Epoch 33, Batch 70, Training Loss: 0.9411296018532345, Training Accuracy: 95.80357142857143%\n",
      "Epoch 33, Batch 80, Training Loss: 0.9402482204139233, Training Accuracy: 95.9765625%\n",
      "Epoch 33, Batch 90, Training Loss: 0.9399640745586819, Training Accuracy: 95.9375%\n",
      "Epoch 33, Validation Loss: 0.9496269018753715, Validation Accuracy: 94.95912806539509%\n",
      "Epoch 33: Adam lr 0.0001\n",
      "Epoch 34, Batch 10, Training Loss: 0.9392298340797425, Training Accuracy: 96.5625%\n",
      "Epoch 34, Batch 20, Training Loss: 0.937786266207695, Training Accuracy: 97.03125%\n",
      "Epoch 34, Batch 30, Training Loss: 0.9406724830468496, Training Accuracy: 96.45833333333333%\n",
      "Epoch 34, Batch 40, Training Loss: 0.9396657377481461, Training Accuracy: 96.40625%\n",
      "Epoch 34, Batch 50, Training Loss: 0.9374797129631043, Training Accuracy: 96.375%\n",
      "Epoch 34, Batch 60, Training Loss: 0.9397415707508723, Training Accuracy: 96.25%\n",
      "Epoch 34, Batch 70, Training Loss: 0.9380122746740068, Training Accuracy: 96.29464285714285%\n",
      "Epoch 34, Batch 80, Training Loss: 0.9393927164375782, Training Accuracy: 96.328125%\n",
      "Epoch 34, Batch 90, Training Loss: 0.9396564728683896, Training Accuracy: 96.21527777777777%\n",
      "Epoch 34, Validation Loss: 0.9474554113719774, Validation Accuracy: 94.82288828337875%\n",
      "Epoch 34: Adam lr 0.0001\n",
      "Epoch 35, Batch 10, Training Loss: 0.9400701522827148, Training Accuracy: 95.625%\n",
      "Epoch 35, Batch 20, Training Loss: 0.9392181992530823, Training Accuracy: 96.09375%\n",
      "Epoch 35, Batch 30, Training Loss: 0.9349142332871755, Training Accuracy: 96.25%\n",
      "Epoch 35, Batch 40, Training Loss: 0.936098974943161, Training Accuracy: 96.171875%\n",
      "Epoch 35, Batch 50, Training Loss: 0.9363945162296295, Training Accuracy: 96.0%\n",
      "Epoch 35, Batch 60, Training Loss: 0.9362421443065008, Training Accuracy: 95.88541666666667%\n",
      "Epoch 35, Batch 70, Training Loss: 0.93637159211295, Training Accuracy: 95.84821428571428%\n",
      "Epoch 35, Batch 80, Training Loss: 0.9385711826384068, Training Accuracy: 95.78125%\n",
      "Epoch 35, Batch 90, Training Loss: 0.9389091663890414, Training Accuracy: 95.79861111111111%\n",
      "Epoch 35, Validation Loss: 0.9451212209203969, Validation Accuracy: 95.2316076294278%\n",
      "Epoch 35: Adam lr 0.0001\n",
      "Epoch 36, Batch 10, Training Loss: 0.9471764087677002, Training Accuracy: 96.25%\n",
      "Epoch 36, Batch 20, Training Loss: 0.9378102898597718, Training Accuracy: 96.5625%\n",
      "Epoch 36, Batch 30, Training Loss: 0.9331586182117462, Training Accuracy: 96.875%\n",
      "Epoch 36, Batch 40, Training Loss: 0.9337203323841095, Training Accuracy: 96.71875%\n",
      "Epoch 36, Batch 50, Training Loss: 0.9339842450618744, Training Accuracy: 96.5%\n",
      "Epoch 36, Batch 60, Training Loss: 0.9360078314940135, Training Accuracy: 96.45833333333333%\n",
      "Epoch 36, Batch 70, Training Loss: 0.9361452732767378, Training Accuracy: 96.38392857142857%\n",
      "Epoch 36, Batch 80, Training Loss: 0.9360907152295113, Training Accuracy: 96.328125%\n",
      "Epoch 36, Batch 90, Training Loss: 0.9360878143045638, Training Accuracy: 96.25%\n",
      "Epoch 36, Validation Loss: 0.9446953068608823, Validation Accuracy: 95.64032697547684%\n",
      "Epoch 36: Adam lr 0.0001\n",
      "Epoch 37, Batch 10, Training Loss: 0.9328783929347992, Training Accuracy: 96.875%\n",
      "Epoch 37, Batch 20, Training Loss: 0.9323966264724731, Training Accuracy: 97.1875%\n",
      "Epoch 37, Batch 30, Training Loss: 0.9351316809654235, Training Accuracy: 96.77083333333333%\n",
      "Epoch 37, Batch 40, Training Loss: 0.9348376840353012, Training Accuracy: 96.875%\n",
      "Epoch 37, Batch 50, Training Loss: 0.9397611093521118, Training Accuracy: 96.375%\n",
      "Epoch 37, Batch 60, Training Loss: 0.9402430276075999, Training Accuracy: 96.35416666666666%\n",
      "Epoch 37, Batch 70, Training Loss: 0.9377396745341164, Training Accuracy: 96.51785714285714%\n",
      "Epoch 37, Batch 80, Training Loss: 0.9371193699538708, Training Accuracy: 96.4453125%\n",
      "Epoch 37, Batch 90, Training Loss: 0.939184578259786, Training Accuracy: 96.31944444444444%\n",
      "Epoch 37, Validation Loss: 0.9441689978475156, Validation Accuracy: 95.50408719346049%\n",
      "Epoch 37: Adam lr 0.0001\n",
      "Epoch 38, Batch 10, Training Loss: 0.9331514477729798, Training Accuracy: 97.8125%\n",
      "Epoch 38, Batch 20, Training Loss: 0.9374106615781784, Training Accuracy: 96.40625%\n",
      "Epoch 38, Batch 30, Training Loss: 0.9353756586710612, Training Accuracy: 96.35416666666666%\n",
      "Epoch 38, Batch 40, Training Loss: 0.9329263746738434, Training Accuracy: 96.5625%\n",
      "Epoch 38, Batch 50, Training Loss: 0.9329029822349548, Training Accuracy: 96.5%\n",
      "Epoch 38, Batch 60, Training Loss: 0.932068920135498, Training Accuracy: 96.66666666666667%\n",
      "Epoch 38, Batch 70, Training Loss: 0.9354808509349823, Training Accuracy: 96.33928571428572%\n",
      "Epoch 38, Batch 80, Training Loss: 0.9373002424836159, Training Accuracy: 96.2109375%\n",
      "Epoch 38, Batch 90, Training Loss: 0.9373539229234059, Training Accuracy: 96.21527777777777%\n",
      "Epoch 38, Validation Loss: 0.9442278613214907, Validation Accuracy: 95.77656675749319%\n",
      "Epoch 38: Adam lr 0.0001\n",
      "Epoch 39, Batch 10, Training Loss: 0.9285774469375611, Training Accuracy: 95.9375%\n",
      "Epoch 39, Batch 20, Training Loss: 0.9336649388074875, Training Accuracy: 95.625%\n",
      "Epoch 39, Batch 30, Training Loss: 0.9313409129778544, Training Accuracy: 96.14583333333333%\n",
      "Epoch 39, Batch 40, Training Loss: 0.9342033594846726, Training Accuracy: 96.09375%\n",
      "Epoch 39, Batch 50, Training Loss: 0.9338853371143341, Training Accuracy: 96.0625%\n",
      "Epoch 39, Batch 60, Training Loss: 0.9344818890094757, Training Accuracy: 95.9375%\n",
      "Epoch 39, Batch 70, Training Loss: 0.9334775541509901, Training Accuracy: 96.07142857142857%\n",
      "Epoch 39, Batch 80, Training Loss: 0.9329856194555759, Training Accuracy: 96.171875%\n",
      "Epoch 39, Batch 90, Training Loss: 0.9378182199266222, Training Accuracy: 95.90277777777779%\n",
      "Epoch 39, Validation Loss: 0.944225769975911, Validation Accuracy: 95.77656675749319%\n",
      "Epoch 39: Adam lr 0.0001\n",
      "Epoch 40, Batch 10, Training Loss: 0.9492682933807373, Training Accuracy: 95.3125%\n",
      "Epoch 40, Batch 20, Training Loss: 0.9423394739627838, Training Accuracy: 95.46875%\n",
      "Epoch 40, Batch 30, Training Loss: 0.9370007216930389, Training Accuracy: 95.9375%\n",
      "Epoch 40, Batch 40, Training Loss: 0.9345665827393532, Training Accuracy: 96.328125%\n",
      "Epoch 40, Batch 50, Training Loss: 0.9376610910892487, Training Accuracy: 96.1875%\n",
      "Epoch 40, Batch 60, Training Loss: 0.9353724151849747, Training Accuracy: 96.45833333333333%\n",
      "Epoch 40, Batch 70, Training Loss: 0.9392349941389901, Training Accuracy: 96.11607142857143%\n",
      "Epoch 40, Batch 80, Training Loss: 0.9377729155123233, Training Accuracy: 96.25%\n",
      "Epoch 40, Batch 90, Training Loss: 0.938976561360889, Training Accuracy: 96.18055555555556%\n",
      "Epoch 40, Validation Loss: 0.9439521120942157, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 40: Adam lr 0.0001\n",
      "Epoch 41, Batch 10, Training Loss: 0.9476976752281189, Training Accuracy: 94.0625%\n",
      "Epoch 41, Batch 20, Training Loss: 0.9412771582603454, Training Accuracy: 95.3125%\n",
      "Epoch 41, Batch 30, Training Loss: 0.9374768495559692, Training Accuracy: 95.83333333333334%\n",
      "Epoch 41, Batch 40, Training Loss: 0.9331408262252807, Training Accuracy: 96.40625%\n",
      "Epoch 41, Batch 50, Training Loss: 0.9328063690662384, Training Accuracy: 96.625%\n",
      "Epoch 41, Batch 60, Training Loss: 0.9347291906674703, Training Accuracy: 96.51041666666667%\n",
      "Epoch 41, Batch 70, Training Loss: 0.9349941977432796, Training Accuracy: 96.5625%\n",
      "Epoch 41, Batch 80, Training Loss: 0.9344298474490642, Training Accuracy: 96.5234375%\n",
      "Epoch 41, Batch 90, Training Loss: 0.9364961895677778, Training Accuracy: 96.38888888888889%\n",
      "Epoch 41, Validation Loss: 0.9433580300082332, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 41: Adam lr 0.0001\n",
      "Epoch 42, Batch 10, Training Loss: 0.9322932004928589, Training Accuracy: 95.9375%\n",
      "Epoch 42, Batch 20, Training Loss: 0.94326431453228, Training Accuracy: 95.3125%\n",
      "Epoch 42, Batch 30, Training Loss: 0.9356499234835307, Training Accuracy: 95.9375%\n",
      "Epoch 42, Batch 40, Training Loss: 0.9341540306806564, Training Accuracy: 96.015625%\n",
      "Epoch 42, Batch 50, Training Loss: 0.934544085264206, Training Accuracy: 96.125%\n",
      "Epoch 42, Batch 60, Training Loss: 0.9312820663054784, Training Accuracy: 96.51041666666667%\n",
      "Epoch 42, Batch 70, Training Loss: 0.9342167718069894, Training Accuracy: 96.5625%\n",
      "Epoch 42, Batch 80, Training Loss: 0.9350483074784279, Training Accuracy: 96.4453125%\n",
      "Epoch 42, Batch 90, Training Loss: 0.9355825874540541, Training Accuracy: 96.31944444444444%\n",
      "Epoch 42, Validation Loss: 0.9432901740074158, Validation Accuracy: 95.64032697547684%\n",
      "Epoch 42: Adam lr 0.0001\n",
      "Epoch 43, Batch 10, Training Loss: 0.9383092045783996, Training Accuracy: 95.9375%\n",
      "Epoch 43, Batch 20, Training Loss: 0.9318674296140671, Training Accuracy: 96.40625%\n",
      "Epoch 43, Batch 30, Training Loss: 0.9360070109367371, Training Accuracy: 96.25%\n",
      "Epoch 43, Batch 40, Training Loss: 0.932571890950203, Training Accuracy: 96.5625%\n",
      "Epoch 43, Batch 50, Training Loss: 0.9295109701156616, Training Accuracy: 96.9375%\n",
      "Epoch 43, Batch 60, Training Loss: 0.9307653288046519, Training Accuracy: 96.82291666666667%\n",
      "Epoch 43, Batch 70, Training Loss: 0.9349017075129917, Training Accuracy: 96.65178571428571%\n",
      "Epoch 43, Batch 80, Training Loss: 0.9362150169909, Training Accuracy: 96.4453125%\n",
      "Epoch 43, Batch 90, Training Loss: 0.9354435039891137, Training Accuracy: 96.45833333333333%\n",
      "Epoch 43, Validation Loss: 0.9433723454890044, Validation Accuracy: 95.64032697547684%\n",
      "Epoch 43: Adam lr 0.0001\n",
      "Epoch 44, Batch 10, Training Loss: 0.9424057126045227, Training Accuracy: 96.25%\n",
      "Epoch 44, Batch 20, Training Loss: 0.9346131920814514, Training Accuracy: 97.03125%\n",
      "Epoch 44, Batch 30, Training Loss: 0.9439473470052083, Training Accuracy: 96.25%\n",
      "Epoch 44, Batch 40, Training Loss: 0.9380230352282524, Training Accuracy: 96.640625%\n",
      "Epoch 44, Batch 50, Training Loss: 0.9387885963916779, Training Accuracy: 96.5%\n",
      "Epoch 44, Batch 60, Training Loss: 0.9399427642424901, Training Accuracy: 96.30208333333333%\n",
      "Epoch 44, Batch 70, Training Loss: 0.939334613084793, Training Accuracy: 96.29464285714285%\n",
      "Epoch 44, Batch 80, Training Loss: 0.9391027681529522, Training Accuracy: 96.25%\n",
      "Epoch 44, Batch 90, Training Loss: 0.937711939546797, Training Accuracy: 96.35416666666666%\n",
      "Epoch 44, Validation Loss: 0.9431401802145917, Validation Accuracy: 95.64032697547684%\n",
      "Epoch 44: Adam lr 0.0001\n",
      "Epoch 45, Batch 10, Training Loss: 0.9509945034980773, Training Accuracy: 94.6875%\n",
      "Epoch 45, Batch 20, Training Loss: 0.9472875773906708, Training Accuracy: 95.625%\n",
      "Epoch 45, Batch 30, Training Loss: 0.9418936550617218, Training Accuracy: 95.83333333333334%\n",
      "Epoch 45, Batch 40, Training Loss: 0.9402413710951805, Training Accuracy: 96.015625%\n",
      "Epoch 45, Batch 50, Training Loss: 0.9381002950668335, Training Accuracy: 96.0%\n",
      "Epoch 45, Batch 60, Training Loss: 0.938150887688001, Training Accuracy: 95.98958333333333%\n",
      "Epoch 45, Batch 70, Training Loss: 0.9373560888426644, Training Accuracy: 96.02678571428571%\n",
      "Epoch 45, Batch 80, Training Loss: 0.9380519524216652, Training Accuracy: 96.171875%\n",
      "Epoch 45, Batch 90, Training Loss: 0.9365818884637621, Training Accuracy: 96.28472222222221%\n",
      "Epoch 45, Validation Loss: 0.9430520068044248, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 45: Adam lr 0.0001\n",
      "Epoch 46, Batch 10, Training Loss: 0.9312387645244599, Training Accuracy: 97.5%\n",
      "Epoch 46, Batch 20, Training Loss: 0.9278028786182404, Training Accuracy: 97.8125%\n",
      "Epoch 46, Batch 30, Training Loss: 0.9304753939310709, Training Accuracy: 96.97916666666667%\n",
      "Epoch 46, Batch 40, Training Loss: 0.9305074915289879, Training Accuracy: 97.03125%\n",
      "Epoch 46, Batch 50, Training Loss: 0.9357039761543274, Training Accuracy: 96.625%\n",
      "Epoch 46, Batch 60, Training Loss: 0.9347344895203908, Training Accuracy: 96.71875%\n",
      "Epoch 46, Batch 70, Training Loss: 0.9347071349620819, Training Accuracy: 96.74107142857142%\n",
      "Epoch 46, Batch 80, Training Loss: 0.9367930598556995, Training Accuracy: 96.484375%\n",
      "Epoch 46, Batch 90, Training Loss: 0.9350180943806966, Training Accuracy: 96.59722222222223%\n",
      "Epoch 46, Validation Loss: 0.943762675575588, Validation Accuracy: 95.64032697547684%\n",
      "Epoch 46: Adam lr 0.0001\n",
      "Epoch 47, Batch 10, Training Loss: 0.9222788214683533, Training Accuracy: 98.125%\n",
      "Epoch 47, Batch 20, Training Loss: 0.9256552428007125, Training Accuracy: 97.65625%\n",
      "Epoch 47, Batch 30, Training Loss: 0.9265727539857228, Training Accuracy: 97.08333333333333%\n",
      "Epoch 47, Batch 40, Training Loss: 0.9277192935347557, Training Accuracy: 96.875%\n",
      "Epoch 47, Batch 50, Training Loss: 0.9287598013877869, Training Accuracy: 96.8125%\n",
      "Epoch 47, Batch 60, Training Loss: 0.9314415921767553, Training Accuracy: 96.45833333333333%\n",
      "Epoch 47, Batch 70, Training Loss: 0.9321729847363063, Training Accuracy: 96.65178571428571%\n",
      "Epoch 47, Batch 80, Training Loss: 0.9355690978467465, Training Accuracy: 96.484375%\n",
      "Epoch 47, Batch 90, Training Loss: 0.9374273028638628, Training Accuracy: 96.42361111111111%\n",
      "Epoch 47, Validation Loss: 0.944829927838367, Validation Accuracy: 95.64032697547684%\n",
      "Epoch 47: Adam lr 0.0001\n",
      "Epoch 48, Batch 10, Training Loss: 0.9463959217071534, Training Accuracy: 95.0%\n",
      "Epoch 48, Batch 20, Training Loss: 0.9445481926202774, Training Accuracy: 95.78125%\n",
      "Epoch 48, Batch 30, Training Loss: 0.940411114692688, Training Accuracy: 95.72916666666667%\n",
      "Epoch 48, Batch 40, Training Loss: 0.9353516802191735, Training Accuracy: 96.328125%\n",
      "Epoch 48, Batch 50, Training Loss: 0.936765558719635, Training Accuracy: 96.25%\n",
      "Epoch 48, Batch 60, Training Loss: 0.9332719961802165, Training Accuracy: 96.5625%\n",
      "Epoch 48, Batch 70, Training Loss: 0.9357041929449353, Training Accuracy: 96.29464285714285%\n",
      "Epoch 48, Batch 80, Training Loss: 0.9338069505989551, Training Accuracy: 96.5625%\n",
      "Epoch 48, Batch 90, Training Loss: 0.9366187347306145, Training Accuracy: 96.31944444444444%\n",
      "Epoch 48, Validation Loss: 0.9430603670037311, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 48: Adam lr 0.0001\n",
      "Epoch 49, Batch 10, Training Loss: 0.9415551245212554, Training Accuracy: 96.25%\n",
      "Epoch 49, Batch 20, Training Loss: 0.9392913997173309, Training Accuracy: 96.40625%\n",
      "Epoch 49, Batch 30, Training Loss: 0.9431087712446848, Training Accuracy: 96.25%\n",
      "Epoch 49, Batch 40, Training Loss: 0.9375371322035789, Training Accuracy: 96.5625%\n",
      "Epoch 49, Batch 50, Training Loss: 0.936371637582779, Training Accuracy: 96.5625%\n",
      "Epoch 49, Batch 60, Training Loss: 0.9372913906971614, Training Accuracy: 96.30208333333333%\n",
      "Epoch 49, Batch 70, Training Loss: 0.9392354215894426, Training Accuracy: 95.98214285714286%\n",
      "Epoch 49, Batch 80, Training Loss: 0.9386595346033573, Training Accuracy: 96.015625%\n",
      "Epoch 49, Batch 90, Training Loss: 0.9369325829876793, Training Accuracy: 96.14583333333333%\n",
      "Epoch 49, Validation Loss: 0.9430964044902636, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 49: Adam lr 0.0001\n",
      "Epoch 50, Batch 10, Training Loss: 0.9219084680080414, Training Accuracy: 97.8125%\n",
      "Epoch 50, Batch 20, Training Loss: 0.9236132472753524, Training Accuracy: 97.5%\n",
      "Epoch 50, Batch 30, Training Loss: 0.93040824731191, Training Accuracy: 96.66666666666667%\n",
      "Epoch 50, Batch 40, Training Loss: 0.935384652018547, Training Accuracy: 96.71875%\n",
      "Epoch 50, Batch 50, Training Loss: 0.9337095081806183, Training Accuracy: 96.8125%\n",
      "Epoch 50, Batch 60, Training Loss: 0.9339591095844905, Training Accuracy: 96.61458333333334%\n",
      "Epoch 50, Batch 70, Training Loss: 0.9378152310848236, Training Accuracy: 96.38392857142857%\n",
      "Epoch 50, Batch 80, Training Loss: 0.9394693456590175, Training Accuracy: 96.09375%\n",
      "Epoch 50, Batch 90, Training Loss: 0.9377968655692206, Training Accuracy: 96.28472222222221%\n",
      "Epoch 50, Validation Loss: 0.9424065092335576, Validation Accuracy: 96.04904632152589%\n",
      "Epoch 50: Adam lr 0.0001\n",
      "Epoch 51, Batch 10, Training Loss: 0.9458180963993073, Training Accuracy: 94.6875%\n",
      "Epoch 51, Batch 20, Training Loss: 0.9407295465469361, Training Accuracy: 95.3125%\n",
      "Epoch 51, Batch 30, Training Loss: 0.9346015353997549, Training Accuracy: 96.35416666666666%\n",
      "Epoch 51, Batch 40, Training Loss: 0.9337661936879158, Training Accuracy: 96.25%\n",
      "Epoch 51, Batch 50, Training Loss: 0.9346543395519257, Training Accuracy: 96.125%\n",
      "Epoch 51, Batch 60, Training Loss: 0.9340189039707184, Training Accuracy: 96.25%\n",
      "Epoch 51, Batch 70, Training Loss: 0.934145495721272, Training Accuracy: 96.38392857142857%\n",
      "Epoch 51, Batch 80, Training Loss: 0.9345690123736858, Training Accuracy: 96.3671875%\n",
      "Epoch 51, Batch 90, Training Loss: 0.9354421721564399, Training Accuracy: 96.42361111111111%\n",
      "Epoch 51, Validation Loss: 0.9437316319216853, Validation Accuracy: 95.77656675749319%\n",
      "Epoch 51: Adam lr 0.0001\n",
      "Epoch 52, Batch 10, Training Loss: 0.9330609917640686, Training Accuracy: 96.875%\n",
      "Epoch 52, Batch 20, Training Loss: 0.9315520375967026, Training Accuracy: 96.71875%\n",
      "Epoch 52, Batch 30, Training Loss: 0.9304567635059356, Training Accuracy: 96.97916666666667%\n",
      "Epoch 52, Batch 40, Training Loss: 0.9339741215109825, Training Accuracy: 97.03125%\n",
      "Epoch 52, Batch 50, Training Loss: 0.9344781196117401, Training Accuracy: 97.0625%\n",
      "Epoch 52, Batch 60, Training Loss: 0.9359648456176122, Training Accuracy: 96.66666666666667%\n",
      "Epoch 52, Batch 70, Training Loss: 0.9357788119997297, Training Accuracy: 96.42857142857143%\n",
      "Epoch 52, Batch 80, Training Loss: 0.9359921045601368, Training Accuracy: 96.5625%\n",
      "Epoch 52, Batch 90, Training Loss: 0.9366062786844042, Training Accuracy: 96.49305555555556%\n",
      "Epoch 52, Validation Loss: 0.9427358404449795, Validation Accuracy: 96.04904632152589%\n",
      "Epoch 52: Adam lr 0.0001\n",
      "Epoch 53, Batch 10, Training Loss: 0.9418344795703888, Training Accuracy: 96.25%\n",
      "Epoch 53, Batch 20, Training Loss: 0.945183464884758, Training Accuracy: 95.9375%\n",
      "Epoch 53, Batch 30, Training Loss: 0.9402093251546224, Training Accuracy: 96.25%\n",
      "Epoch 53, Batch 40, Training Loss: 0.9418936565518379, Training Accuracy: 96.171875%\n",
      "Epoch 53, Batch 50, Training Loss: 0.9387325191497803, Training Accuracy: 96.3125%\n",
      "Epoch 53, Batch 60, Training Loss: 0.9403475046157836, Training Accuracy: 96.25%\n",
      "Epoch 53, Batch 70, Training Loss: 0.9383325585297175, Training Accuracy: 96.29464285714285%\n",
      "Epoch 53, Batch 80, Training Loss: 0.9381550282239914, Training Accuracy: 96.3671875%\n",
      "Epoch 53, Batch 90, Training Loss: 0.936956520875295, Training Accuracy: 96.45833333333333%\n",
      "Epoch 53, Validation Loss: 0.9423942514087843, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 53: Adam lr 0.0001\n",
      "Epoch 54, Batch 10, Training Loss: 0.9357698678970336, Training Accuracy: 95.9375%\n",
      "Epoch 54, Batch 20, Training Loss: 0.9460003137588501, Training Accuracy: 95.3125%\n",
      "Epoch 54, Batch 30, Training Loss: 0.9423959434032441, Training Accuracy: 96.04166666666667%\n",
      "Epoch 54, Batch 40, Training Loss: 0.9431013524532318, Training Accuracy: 96.015625%\n",
      "Epoch 54, Batch 50, Training Loss: 0.940557302236557, Training Accuracy: 96.0625%\n",
      "Epoch 54, Batch 60, Training Loss: 0.9405782620112101, Training Accuracy: 96.19791666666667%\n",
      "Epoch 54, Batch 70, Training Loss: 0.9400374523230961, Training Accuracy: 96.33928571428572%\n",
      "Epoch 54, Batch 80, Training Loss: 0.9402407445013523, Training Accuracy: 96.5234375%\n",
      "Epoch 54, Batch 90, Training Loss: 0.9407502121395535, Training Accuracy: 96.31944444444444%\n",
      "Epoch 54, Validation Loss: 0.9427210818166318, Validation Accuracy: 96.04904632152589%\n",
      "Epoch 54: Adam lr 0.0001\n",
      "Epoch 55, Batch 10, Training Loss: 0.9523421823978424, Training Accuracy: 95.0%\n",
      "Epoch 55, Batch 20, Training Loss: 0.9430450558662414, Training Accuracy: 95.9375%\n",
      "Epoch 55, Batch 30, Training Loss: 0.9408414800961812, Training Accuracy: 96.04166666666667%\n",
      "Epoch 55, Batch 40, Training Loss: 0.9396696060895919, Training Accuracy: 96.09375%\n",
      "Epoch 55, Batch 50, Training Loss: 0.9370371413230896, Training Accuracy: 96.375%\n",
      "Epoch 55, Batch 60, Training Loss: 0.9336024294296901, Training Accuracy: 96.77083333333333%\n",
      "Epoch 55, Batch 70, Training Loss: 0.932874823468072, Training Accuracy: 96.65178571428571%\n",
      "Epoch 55, Batch 80, Training Loss: 0.9325834140181541, Training Accuracy: 96.6796875%\n",
      "Epoch 55, Batch 90, Training Loss: 0.934602184428109, Training Accuracy: 96.52777777777779%\n",
      "Epoch 55, Validation Loss: 0.943774049696715, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 55: Adam lr 0.0001\n",
      "Epoch 56, Batch 10, Training Loss: 0.9422880470752716, Training Accuracy: 96.5625%\n",
      "Epoch 56, Batch 20, Training Loss: 0.9319874316453933, Training Accuracy: 97.1875%\n",
      "Epoch 56, Batch 30, Training Loss: 0.9330453932285309, Training Accuracy: 96.97916666666667%\n",
      "Epoch 56, Batch 40, Training Loss: 0.931994092464447, Training Accuracy: 97.109375%\n",
      "Epoch 56, Batch 50, Training Loss: 0.9312992298603058, Training Accuracy: 97.0625%\n",
      "Epoch 56, Batch 60, Training Loss: 0.9323821912209193, Training Accuracy: 96.92708333333333%\n",
      "Epoch 56, Batch 70, Training Loss: 0.9338772356510162, Training Accuracy: 96.69642857142857%\n",
      "Epoch 56, Batch 80, Training Loss: 0.9344373255968094, Training Accuracy: 96.5234375%\n",
      "Epoch 56, Batch 90, Training Loss: 0.9351780447694991, Training Accuracy: 96.49305555555556%\n",
      "Epoch 56, Validation Loss: 0.9455358541530111, Validation Accuracy: 95.77656675749319%\n",
      "Epoch 56: Adam lr 0.0000\n",
      "Epoch 57, Batch 10, Training Loss: 0.9309789717197419, Training Accuracy: 97.1875%\n",
      "Epoch 57, Batch 20, Training Loss: 0.9400690287351608, Training Accuracy: 96.09375%\n",
      "Epoch 57, Batch 30, Training Loss: 0.9358256816864013, Training Accuracy: 96.35416666666666%\n",
      "Epoch 57, Batch 40, Training Loss: 0.9392931133508682, Training Accuracy: 96.25%\n",
      "Epoch 57, Batch 50, Training Loss: 0.9374321055412292, Training Accuracy: 96.25%\n",
      "Epoch 57, Batch 60, Training Loss: 0.9385983685652415, Training Accuracy: 96.30208333333333%\n",
      "Epoch 57, Batch 70, Training Loss: 0.9391006469726563, Training Accuracy: 96.33928571428572%\n",
      "Epoch 57, Batch 80, Training Loss: 0.9388653457164764, Training Accuracy: 96.25%\n",
      "Epoch 57, Batch 90, Training Loss: 0.9369339923063914, Training Accuracy: 96.35416666666666%\n",
      "Epoch 57, Validation Loss: 0.9454957350440647, Validation Accuracy: 96.04904632152589%\n",
      "Epoch 57: Adam lr 0.0000\n",
      "Epoch 58, Batch 10, Training Loss: 0.9538893103599548, Training Accuracy: 95.625%\n",
      "Epoch 58, Batch 20, Training Loss: 0.9481330007314682, Training Accuracy: 96.25%\n",
      "Epoch 58, Batch 30, Training Loss: 0.9431155482927959, Training Accuracy: 96.35416666666666%\n",
      "Epoch 58, Batch 40, Training Loss: 0.9415303096175194, Training Accuracy: 96.484375%\n",
      "Epoch 58, Batch 50, Training Loss: 0.9405166554450989, Training Accuracy: 96.5%\n",
      "Epoch 58, Batch 60, Training Loss: 0.9380411545435587, Training Accuracy: 96.5625%\n",
      "Epoch 58, Batch 70, Training Loss: 0.9403594519410815, Training Accuracy: 96.51785714285714%\n",
      "Epoch 58, Batch 80, Training Loss: 0.941811454296112, Training Accuracy: 96.3671875%\n",
      "Epoch 58, Batch 90, Training Loss: 0.9393793986903296, Training Accuracy: 96.45833333333333%\n",
      "Epoch 58, Validation Loss: 0.945256901823956, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 58: Adam lr 0.0000\n",
      "Epoch 59, Batch 10, Training Loss: 0.9504950642585754, Training Accuracy: 95.9375%\n",
      "Epoch 59, Batch 20, Training Loss: 0.9439611852169036, Training Accuracy: 96.40625%\n",
      "Epoch 59, Batch 30, Training Loss: 0.9373664875825246, Training Accuracy: 96.97916666666667%\n",
      "Epoch 59, Batch 40, Training Loss: 0.9378070250153542, Training Accuracy: 96.796875%\n",
      "Epoch 59, Batch 50, Training Loss: 0.9341781997680664, Training Accuracy: 97.0%\n",
      "Epoch 59, Batch 60, Training Loss: 0.9320342749357223, Training Accuracy: 97.13541666666666%\n",
      "Epoch 59, Batch 70, Training Loss: 0.9315177610942296, Training Accuracy: 97.27678571428572%\n",
      "Epoch 59, Batch 80, Training Loss: 0.9340566597878933, Training Accuracy: 97.03125%\n",
      "Epoch 59, Batch 90, Training Loss: 0.9367568996217516, Training Accuracy: 96.63194444444444%\n",
      "Epoch 59, Validation Loss: 0.9451159808946692, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 59: Adam lr 0.0000\n",
      "Epoch 60, Batch 10, Training Loss: 0.9433973670005799, Training Accuracy: 95.3125%\n",
      "Epoch 60, Batch 20, Training Loss: 0.937863877415657, Training Accuracy: 96.40625%\n",
      "Epoch 60, Batch 30, Training Loss: 0.9314017653465271, Training Accuracy: 96.77083333333333%\n",
      "Epoch 60, Batch 40, Training Loss: 0.9340501874685287, Training Accuracy: 96.484375%\n",
      "Epoch 60, Batch 50, Training Loss: 0.9327937126159668, Training Accuracy: 96.5625%\n",
      "Epoch 60, Batch 60, Training Loss: 0.9344554583231608, Training Accuracy: 96.40625%\n",
      "Epoch 60, Batch 70, Training Loss: 0.9342403198991504, Training Accuracy: 96.42857142857143%\n",
      "Epoch 60, Batch 80, Training Loss: 0.9359470687806606, Training Accuracy: 96.3671875%\n",
      "Epoch 60, Batch 90, Training Loss: 0.9370738161934746, Training Accuracy: 96.25%\n",
      "Epoch 60, Validation Loss: 0.9449620791103529, Validation Accuracy: 95.91280653950953%\n",
      "Epoch 60: Adam lr 0.0000\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for i, (x0_batch, x1_batch, x2_batch, x3_batch, x4_batch, \n",
    "        x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, \n",
    "        x10_batch, x11_batch, x12_batch, y_batch) in enumerate(train_dataloader):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x0_batch, x1_batch, x2_batch, x3_batch, x4_batch,x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, x10_batch, x11_batch, x12_batch, y_batch = (\n",
    "            x0_batch.to(device),\n",
    "            x1_batch.to(device),\n",
    "            x2_batch.to(device),\n",
    "            x3_batch.to(device),\n",
    "            x4_batch.to(device),\n",
    "            x5_batch.to(device),\n",
    "            x6_batch.to(device),\n",
    "            x7_batch.to(device),\n",
    "            x8_batch.to(device),\n",
    "            x9_batch.to(device),\n",
    "            x10_batch.to(device),\n",
    "            x11_batch.to(device),\n",
    "            x12_batch.to(device),\n",
    "            y_batch.to(device)\n",
    "        )\n",
    "        outputs = model(x0_batch, x1_batch, x2_batch, x3_batch, x4_batch, \n",
    "                         x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, \n",
    "                         x10_batch, x11_batch, x12_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_train += y_batch.size(0)\n",
    "        correct_train += (predicted == y_batch).sum().item()\n",
    "\n",
    "        if i % 10 == 9:  \n",
    "            print(f\"Epoch {epoch + 1}, Batch {i + 1}, Training Loss: {running_loss / (i + 1)}, Training Accuracy: {(correct_train / total_train) * 100}%\")\n",
    "            \n",
    "    train_epoch_loss = running_loss / len(train_dataloader)\n",
    "    train_epoch_accuracy = (correct_train / total_train) * 100\n",
    "\n",
    "    train_losses.append(train_epoch_loss)\n",
    "    train_accuracies.append(train_epoch_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x0_val, x1_val, x2_val, x3_val, x4_val, x5_val, x6_val, \\\n",
    "            x7_val, x8_val, x9_val, x10_val, x11_val, x12_val, y_val in test_dataloader:\n",
    "            \n",
    "            x0_val, x1_val, x2_val, x3_val, x4_val, \\\n",
    "            x5_val, x6_val, x7_val, x8_val, x9_val, \\\n",
    "            x10_val, x11_val, x12_val, y_val = (\n",
    "                x0_val.to(device),\n",
    "                x1_val.to(device),\n",
    "                x2_val.to(device),\n",
    "                x3_val.to(device),\n",
    "                x4_val.to(device),\n",
    "                x5_val.to(device),\n",
    "                x6_val.to(device),\n",
    "                x7_val.to(device),\n",
    "                x8_val.to(device),\n",
    "                x9_val.to(device),\n",
    "                x10_val.to(device),\n",
    "                x11_val.to(device),\n",
    "                x12_val.to(device),\n",
    "                y_val.to(device)\n",
    "            )\n",
    "            \n",
    "            outputs = model(x0_val, x1_val, x2_val, x3_val, x4_val, \n",
    "                             x5_val, x6_val, x7_val, x8_val, x9_val, \n",
    "                             x10_val, x11_val, x12_val)\n",
    "            loss = criterion(outputs, y_val)\n",
    "            val_running_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += y_val.size(0)\n",
    "            correct_val += (predicted == y_val).sum().item()\n",
    "\n",
    "    scheduler.step(val_running_loss)\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(test_dataloader)\n",
    "    val_epoch_accuracy = (correct_val / total_val) * 100\n",
    "\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Validation Loss: {val_epoch_loss}, Validation Accuracy: {val_epoch_accuracy}%\")\n",
    "    print(f\"Epoch {epoch + 1}: Adam lr {optimizer.param_groups[0]['lr']:.4f}\")\n",
    "\n",
    "print(\"Training finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWyElEQVR4nO3deXxU1f3/8dedmcxknayQBcKm7EJAUIpUBcUitbhh3ajiV63Vgrut8nNvq9hW616ttoLUBVfQVi2uLOKCbIKCLBogQFhD9mSSmbm/P24ySSQJSZglCe/n4zGPuXPvnZmTax7k7Tmfe45hmqaJiIiISCdhi3QDRERERIJJ4UZEREQ6FYUbERER6VQUbkRERKRTUbgRERGRTkXhRkRERDoVhRsRERHpVByRbkC4+f1+du7cSUJCAoZhRLo5IiIi0gKmaVJSUkJWVhY2W/N9M0dcuNm5cyfZ2dmRboaIiIi0QV5eHt27d2/2nCMu3CQkJADWxXG73RFujYiIiLREcXEx2dnZgb/jzTniwk3tUJTb7Va4ERER6WBaUlKigmIRERHpVBRuREREpFNRuBEREZFO5YiruRERkcPn8/morq6OdDOkk3E6nYe8zbslFG5ERKTFTNNk165dFBYWRrop0gnZbDZ69+6N0+k8rM9RuBERkRarDTZdu3YlNjZWk6FK0NROspufn0+PHj0O63dL4UZERFrE5/MFgk1qamqkmyOdUJcuXdi5cyder5eoqKg2f44KikVEpEVqa2xiY2Mj3BLprGqHo3w+32F9jsKNiIi0ioaiJFSC9bulcCMiIiKdisKNiIiIdCoKNyIiIq3Uq1cvHnnkkRafv3DhQgzD0C30YaJwEyQ+v8nu4kpy95VFuikiIlLDMIxmH/fcc0+bPverr77iqquuavH5J5xwAvn5+SQmJrbp+1pKIcqiW8GDZGdhBSf+5ROcDhsb/zQx0s0REREgPz8/sP3KK69w1113sWHDhsC++Pj4wLZpmvh8PhyOQ/9p7NKlS6va4XQ6ycjIaNV7pO3UcxMk7mjrfvwqrx+P9/BuYRMR6ShM06S8yhv2h2maLWpfRkZG4JGYmIhhGIHX3333HQkJCbz33nuMGDECl8vFp59+yvfff89ZZ51Feno68fHxHHfccXz44YcNPvfHw1KGYfDPf/6Tc845h9jYWPr27cvbb78dOP7jHpXZs2eTlJTEggULGDhwIPHx8Zx++ukNwpjX6+W6664jKSmJ1NRUbr31VqZOncrZZ5/d5v9eBw4c4NJLLyU5OZnY2FgmTpzIpk2bAse3bt3KpEmTSE5OJi4ujsGDB/Puu+8G3jtlyhS6dOlCTEwMffv2ZdasWW1uSyip5yZI4qPrLmVppRdXvD2CrRERCY+Kah+D7loQ9u9d94cJxDqD8yfstttu48EHH6RPnz4kJyeTl5fHz3/+c+677z5cLhdz5sxh0qRJbNiwgR49ejT5Offeey9/+ctf+Otf/8rjjz/OlClT2Lp1KykpKY2eX15ezoMPPsi///1vbDYbv/rVr7jlllt48cUXAfjzn//Miy++yKxZsxg4cCCPPvoo8+fPZ9y4cW3+WS+77DI2bdrE22+/jdvt5tZbb+XnP/8569atIyoqimnTplFVVcXixYuJi4tj3bp1gd6tO++8k3Xr1vHee++RlpbG5s2bqaioaHNbQknhJkjsNoM4p52yKh8llV5S412RbpKIiLTAH/7wB0477bTA65SUFHJycgKv//jHPzJv3jzefvttpk+f3uTnXHbZZVx00UUA3H///Tz22GMsW7aM008/vdHzq6urefrppznqqKMAmD59On/4wx8Cxx9//HFmzJjBOeecA8ATTzwR6EVpi9pQs3TpUk444QQAXnzxRbKzs5k/fz6//OUv2bZtG5MnT2bIkCEA9OnTJ/D+bdu2MXz4cEaOHAlYvVftlcJNECVERwXCjYjIkSAmys66P0yIyPcGS+0f61qlpaXcc889vPPOO+Tn5+P1eqmoqGDbtm3Nfs7QoUMD23Fxcbjdbvbs2dPk+bGxsYFgA5CZmRk4v6ioiN27d3P88ccHjtvtdkaMGIHf72/Vz1dr/fr1OBwORo0aFdiXmppK//79Wb9+PQDXXXcd11xzDe+//z7jx49n8uTJgZ/rmmuuYfLkyaxcuZKf/exnnH322YGQ1N6o5iaIaoemSiqrI9wSEZHwMAyDWKcj7I9gzpIcFxfX4PUtt9zCvHnzuP/++1myZAmrV69myJAhVFVVNfs5P14LyTCMZoNIY+e3tJYoVK688kp++OEHLrnkEtauXcvIkSN5/PHHAZg4cSJbt27lxhtvZOfOnZx66qnccsstEW1vUyIabhYvXsykSZPIysrCMAzmz5/f7Pm1BVk/fuzatSs8DT6EhJpwU6yeGxGRDmvp0qVcdtllnHPOOQwZMoSMjAy2bNkS1jYkJiaSnp7OV199Fdjn8/lYuXJlmz9z4MCBeL1evvzyy8C+/fv3s2HDBgYNGhTYl52dzdVXX82bb77JzTffzLPPPhs41qVLF6ZOncoLL7zAI488wjPPPNPm9oRSRIelysrKyMnJ4fLLL+fcc89t8fs2bNiA2+0OvO7atWsomtdqCTV3TJV6FG5ERDqqvn378uabbzJp0iQMw+DOO+9s81DQ4bj22muZOXMmRx99NAMGDODxxx/nwIEDLeq1Wrt2LQkJCYHXhmGQk5PDWWedxa9//Wv+8Y9/kJCQwG233Ua3bt0466yzALjhhhuYOHEi/fr148CBA3zyyScMHDgQgLvuuosRI0YwePBgPB4P//3vfwPH2puIhpuJEycycWLr54Tp2rUrSUlJwW/QYUrQsJSISIf3t7/9jcsvv5wTTjiBtLQ0br31VoqLi8PejltvvZVdu3Zx6aWXYrfbueqqq5gwYQJ2+6HrjU466aQGr+12O16vl1mzZnH99dfzi1/8gqqqKk466STefffdwBCZz+dj2rRpbN++Hbfbzemnn87DDz8MWHP1zJgxgy1bthATE8OJJ57I3Llzg/+DB4FhRnqAr4ZhGMybN6/Z+/cXLlzIuHHj6NmzJx6Ph2OOOYZ77rmHMWPGNPkej8eDx+MJvC4uLiY7O5uioqIGvT/BcNsba5j7VR43ndaP607tG9TPFhGJtMrKSnJzc+nduzfR0dGRbs4Rx+/3M3DgQM4//3z++Mc/Rro5IdHc71hxcTGJiYkt+vvdoQqKMzMzefrpp3njjTd44403yM7OZuzYsc2OQc6cOZPExMTAIzs7O2TtU8+NiIgEy9atW3n22WfZuHEja9eu5ZprriE3N5eLL7440k1r9zrUreD9+/enf//+gdcnnHAC33//PQ8//DD//ve/G33PjBkzuOmmmwKva3tuQqG25ka3gouIyOGy2WzMnj2bW265BdM0OeaYY/jwww/bbZ1Le9Khwk1jjj/+eD799NMmj7tcLlyu8EyoF+i5UUGxiIgcpuzsbJYuXRrpZnRIHWpYqjGrV68mMzMz0s0A1HMjIiLSHkS056a0tJTNmzcHXufm5rJ69WpSUlLo0aMHM2bMYMeOHcyZMweARx55hN69ezN48GAqKyv55z//yccff8z7778fqR+hgXiXam5EREQiLaLhZvny5Q0WAKutjZk6dSqzZ88mPz+/wXTXVVVV3HzzzezYsYPY2FiGDh3Khx9+eFiLiAWTO1BQrJ4bERGRSIlouBk7dmyzU03Pnj27wevf//73/P73vw9xq9ouMImfwo2IiEjEdPiam/ZEt4KLiIhEnsJNENWGm7IqHz5/u5gbUUREgmDs2LHccMMNgde9evXikUceafY9LVkzsSWC9TlHEoWbIKpdFRw0NCUi0h5MmjSJ008/vdFjS5YswTAM1qxZ0+rP/eqrr7jqqqsOt3kN3HPPPQwbNuyg/fn5+W1aqqg1Zs+e3S6XNWorhZsgcjnsOB3WJS3W0JSISMRdccUVfPDBB2zfvv2gY7NmzWLkyJEMHTq01Z/bpUsXYmNjg9HEQ8rIyAjbfG2dhcJNkNXeMaWVwUVEIu8Xv/gFXbp0OegGldLSUl577TWuuOIK9u/fz0UXXUS3bt2IjY1lyJAhvPzyy81+7o+HpTZt2sRJJ51EdHQ0gwYN4oMPPjjoPbfeeiv9+vUjNjaWPn36cOedd1Jdbf2P8OzZs7n33nv5+uuvMQwDwzACbf7xsNTatWs55ZRTiImJITU1lauuuorS0tLA8csuu4yzzz6bBx98kMzMTFJTU5k2bVrgu9pi27ZtnHXWWcTHx+N2uzn//PPZvXt34PjXX3/NuHHjSEhIwO12M2LECJYvXw5Yy0hMmjSJ5ORk4uLiGDx4MO+++26b29ISHX6G4vYmITqKfaVVuh1cRI4MpgnV5eH/3qhYMIxDnuZwOLj00kuZPXs2t99+O0bNe1577TV8Ph8XXXQRpaWljBgxgltvvRW3280777zDJZdcwlFHHcXxxx9/yO/w+/2ce+65pKen8+WXX1JUVNSgPqdWQkICs2fPJisri7Vr1/LrX/+ahIQEfv/733PBBRfwzTff8L///Y8PP/wQgMTExIM+o6ysjAkTJjB69Gi++uor9uzZw5VXXsn06dMbBLhPPvmEzMxMPvnkEzZv3swFF1zAsGHD+PWvf33In6exn6822CxatAiv18u0adO44IILWLhwIQBTpkxh+PDhPPXUU9jtdlavXh1YaXzatGlUVVWxePFi4uLiWLduHfHx8a1uR2so3ASZJvITkSNKdTncnxX+7/1/O8EZ16JTL7/8cv7617+yaNEixo4dC1hDUpMnTw4sqnzLLbcEzr/22mtZsGABr776aovCzYcffsh3333HggULyMqyrsX9999/UJ3MHXfcEdju1asXt9xyC3PnzuX3v/89MTExxMfH43A4yMjIaPK7XnrpJSorK5kzZw5xcdbP/8QTTzBp0iT+/Oc/k56eDkBycjJPPPEEdrudAQMGcMYZZ/DRRx+1Kdx89NFHrF27ltzc3MDajHPmzGHw4MF89dVXHHfccWzbto3f/e53DBgwAIC+ffsG3r9t2zYmT57MkCFDAOjTp0+r29BaGpYKsgRN5Cci0q4MGDCAE044geeeew6AzZs3s2TJEq644goAfD4ff/zjHxkyZAgpKSnEx8ezYMGCBpPINmf9+vVkZ2cHgg3A6NGjDzrvlVdeYcyYMWRkZBAfH88dd9zR4u+o/105OTmBYAMwZswY/H4/GzZsCOwbPHgwdrs98DozM5M9e/a06rvqf2d2dnaDRacHDRpEUlIS69evB6xJeK+88krGjx/PAw88wPfffx8497rrruNPf/oTY8aM4e67725TAXdrqecmyLR4pogcUaJirV6USHxvK1xxxRVce+21PPnkk8yaNYujjjqKk08+GYC//vWvPProozzyyCMMGTKEuLg4brjhBqqqqoLW3M8//5wpU6Zw7733MmHCBBITE5k7dy4PPfRQ0L6jvtohoVqGYeD3+0PyXWDd6XXxxRfzzjvv8N5773H33Xczd+5czjnnHK688komTJjAO++8w/vvv8/MmTN56KGHuPbaa0PWHvXcBFnd4pkalhKRI4BhWMND4X60oN6mvvPPPx+bzcZLL73EnDlzuPzyywP1N0uXLuWss87iV7/6FTk5OfTp04eNGze2+LMHDhxIXl4e+fn5gX1ffPFFg3M+++wzevbsye23387IkSPp27cvW7dubXCO0+nE5/Md8ru+/vprysrKAvuWLl2KzWajf//+LW5za9T+fHl5eYF969ato7CwkEGDBgX29evXjxtvvJH333+fc889l1mzZgWOZWdnc/XVV/Pmm29y88038+yzz4akrbUUboJMw1IiIu1PfHw8F1xwATNmzCA/P5/LLrsscKxv37588MEHfPbZZ6xfv57f/OY3De4EOpTx48fTr18/pk6dytdff82SJUu4/fbbG5zTt29ftm3bxty5c/n+++957LHHmDdvXoNzevXqFVhAet++fXg8noO+a8qUKURHRzN16lS++eYbPvnkE6699louueSSQL1NW/l8PlavXt3gsX79esaPH8+QIUOYMmUKK1euZNmyZVx66aWcfPLJjBw5koqKCqZPn87ChQvZunUrS5cu5auvvmLgwIEA3HDDDSxYsIDc3FxWrlzJJ598EjgWKgo3QZaggmIRkXbpiiuu4MCBA0yYMKFBfcwdd9zBsccey4QJExg7diwZGRmcffbZLf5cm83GvHnzqKio4Pjjj+fKK6/kvvvua3DOmWeeyY033sj06dMZNmwYn332GXfeeWeDcyZPnszpp5/OuHHj6NKlS6O3o8fGxrJgwQIKCgo47rjjOO+88zj11FN54oknWncxGlFaWsrw4cMbPCZNmoRhGLz11lskJydz0kknMX78ePr06cMrr7wCgN1uZ//+/Vx66aX069eP888/n4kTJ3LvvfcCVmiaNm0aAwcO5PTTT6dfv378/e9/P+z2Nscwm1u5shMqLi4mMTGRoqIi3G530D//2cU/cN+76zlrWBaPXjg86J8vIhIplZWV5Obm0rt3b6KjoyPdHOmEmvsda83fb/XcBFntsJSWXxAREYkMhZsgqysoVrgRERGJBIWbIKtdPFNrS4mIiESGwk2Q6W4pERGRyFK4CTItnCkind0Rdh+KhFGwfrcUboKstuam1OPVPwAi0qnUznpbXh6BhTLliFA7K3T9pSPaQssvBFntsJTPb1Je5SPOpUssIp2D3W4nKSkpsEZRbGxsYJZfkcPl9/vZu3cvsbGxOByH97dTf3mDLCbKjt1m4POblFR6FW5EpFOpXbG6rYswijTHZrPRo0ePww7N+ssbZIZhEO9yUFRRTUllNRmJmuhKRDoPwzDIzMyka9euVFfrrlAJLqfTic12+BUzCjchkBBdE25UVCwinZTdbj/sugiRUFFBcQhoIj8REZHIUbgJgbq5btRlKyIiEm4KNyFQtzK4em5ERETCTeEmBNRzIyIiEjkKNyEQmMhPPTciIiJhp3ATAgmBxTMVbkRERMJN4SYE4rV4poiISMQo3IRA3a3gqrkREREJN4WbENDK4CIiIpGjcBMCCRqWEhERiRiFmxDQsJSIiEjkKNyEQLwm8RMREYkYhZsQ0LCUiIhI5CjchEDtsFSVz4/H64twa0RERI4sCjchUDssBeq9ERERCTeFmxCw2wzV3YiIiESIwk2I1IUb3TElIiISTgo3IVJbVKzFM0VERMJL4SZEtHimiIhIZCjchIgm8hMREYkMhZsQ0crgIiIikaFwEyJuhRsREZGIULgJkdphqVKPhqVERETCSeEmRBI0z42IiEhERDTcLF68mEmTJpGVlYVhGMyfP7/F7126dCkOh4Nhw4aFrH2HQ+tLiYiIREZEw01ZWRk5OTk8+eSTrXpfYWEhl156KaeeemqIWnb44muGpYp1t5SIiEhYOQ59SuhMnDiRiRMntvp9V199NRdffDF2u71VvT3hFJjEz6OeGxERkXDqcDU3s2bN4ocffuDuu+9u0fkej4fi4uIGj3DQsJSIiEhkdKhws2nTJm677TZeeOEFHI6WdTrNnDmTxMTEwCM7OzvErbS4NYmfiIhIRHSYcOPz+bj44ou599576devX4vfN2PGDIqKigKPvLy8ELayjnpuREREIiOiNTetUVJSwvLly1m1ahXTp08HwO/3Y5omDoeD999/n1NOOeWg97lcLlwuV7ibG1gVvLzKh9fnx2HvMDlSRESkQ+sw4cbtdrN27doG+/7+97/z8ccf8/rrr9O7d+8ItaxxtZP4AZR5fCTGKtyIiIiEQ0TDTWlpKZs3bw68zs3NZfXq1aSkpNCjRw9mzJjBjh07mDNnDjabjWOOOabB+7t27Up0dPRB+9sDp8OGy2HD4/VTXFlNYmzUod8kIiIihy2i4Wb58uWMGzcu8Pqmm24CYOrUqcyePZv8/Hy2bdsWqeYdtoToKDylHtXdiIiIhJFhmqYZ6UaEU3FxMYmJiRQVFeF2u0P6XeMeXEjuvjJeueonjOqTGtLvEhER6cxa8/dbhSAhpDumREREwk/hJoQ0S7GIiEj4KdyEUIJLE/mJiIiEm8JNCNX23BRrWEpERCRsFG5CKF41NyIiImGncBNCtRP5lXo0LCUiIhIuCjch5FbPjYiISNgp3ISQbgUXEREJP4WbEKodltLdUiIiIuGjcBNCtSuDq+dGREQkfBRuQkjDUiIiIuGncBNCGpYSEREJP4WbEHLXW37hCFufVEREJGIUbkKodhI/vwllVb4It0ZEROTIoHATQjFRduw2A4BS1d2IiIiEhcJNCBmGUa+oWHU3IiIi4aBwE2JaPFNERCS8HJFuQKdRXgBLHgJfNfz8L4HdCa4ooEI9NyIiImGinptg8VXB50/AV8+C3x/YrZXBRUREwkvhJliik6xn0w9VJYHd9W8HFxERkdBTuAmWqGhwRFvbFYWB3ZrIT0REJLwUboIpOtF6riwK7NISDCIiIuGlcBNMtUNTlYWBXQo3IiIi4aVwE0wxSdZzvWGpeFftsJTCjYiISDgo3ARTsz03qrkREREJB4WbYFLNjYiISMQp3ARTI8NS7tq7pTzquREREQkHhZtgamRYSpP4iYiIhJfCTTA10nNTOyylVcFFRETCQ+EmmBotKNbdUiIiIuGkcBNMzRQUV/n8VFb7ItEqERGRI4rCTTA1Ns+Ns27hdfXeiIiIhJ7CTTA1MixlsxnEu7R4poiISLgo3ART/Z4b0wzs1kR+IiIi4aNwE0y1NTf+aqiuCOzWRH4iIiLho3ATTM54MOzWdqN3TKnnRkREJNQUboLJMJqd66ZYPTciIiIhp3ATbI3NUuzSRH4iIiLhonATbLV1Nw16bjSRn4iISLgo3ARb7bBUvYn83LpbSkREJGwUboKt0SUYdLeUiIhIuCjcBFtjsxTX1NyUeNRzIyIiEmoKN8GmxTNFREQiSuEm2BotKNawlIiISLgo3ARbIwXFmsRPREQkfBRugk0FxSIiIhGlcBNszcxQrFXBRUREQi+i4Wbx4sVMmjSJrKwsDMNg/vz5zZ7/6aefMmbMGFJTU4mJiWHAgAE8/PDD4WlsS9XW3DRSUFxe5cPr80egUSIiIkcORyS/vKysjJycHC6//HLOPffcQ54fFxfH9OnTGTp0KHFxcXz66af85je/IS4ujquuuioMLW6BwLBU/Zqbustc6vGSFOsMc6NERESOHBENNxMnTmTixIktPn/48OEMHz488LpXr168+eabLFmypMlw4/F48Hg8gdfFxcVtb3BL1A5LVZeDtwocTqLsNqKjbFRW+ympVLgREREJpQ5dc7Nq1So+++wzTj755CbPmTlzJomJiYFHdnZ2aBvlSgQMa7uRoali3TElIiISUh0y3HTv3h2Xy8XIkSOZNm0aV155ZZPnzpgxg6KiosAjLy8vtI2z2SDabW3XLyrWyuAiIiJhEdFhqbZasmQJpaWlfPHFF9x2220cffTRXHTRRY2e63K5cLlc4W1gdKJVc6PbwUVERMKuQ4ab3r17AzBkyBB2797NPffc02S4iYjoJGBb4xP5aX0pERGRkOqQw1L1+f3+BgXD7UIzc92o50ZERCS0ItpzU1payubNmwOvc3NzWb16NSkpKfTo0YMZM2awY8cO5syZA8CTTz5Jjx49GDBgAGDNk/Pggw9y3XXXRaT9TWpkluLAyuAKNyIiIiEV0XCzfPlyxo0bF3h90003ATB16lRmz55Nfn4+27ZtCxz3+/3MmDGD3NxcHA4HRx11FH/+85/5zW9+E/a2N6vRxTO1MriIiEg4RDTcjB07FtM0mzw+e/bsBq+vvfZarr322hC3KggCi2cWBnbVDUup5kZERCSUOnzNTbvUyLCUO8bquSmsULgREREJJYWbUGikoDgt3pqVuKC0KvztEREROYIo3IRCI+tLpcZZc+3sL2tnd3aJiIh0Mgo3oVAbbur13KTW9NzsV8+NiIhISCnchEKgoLhez01NuDlQXoXP33QRtYiIiBwehZtQaKSgOKVmJXC/CYXl6r0REREJFYWbUKjtufEUg98HgMNuIznWumNqf5nCjYiISKgo3IRC7SR+8KOhKauoeF+piopFRERCReEmFOxREBVnbdcbmkqNU1GxiIhIqCnchEqjc93U3A6unhsREZGQUbgJlUaKigO3g6vmRkREJGQUbkKlkZ6b2on89mlYSkREJGQUbkKltqi4/u3ggYn8NCwlIiISKgo3odLIEgxpcRqWEhERCTWFm1BpbFhKBcUiIiIhp3ATKs0VFKvmRkREJGQUbkKltuam/q3gNQXFJR4vHq8vAo0SERHp/BRuQiWweGZhYJc7xoHDZgBQoLobERGRkFC4CZVGCooNw9DQlIiISIgp3IRKIwXFUH+uGxUVi4iIhILCTag0UlAMKioWEREJNYWbUAlM4lcEfn9gd2B9qTL13IiIiISCwk2o1A5LmX6oKg3s1srgIiIioaVwEypRMWC3emkaW4JB60uJiIiEhsJNKDVSVFw7142GpUREREKjTeEmLy+P7du3B14vW7aMG264gWeeeSZoDesUGlk8UwXFIiIiodWmcHPxxRfzySefALBr1y5OO+00li1bxu23384f/vCHoDawQ6u9Y0rrS4mIiIRNm8LNN998w/HHHw/Aq6++yjHHHMNnn33Giy++yOzZs4PZvo4tMEtx3UR+qfVWBjdNMwKNEhER6dzaFG6qq6txuaweiA8//JAzzzwTgAEDBpCfnx+81nV0zSye6fH6KavS+lIiIiLB1qZwM3jwYJ5++mmWLFnCBx98wOmnnw7Azp07SU1NDWoDO7RGCopjnQ5inXZAQ1MiIiKh0KZw8+c//5l//OMfjB07losuuoicnBwA3n777cBwldBoQTHU9d7odnAREZHgc7TlTWPHjmXfvn0UFxeTnJwc2H/VVVcRGxsbtMZ1eI0sngnW+lJ5BRXquREREQmBNvXcVFRU4PF4AsFm69atPPLII2zYsIGuXbsGtYEdWhOLZ6bF1xUVi4iISHC1KdycddZZzJkzB4DCwkJGjRrFQw89xNlnn81TTz0V1AZ2aE0tnhmn28FFRERCpU3hZuXKlZx44okAvP7666Snp7N161bmzJnDY489FtQGdmi1NTc/6rnREgwiIiKh06ZwU15eTkJCAgDvv/8+5557LjabjZ/85Cds3bo1qA3s0ALz3BQ22F1/rhsREREJrjaFm6OPPpr58+eTl5fHggUL+NnPfgbAnj17cLvdQW1gh1a/oLjehH1pmqVYREQkZNoUbu666y5uueUWevXqxfHHH8/o0aMBqxdn+PDhQW1gh1bbc+OrguqKwG6tLyUiIhI6bboV/LzzzuOnP/0p+fn5gTluAE499VTOOeecoDWuw3PGg2EH02cNTTmt2+QDBcUalhIREQm6NoUbgIyMDDIyMgKrg3fv3l0T+P2YYVhFxRUFVlGxOwuouxW8oMyD329isxkRbKSIiEjn0qZhKb/fzx/+8AcSExPp2bMnPXv2JCkpiT/+8Y/4/f5gt7Fja2TxzOSagmK/CYUV1RFolIiISOfVpp6b22+/nX/961888MADjBkzBoBPP/2Ue+65h8rKSu67776gNrJDa2Sumyi7jaTYKArLq9lf6iGlJuyIiIjI4WtTuHn++ef55z//GVgNHGDo0KF069aN3/72two39TUxS3FqnJPC8mr2lVbRNz3srRIREem02jQsVVBQwIABAw7aP2DAAAoKCg67UZ1Kk4tn1hYV63ZwERGRYGpTuMnJyeGJJ544aP8TTzzB0KFDD7tRnUrtsFRT60vpdnAREZGgatOw1F/+8hfOOOMMPvzww8AcN59//jl5eXm8++67QW1gh9dIQTFofSkREZFQaVPPzcknn8zGjRs555xzKCwspLCwkHPPPZdvv/2Wf//738FuY8fWxOKZtUXE+zTXjYiISFC1KdwAZGVlcd999/HGG2/wxhtv8Kc//YkDBw7wr3/9q8WfsXjxYiZNmkRWVhaGYTB//vxmz3/zzTc57bTT6NKlC263m9GjR7NgwYK2/gjh0URBcd2wlHpuREREgqnN4SYYysrKyMnJ4cknn2zR+YsXL+a0007j3XffZcWKFYwbN45JkyaxatWqELf0MByqoFg1NyIiIkHV5hmKg2HixIlMnDixxec/8sgjDV7ff//9vPXWW/znP/9pck0rj8eDx1PXO1JcXNymtrZZEwXFWhlcREQkNCLac3O4/H4/JSUlpKSkNHnOzJkzSUxMDDyys7PD2EKaLijWyuAiIiIh0aqem3PPPbfZ44WFhYfTllZ78MEHKS0t5fzzz2/ynBkzZnDTTTcFXhcXF4c34DRRUFxbc1Nc6aXK68fp6NA5U0REpN1oVbhJTEw85PFLL730sBrUUi+99BL33nsvb731Fl27dm3yPJfLhcvlCkubGlVbc1NdDt4qcFihxh0dhcNm4PWbFJRVkZEYHbk2ioiIdCKtCjezZs0KVTtaZe7cuVx55ZW89tprjB8/PtLNaV50vUBYWQjxVhCz2QxS4pzsKfGwr9SjcCMiIhIkHW4s5OWXX+b//u//ePnllznjjDMi3ZxDs9nBVXvHVBN1NyoqFhERCZqI3i1VWlrK5s2bA69zc3NZvXo1KSkp9OjRgxkzZrBjxw7mzJkDWENRU6dO5dFHH2XUqFHs2rULgJiYmEMOmUVUTCJ4ijTXjYiISBhEtOdm+fLlDB8+PHAb90033cTw4cO56667AMjPz2fbtm2B85955hm8Xi/Tpk0jMzMz8Lj++usj0v4Wa6KoOHA7uOa6ERERCZqI9tyMHTsW0zSbPD579uwGrxcuXBjaBoVKbd3Nj3puUmrWl9qnlcFFRESCpsPV3HRIgbluChvsTtXK4CIiIkGncBMOh5jrRjU3IiIiwaNwEw5NLJ6ZGqe7pURERIJN4SYcmlw8U8NSIiIiwaZwEw5NLJ6ZFpjnxtNsYbWIiIi0nMJNOMQkW88HTeJn9dxUVvspr/KFu1UiIiKdksJNODRRUBzrdBATZQc0NCUiIhIsCjfhECgoLjroUG3vjea6ERERCQ6Fm3BooqAY6q0vpZ4bERGRoFC4CYfaYSlPMfgb1takxWmuGxERkWBSuAmH2mEpOKioOKU23GiuGxERkaBQuAkHexRExVnbB811U7O+lHpuREREgkLhJlyaWDwzTRP5iYiIBJXCTbgcavFM3S0lIiISFAo34dLELMWB9aXUcyMiIhIUCjfhEui5aXyWYhUUi4iIBIfCTbg0MUtx7fpSBWVV+P1aX0pERORwKdyESxMFxcmxVs+Nz29SVFEd5kaJiIh0Pgo34dJEQbHTYSMxJgpQUbGIiEgwKNyES1wX67k4/6BDgfWlVFQsIiJy2BRuwiX1aOt5/+aDDqXpjikREZGgUbgJl9pwc2AL+BrW1miuGxERkeBRuAmXhEyIigXTBwe2NjhUu76UhqVEREQOn8JNuNhskHKUtV3wfYNDtetLaWVwERGRw6dwE06pNeHmR3U3Wl9KREQkeBRuwqmJouLAEgyquRERETlsCjfh1FS40RIMIiIiQaNwE06BcNOw5kbDUiIiIsGjcBNOtTU3xTugqqxud82wVFFFNVVefyRaJiIi0mko3IRTbArEpFjbBT8EdifGRGG3GQAcKFfvjYiIyOFQuAm3RupubDaj3lw3KioWERE5HAo34dbk7eDW0FR+YWW4WyQiItKpKNyEWyDcNCwqHpiZAMDaHUXhbpGIiEinonATbk3cDp7TPQmANdsLw9seERGRTkbhJtyaCjfZSQB8vb0I0zTD3CgREZHOQ+Em3FL6WM8VB6C8ILB7YGYCUXaDgrIqth+oiFDjREREOj6Fm3BzxoG7m7Vdr+7G5bAzKNMNwOq8wgg0TEREpHNQuImEJu6YCgxNKdyIiIi0mcJNJByiqPhrFRWLiIi0mcJNJByiqHjtjiK8Pi3DICIi0hYKN5HQxAKafdLiSHA5qKz2s2lPaQQaJiIi0vEp3ERCbbgp+B78dT00NpvBkO6JgOpuRERE2krhJhKSeoDNAdXlUJLf4FDdfDeF4W+XiIhIJ6BwEwn2KEjuZW03UVS8Ok/LMIiIiLSFwk2kNFFUPKym52bj7hLKq7xhbpSIiEjHp3ATKSmNL6CZkRhNutuFz2/y7c7iCDRMRESkY1O4iZQmJvKDevPdqKhYRESk1SIabhYvXsykSZPIysrCMAzmz5/f7Pn5+flcfPHF9OvXD5vNxg033BCWdoZE/TumfqS2qFjLMIiIiLReRMNNWVkZOTk5PPnkky063+Px0KVLF+644w5ycnJC3LoQqw03B7aAr7rBodqemzXbVVQsIiLSWo5IfvnEiROZOHFii8/v1asXjz76KADPPfdci97j8XjweDyB18XF7aSOJSETomKt28ELt9UNU0FgrpttBeUUlFWREueMVCtFREQ6nE5fczNz5kwSExMDj+zs7Eg3yWKz1Ssqblh3kxgTRZ8ucYDmuxEREWmtTh9uZsyYQVFRUeCRl5cX6SbVaaaoeJiKikVERNqk04cbl8uF2+1u8Gg3mpjrBurNVKxwIyIi0iqdPty0ay0JN9uLME0zjI0SERHp2BRuIqmJ1cEBBmYmEGU3KCirYvuBijA3TEREpOOK6N1SpaWlbN5c12uRm5vL6tWrSUlJoUePHsyYMYMdO3YwZ86cwDmrV68OvHfv3r2sXr0ap9PJoEGDwt38w1dbc1O8A6rKwBkXOORy2BmY6WbN9iJW5xWSnRIboUaKiIh0LBENN8uXL2fcuHGB1zfddBMAU6dOZfbs2eTn57Nt27YG7xk+fHhge8WKFbz00kv07NmTLVu2hKXNQRWbAjEpUFEABT9AxpAGh3O6J7FmexFrthcyKScrQo0UERHpWCIabsaOHdtsPcns2bMP2tfp6k9Sj4bty6y6mx+Hm+wk/v3FVr7WCuEiIiItppqbSGumqHhYtjWZ39odRXh9/nC2SkREpMNSuIm01D7W8/4fDjrUJy2eeJeDimofm/aUhrlhIiIiHZPCTaQ103NjsxkMrVmKQfPdiIiItIzCTaQ1E24AhtbOVKxlGERERFpE4SbSUmqGpSoKoLzgoMO1dTerVVQsIiLSIgo3keaMA3c3a7uRyfxqZyreuLuEiipfGBsmIiLSMSnctAfNLKCZ4Y6ma4ILn9/k253qvRERETkUhZv2oJm6G8MwAr03q1VULCIickgKN+3BIYqKh9VbRFNERESap3DTHjSzgCZYyzAArNx6oPPN0CwiIhJkCjftQW24Kfge/AfPRHxszyRinXZ2FFawfOuBMDdORESkY1G4aQ+SeoDNAdXlUJJ/0OFYp4MzhmQC8OpXeeFunYiISIeicNMe2KMguZe1vWtto6ecf1w2AO+szafM4w1Tw0RERDoehZv24qhTrOe1rzV6eGTPZHqnxVFe5eOdtQf37oiIiIhF4aa9GHax9fzdf6Gi8KDDhmHwy5HdAXhtuYamREREmqJw015kDoOug8BbCd/Oa/SUycd2x2bAV1sO8MNerRIuIiLSGIWb9sIwIOcia3v1S42eku6O5uR+XQB4fcX2cLVMRESkQ1G4aU+Gng+GHbYvg32bGj3l/JFWYfEbK7fj9R1827iIiMiRTuGmPUnIgKPHW9tfv9zoKacOTCclzsnuYg9LNu0LY+NEREQ6BoWb9qa2sPjrueA/eBVwp8PG2cOsVcRfVWGxiIjIQRRu2pv+EyE6CYp3QO6iRk+pvWvqw/W7KSirCmPjRERE2j+Fm/bG4YIhv7S2mygsHpjpZki3RKp9JvNX7Qhj40RERNo/hZv2aFjNXVPr/wOVja8Efn5N782ry/O0mKaIiEg9CjftUdax0GVAs3PenJnTDafDxne7SvhmR3GYGygiItJ+Kdy0R4ZRV1jcxNBUYmwUEwZnAPDaChUWi4iI1FK4aa+GXgCGDfK+hH2bGz2ldmhq/qodVFYffGeViIjIkUjhpr1qMOdN4703JxyVRrekGIorvby/bncYGyciItJ+Kdy0Z4eY88ZuM5g8QotpioiI1Kdw0571mwjRic3PeVMTbj7dvI8dhRXhbJ2IiEi7pHDTnkVFwzHnWdurG1+OITslltF9UjFNmPbiStZsLwxf+0RERNohhZv2btgU67mZOW+uH9+X6Cgbq/MKOfOJpdz06mp2FVWGsZEiIiLth8JNe9ftWEjrD94K+HZ+o6f8pE8qn9wylnOHW2tOvblyB+MeXMijH26iokp3UYmIyJFF4aa9qz/nzYrZ4Pc3elpmYgx/u2AY86eNYUTPZCqqfTz84UZOeWgh81Ztx+/XLMYiInJkULjpCHIuBEcM7FwJXzzZ7KnDspN4/erRPHHxcLolxZBfVMmNr3zNL//xOYXlWmRTREQ6P4WbjiAhA06/39r+8F7YubrZ0w3D4BdDs/jo5pP53YT+xDntrNh6gKtfWEGVt/GeHxERkc5C4aajGPF/MOAX4K+GN66EqrJDviU6ys60cUfzxm9PIN7l4IsfCvh/89ZqoU0REenUFG46CsOAMx+HhEzYvwkW/L8Wv3VAhpsnLh6OzYDXV2zn7wu/D2FDRUREIkvhpiOJTYFzngYMq7h4/X9a/Nax/bty75mDAfjrgg28syY/NG0UERGJMIWbjqbPWBhznbX99rVQtKPFb71kdC/+b0wvAG56dTWrth0IfvtEREQiTOGmIxp3B2QOg4oDMO83ja471ZQ7zhjEKQO64vH6+fWc5eQVlIeunSIiIhGgcNMROZww+V8QFQtblsBnj7X4rXabwWMXDWdgppt9pVVc8fxXFFdWh7CxIiIi4aVw01GlHQ0T/2xtf/wn2LGyxW+Ndzl47rKRdE1wsXF3KdNeXInXp1vERUSkc1C46ciGXwKDzgK/17o93FPa4rdmJsbwr6nHERNlZ8mmffzxv+tC2FAREZHwUbjpyAwDJj0K7m5Q8D28cQV4Wz4L8ZDuiTxy4TAAnv98Kwu+3RWihoqIiISPwk1HF5MM5z0HjmjY+D8r4Pi8LX77hMEZ/OakPgDc+sYarSYuIiIdnsJNZ9DjJ3DBi2B3wvq3Yf7VrbqD6uaf9eeYbm4Ky6u56dXVWmRTREQ6NIWbzqLvePjl82BzwNrX4O3rmlxB/MecDhuPXjicmCg7n32/n2eW/BDixoqIiIRORMPN4sWLmTRpEllZWRiGwfz58w/5noULF3Lsscficrk4+uijmT17dsjb2WEM+Ll1i7hhg9UvwLu3QAvXkTqqSzz3nDkIgAcXbGDN9sIQNlRERCR0IhpuysrKyMnJ4cknn2zR+bm5uZxxxhmMGzeO1atXc8MNN3DllVeyYMGCELe0Axl8NpzzD8CA5f+y1qBqYcA5f2Q2E4/JwOs3uX7uaso8La/dERERaS8Ms50sEW0YBvPmzePss89u8pxbb72Vd955h2+++Saw78ILL6SwsJD//e9/jb7H4/Hg8XgCr4uLi8nOzqaoqAi32x209rc7K/8Nb0+3tn96I5x6t3V31SEUllcx8dEl5BdVcv7I7vzlvJwQN1REROTQiouLSUxMbNHf7w5Vc/P5558zfvz4BvsmTJjA559/3uR7Zs6cSWJiYuCRnZ0d6ma2D8deAmc8ZG1/+jAsnNmiGpykWCcPXzAMw4BXl2/XApsiItLhdKhws2vXLtLT0xvsS09Pp7i4mIqKikbfM2PGDIqKigKPvLy8cDS1fTjuSphwv7W96M/wr/Gw7YtDvu0nfVL57dijAJjx5hp2FDZ+bUVERNqjDhVu2sLlcuF2uxs8jiijp8HPHwRnPOxYAc9NgNcugwNbmn3bDeP7kZOdRHGllxvnrtbyDCIi0mF0qHCTkZHB7t27G+zbvXs3brebmJiYCLWqAzj+13DtSjj2UsCAb+fBE8fDB3dDZXGjb4my23jswmHEOe0s21LA6Ac+5q63vuGLH/bj0zw4IiLSjnWocDN69Gg++uijBvs++OADRo8eHaEWdSAJ6XDm43D1Euh9Evg8sPQReGw4LH+u0VmNe6bG8bcLhuGOdrC3xMOcz7dy4TNf8JOZH3HnfAUdERFpnyJ6t1RpaSmbN28GYPjw4fztb39j3LhxpKSk0KNHD2bMmMGOHTuYM2cOYN0KfswxxzBt2jQuv/xyPv74Y6677jreeecdJkyY0KLvbE21dadlmtZSDe/fAfut64+7Gwz5JQy9ANIHNTi9yutn6eZ9vLM2n/e/3UVxZV0QSot3MSw7CY/XR0WVj4pq67m8Ztvj9XHhcT24e9IgjBbcrSUiItKY1vz9jmi4WbhwIePGjTto/9SpU5k9ezaXXXYZW7ZsYeHChQ3ec+ONN7Ju3Tq6d+/OnXfeyWWXXdbi71S4qcdXbfXaLHwAKgrq9qcPgaG/hGPOg8RuDd5S5fWz9Pt9vLsmn/fX7aaoorpFX/XHs4/hkp/0DGbrRUTkCNJhwk0kKNw0oroSNr0Pa16BjQvAXxtYDOh9Igy9EIaeD/aoBm+r8vr5/If95BWUE+u0ExNlJ8ZpJ9bpINZpJzrKzntr83nog404bAYvX/UTjuuVEv6fT0REOjyFm2Yo3BxCeQGsewvWvArbPqvb328inP88OFyt+jjTNJn+8ireWZNPWryL/177UzISo4PcaBER6ew67SR+EgaxKTDy/+Dy9+D6NTDuDnBEw8b34JVfWb08rWAYBn89bygDMhLYV+rhmhdX4PG2fMVyERGR1lK4kaYl94STfwcXvwKOGGvoau7FUN26Sf1inQ7+cckI3NEOVm0r5N7/rAtRg0VERBRupCX6jIUpr0FUHHz/Ebx8IVSVt+ojeqbG8ehFwzEMeOnLbby8bFto2ioiIkc8hRtpmd4nwq9et2Y6/mEhvHQ+VJW16iPG9e/KLT/rD8Ddb33Lym0HQtBQERE50incSMv1PAF+9SY4E2DLEnjhPPCUtOojfjv2KE4fnEGVz881L6xgT0nranhEREQOReFGWqfHKLh0PrgSrbupXpjc5BIOjTEMgwfPz+HorvHsLvYw7cWV7ClWwBERkeDRreDSNjtWwr/PgcpCSOwBXfpDXBeIS4XYtJrtNGs7IQPi08HuCLz9h72lnPXEUko81mzHw7KTOG1QOuMHptMvPV6zGYuISAOa56YZCjdBlP81zDm74ezGTTFsVsBJyAR3Fri7sc2byEubHPxr7wCqqQs+2SkxjB+YzmkD0zmudwpR9nbWwbhnvbXC+tALGwQ2EREJHYWbZijcBFl5AeR9CWX7oHyf9RzY3mttl+4G/8ELc9byJvXms6Nu4Pl9g/j0+/14vP7AsbR4F/83phe/GtWTxNioJj8jbArz4OkxUFkEx0yGc58Fmz3SrRIR6fQUbpqhcBMBfr8VdIp3QPFOKMmv2/7+EyjbY53X+yQqTv0TS4rS+XD9bj5av4f9ZVUAxDrtXHhcD644sTfdkmIi83P4vDD7DMj7om7f0Avh7L8r4IiIhJjCTTMUbtoZTwl8+jB89gT4PNbw1fBL4JQ7qI5J479rdvKPRT/w3S7rriy7zWDS0EyuOukoBmWF+b/fJ/fDoj9bd4uN+3/Wquqmz2rvpMfA1s6Gz0REOhGFm2Yo3LRTB7bCh3fDt/Os184EOOlmGHUNpsPF4k37eGbx9yzdvD/wlhP7pnHeiO6c2LcLKXHO0LZvy6fw/CQw/TD5XzDkPPjmDXjjSmvfyMvhjL+BCqFFREJC4aYZCjft3NbPYcEM2LnKep2QBSOmwrGXgjuLb3YU8Y/FP/DOmp34a35zDQOGdk/i5H5dOLlfGjndk3AEswi5vACeGgMlO2HYr+DsJ+uOff0KzPsNYMKoq+H0BxRwRERCQOGmGQo3HYDfD2tegY/utepzAAw79J9oLerZ5xTyCit5adk2Fm7Yy/r8hvPsuKMdnNi3Cyf1S+MnfVLpkRLb9lvLTRPmToEN70Dq0XDVInDFNzxn1Qvw1jRr+4Rr4bQ/KuCIiASZwk0zFG46EK8H1v8Hlj8HW5fW7U/uBSMus3pRohPZu2sra9etY+sPmyjYtYVk714yjAJSDSv0RNntJERHkRAThTvGSYzTYYWdroPgJ7+FpOzAR1dW+9hb4mFfqYd9pVUkf/s8I7+9D68RxYPZT7La24P9pVX4TJPBWYnkdE9kaPckhu1+E+f/brY+5MSb4ZQ7FXBERIJI4aYZCjcd1J7vYMUsWP0yeIqsfYbdqneh7b/CPux8Ej2eWcbZfF2eSqmn7pb1AcY23nLeicuo5t7qS5jlm9jk59gMuCVpIb+teAaAsgG/JG7YOdBzDMQktbl9IiJiUbhphsJNB1dVDt++afXm7Fhh7bM7AxMD1j13g7g0qvwmuXtL2by7hO/3lrJlXylenx+n4eVc2xJOsK8DwGcavOUfw9+9Z7LN3oPucfC893dk+/JYnzCa/wx6mLSEaFLjnXSJd+H1m6zdUcTXeYWs2V7ErpolJK6wv8OdUS8GmmsaNoyModbCo71Phh4/AVeCddDrsQqpD+TCgS1QkGttO+Ph5N9bsz6LiAigcNMshZtOpDAPHNEQm9ri27A9Xh9rtxexbEsBlVU+BnrXMWLrc3TdvRgAEwMGnYlh2Kw7t+Iz4Jql1lISzdhdXBkIOp4NH9Bzz8eMtq3jKFt+wxMNuzUcVnHAmuunqV4nWxScMB1O+h0+RyyllV6KK6spq/LSPTmWeFdwZkY2vR62fjGP8mUvcFTxF+Qa2byXeCH5WafRs4ubnqmx9EqNo0dqLO7oJiZRrK6ETe+DzQF9f6ZZm0UkJBRumqFwI43auQqWPGTV+AQY1iKhfca2+uM27i7hn0t+4PNV33Cs+Q0n2NZxYtR6sszdDc7zOWIpi8tmvzOLfCODXF8X+pV8wXFVy6xmmWncXX0pH/hHBt7jctg4dWBXJg3NYtyArkRH2a3C593fWEtiuLMgta/Ve9VY6DNNSn74ku0Ln6Pb9ndxmwev7P6DP4OnfZOY5zsxsDRG1wQXFxyXzdQTepEW77KGClc+D1+/bIU1gOTe8NMbIOcicLhafd3Czl8zG7bmKBJp9xRumqFwI83avQ4+/Rt8Ox/G3gYn3XJYH7enpJI5n23lhS+3UlheTXdjLzmObezxu8n1dWUfbuDHhccmp9lWcHfUHLob+wD4wHcsD5iXsdeRQXGlVRfkpJpxrg1ckrKOkZ5lRJfvbPgxUbGQchSkHQ2pffGnHs223I1Er3uVjKptdT+ymcw3qRNIO+480vd8Sso3z+Gstoqx99tSeZ5JPFt+EhVEE42HM6O+4rcJS+hVvrbuu9zdoLqibp2xhCzrzrERU8EZh89vsrfEw86iCvILK8kvqmBn7XORNaR31Yl9+PmQjNAumlpeAHnLrCVD8pZZQ5veCmteJVcjj5gk6xp2GWANEyb1VBASiRCFm2Yo3EiL+P1B/SNWXuXljRXb+eenuWzdXw5Ysy1nuKPplhRDVlI0mUkxZCXF0DXBhTs6Cre9iu5rn8S96mkMfzU4ojFPvJkdvmTK1v6H7ANfEktl4DsqcLIjdhAJ3gLSqnZgx9dkeypMJ1+4RuM95gKOP2UyifHRdQc9JbBitjVrdOkuAMzoZPK7nIB7+0LizTIAvKaNtfGjiR99JX1POAu8lbDieczPHscosYJWmSOJec4zebj4ZPZ7Y4ihkixjP5lGAVnGPrKM/WSxn1SjGCfVpEYb9EqOItbuA181+KqshzMBErvXe2TXbSdkWoXl1WVWwKoqh+qaR1UZFG2vCzT7Nx3ef0hHDKT1ha4DrbDTZYA1zKjQIxJyCjfNULiRSPL5TTbtKSExJoquCdHYbS3opdi7Ad65GbYsOehQVWw6X8f8hBcPDOR/5f2pxBoKsuMj29hDHyO/5rGTo2z5eA0Xu3v8nP7jfsWg3t2a7yXxeqwhp08fsQqda1TGd+cdx8/4864R7CEZgJE9k8nJTmLtjiI27tjH6b6FXGN/m542a92wMtOFhyhSjNKWX6xQSesH2cdD9ijofrxVs+UptkJd4LnmUb4f9m2Cvd/Bvo1W0GqMM94KPF0HQfpg69F1EMSmhPdnEwHwVkFRnrVoMQBGvakparcNK5DbHFaNnz3KWiPPFmXts0dZy+EYNmu/Ya95ttVshz/MK9w0Q+FGOiTThLWvW3VBDif0mwj9T4fMYWAYeH1+Pv9hP8tyC4iOsuOOicId7ah7jo7CHRNFSpyTqNbO3uzzwrr5Vl3S0adC77Fgs7FpdwnPLvmBeat2UO1r+M9IrNPO0Mx4Lohdzqn7X8BdXK/HJNAL062u9yU+nQNVNuat2ctnW0qoxoEjysVZI3oxMSebqOoSqwemKK/muXZ7B/ir6z7bsIMzzhqSi4qxtmNToPtxNWHmuLYHDp8XCrdaQWfvd1bN0Z71sG9D06HH5rCK3gMPV91zVEy9R2y9R80+uxMwrf/2tVMemCYtnvrAFmV9hr32j1W97drvdMaDM7bmmsVZzw5X+5ijyTSt3sBA2Cy2arvK9kP5PijbZ4XP8n3WPk8JuDOtebCSe1n1X8m9ILmn9XOFQlUZlOyy/vvHpFi/W/YmCu+DxTRrgnfNNSjcVnfH5YGt1nPRdg5niowWCwSe+s814Seh5maMIFK4aYbCjUhw7S6u5KUvt1FYXsUx3axJDY/uGl/XK+X3Q/5q649mYneITmz2877aUsC9//mWb3ZYdT+90+KYNDSTEo+XovJqiirqHiXllTiri+jRxc2Q3lmM7JPOyJ4pJMaG+A9Mfb5q2P897PnWqtna/a21Xbjt0O9tj2r/z9yw1f0fvmFYr2u3TX9d6Kp9UPPaqNcbYLPXBKragOWo6w3AqNs2aj7X77f+cFfVBBq/t/m2tlR8OsR1rXlR8yevNijW/gl0uBrWWznja7bjwe6Csj1QstuaNb1kl9Ur4ik++LtcbohJtoJObKoVeqJirM+3O+seDqf1uTZ7wyFYX1Xda6+nrgex/qOpMF1fVKwVMAxb3c9YPyCbNQ9/tfV9fm/dw1dtLQp8OBIy4ebvDu8zfkThphkKNyLtn99v8vqK7fxlwXfsK23BP+T1GAb0T09gVO8Uju+dysBMa14hn9/E6zcbPPv8Jh6vj8pqP5XVvnoP63W13yQxJoq0eCdp8S5S452kxrlIjo069PplnlLrj5+30voj5a20bpuvfV1dXrOvvKZOqKKuVqi63PoDUz9QYFi157X7mmVaPU3+2j+aXuu59g+Zt9L6zqoyq1apqsza1y4ZdWEjJhniUq3QEJtmTdEQW/PalWBNrxCYM2qL1aNRWRTa5kXFWUGlopCw9JYEvjfW+rkTs+t6q1J6123HdTmsHji/z4/NMMHvs4KO31cTZH1WCA3sq/9cb79hg64DgvTDWhRumqFwI9JxlFRW8/xnW9hRWElSbBSJMdYjqebZHROFy2FjzfYivtpSwLLcAn7YVxbydhkGJMc6SYmrecQ6SY6LCuyrfe6WHEPP1FhcDvshP7PU4+XrvEJWbj3AqrxCKqp8DMpyc0w3N8dkJdKnS3zLarR+xDRNiiu95AfuVKskxmljRI8UslNi6uqu/L6asFNubdf2xAT+T99f1wPQoCfH1vA1ZuM9AX6fFa7q9/hQv/fHtD7D5a7rMXElWOHhcOo7Kg5YQad8P43XntSoroSq0rphsPrbXo8VFhIyrB6JhPSa54y6STn9PitIle+37sqrKLCey/db7/d5ap6rrW1flVUb4/cGhgw9ONhZ4mdLYRW5BdUUeAzKiSYuOZ2h/fow6ph+uFMyrFDjjG37NWmEz2+yZnshCzfsZeHGvazZXsjRXeI5qV8XTurXhVG9U6xpJyJI4aYZCjcinduekkqWbznAstwCvswtYNv+Mmw2A4fNwG6z1TwbOOwGdsPA6bARHWUnOqrm2VG37bAbFJZXs7+0iv1lHvaXVlFQXkVr/tW0GdAtOYY+afH0TovjqC5x9OkST0qck292FLGqJtBs3F0SWOm+MdFRNgZmWkFnUJabmCh7oKfJ4/VbvU1e63VppZddxZXsLKxgV1ElZVWNDzF0SXAxsmcyI3omM7JXCoOz3A1qsnx+k/2lHnYVV7KrqJLdxdZnpbtdpLujyUyMIcMdTYyz8T96ldU+dte+t8TD/lIPUXYbcS47sU4HcU4HsS478S4HsU47UXYbFVU+KqqtR2WVj/J6rw3AFWXH5bDhdNhwOWy4HPaaZxuxLgfxTgdxLnujPWvVPj95BeXk7isjd18ZP+wrI3dvGVv2l+H1m4HPiY6y1312lI04l4MB6QkMqVlLLiXO2fJfgCb4/CallV62FZSzeNNeFm7Yw8pthfjq/RJER9nw+qyeRoAou8EpA7oy+djujBvQtfX1cz9SUFbF4o3Wdy/auJcD5dVNnuty2BjVJ5WT+3Xh5H5pHNUlPrTTNjRC4aYZCjcicjh8fpMD5VVW4Cn1cKC8moLyKg6UVVFQVsWBcut5f2kVeQXllHhaXjfSLSmGY3smMzw7iXiXg293FvHtzmLW5RdT3kRAaank2CgyE2PITIymoLyKb3YUHVQIHh1lY0i3RKp9JruLK9lT4mnwx7YpiTFRZCZGk+6Oxm9a791d7KGoouk/lqHmdNiId1lBJ87poMrrZ1tBeSAoHI7uyTEM7Z7IkG5JDO2eSLrbRWF5tfWoqKawvIrC8moOlFdRWFFNSaWXksq659JKb5OB86gucYzt35WT+3Xh+N4plHq8vL16J2+s3M63O+tqfFLinJyZk0V2itWDY1DTgQaB0OHzm5RUein11H63NdN5SaWX4opqcveXNQjqCdEOTuybxth+XRnZK5n1+SUs2riHxRv3BZaYqX+u3Wbg95vWYJxpDcr5TRPThK5uF4t+N+6wr3V9CjfNULgRkXAxTZN9pVX8sLfU6iXYV2Zt7y1jb6mHARkJDO+RzLE9kji2RzJd3dGNfo7Pb5K7rywQdtbnF2Oa1PUy/KjXKc7lqOlZqX3EHNS7UlntY832IpZvLWD5lgOs2Hqg0TBiMyAt3kVGTXiJdznYU2INb+0qqjxk6IqOspHhjqarO7pmXTY/5VU+yjxe67nKS7nHeq72mcRG2Yl22omJsh7Wto2YKDsmUOX14/H68Xh9eKr9VPn8eGp6rco9Pqp8/mbbExNlp3daHL27xNEnLY7eaXH0Sosj2mG3PrPm82t7xDzVPgrLq/lmZxFrtxcFfdgzweVgVJ9Uxvbvwsn9ugTCSmO+21XMGyu2M2/VTvaVeoLy/QMz3Yzt34Wx/bpwbM/kRnuDTNNk4+5SFm/cy6KNe1mWW3DI69w1wcWy28cHpY21FG6aoXAjInIwv9/k+72lrN1RRKzTQUZiNBnuaNLinU0WT9fW8+wurg07FdgMIxCE0t3RuKMdYR2+qPL6Ka/yUurxUubxUerxUl7lxW4Y9O4SR3pCNLY21C7VKq6s5psdVtBZs6OINdsLKSqvJinWSXJsFIk1z0kxUSTFOgN1YvHRDhJqpmVIiHaQEB1FvMuB09H6oSWvz8+STft4f90uyjxWuDSx/nsE/qCbVk9OQrQ1HUS8yxH43trn3mlxZCQ2HqibU1HlY/uB8pqSJQPDAJth1Os9MrDbDbolxbT6s5ujcNMMhRsREZGOpzV/vzVfuIiIiHQqCjciIiLSqSjciIiISKeicCMiIiKdisKNiIiIdCoKNyIiItKpKNyIiIhIp6JwIyIiIp2Kwo2IiIh0Kgo3IiIi0qko3IiIiEinonAjIiIinYrCjYiIiHQqCjciIiLSqTgi3YBwM00TsJZOFxERkY6h9u927d/x5hxx4aakpASA7OzsCLdEREREWqukpITExMRmzzHMlkSgTsTv97Nz504SEhIwDCOon11cXEx2djZ5eXm43e6gfnZnpOvVerpmraPr1Xq6Zq2j69U6h3O9TNOkpKSErKwsbLbmq2qOuJ4bm81G9+7dQ/odbrdbv+StoOvVerpmraPr1Xq6Zq2j69U6bb1eh+qxqaWCYhEREelUFG5ERESkU1G4CSKXy8Xdd9+Ny+WKdFM6BF2v1tM1ax1dr9bTNWsdXa/WCdf1OuIKikVERKRzU8+NiIiIdCoKNyIiItKpKNyIiIhIp6JwIyIiIp2Kwk2QPPnkk/Tq1Yvo6GhGjRrFsmXLIt2kdmPx4sVMmjSJrKwsDMNg/vz5DY6bpsldd91FZmYmMTExjB8/nk2bNkWmse3AzJkzOe6440hISKBr166cffbZbNiwocE5lZWVTJs2jdTUVOLj45k8eTK7d++OUIsj76mnnmLo0KGBicFGjx7Ne++9Fziu69W8Bx54AMMwuOGGGwL7dM3q3HPPPRiG0eAxYMCAwHFdq8bt2LGDX/3qV6SmphITE8OQIUNYvnx54Hgo/+1XuAmCV155hZtuuom7776blStXkpOTw4QJE9izZ0+km9YulJWVkZOTw5NPPtno8b/85S889thjPP3003z55ZfExcUxYcIEKisrw9zS9mHRokVMmzaNL774gg8++IDq6mp+9rOfUVZWFjjnxhtv5D//+Q+vvfYaixYtYufOnZx77rkRbHVkde/enQceeIAVK1awfPlyTjnlFM466yy+/fZbQNerOV999RX/+Mc/GDp0aIP9umYNDR48mPz8/MDj008/DRzTtTrYgQMHGDNmDFFRUbz33nusW7eOhx56iOTk5MA5If2335TDdvzxx5vTpk0LvPb5fGZWVpY5c+bMCLaqfQLMefPmBV77/X4zIyPD/Otf/xrYV1hYaLpcLvPll1+OQAvbnz179piAuWjRItM0resTFRVlvvbaa4Fz1q9fbwLm559/HqlmtjvJycnmP//5T12vZpSUlJh9+/Y1P/jgA/Pkk082r7/+etM09Tv2Y3fffbeZk5PT6DFdq8bdeuut5k9/+tMmj4f633713BymqqoqVqxYwfjx4wP7bDYb48eP5/PPP49gyzqG3Nxcdu3a1eD6JSYmMmrUKF2/GkVFRQCkpKQAsGLFCqqrqxtcswEDBtCjRw9dM8Dn8zF37lzKysoYPXq0rlczpk2bxhlnnNHg2oB+xxqzadMmsrKy6NOnD1OmTGHbtm2ArlVT3n77bUaOHMkvf/lLunbtyvDhw3n22WcDx0P9b7/CzWHat28fPp+P9PT0BvvT09PZtWtXhFrVcdReI12/xvn9fm644QbGjBnDMcccA1jXzOl0kpSU1ODcI/2arV27lvj4eFwuF1dffTXz5s1j0KBBul5NmDt3LitXrmTmzJkHHdM1a2jUqFHMnj2b//3vfzz11FPk5uZy4oknUlJSomvVhB9++IGnnnqKvn37smDBAq655hquu+46nn/+eSD0//YfcauCi3Qk06ZN45tvvmkwvi+N69+/P6tXr6aoqIjXX3+dqVOnsmjRokg3q13Ky8vj+uuv54MPPiA6OjrSzWn3Jk6cGNgeOnQoo0aNomfPnrz66qvExMREsGXtl9/vZ+TIkdx///0ADB8+nG+++Yann36aqVOnhvz71XNzmNLS0rDb7QdVxu/evZuMjIwItarjqL1Gun4Hmz59Ov/973/55JNP6N69e2B/RkYGVVVVFBYWNjj/SL9mTqeTo48+mhEjRjBz5kxycnJ49NFHdb0asWLFCvbs2cOxxx6Lw+HA4XCwaNEiHnvsMRwOB+np6bpmzUhKSqJfv35s3rxZv19NyMzMZNCgQQ32DRw4MDCcF+p/+xVuDpPT6WTEiBF89NFHgX1+v5+PPvqI0aNHR7BlHUPv3r3JyMhocP2Ki4v58ssvj9jrZ5om06dPZ968eXz88cf07t27wfERI0YQFRXV4Jpt2LCBbdu2HbHXrDF+vx+Px6Pr1YhTTz2VtWvXsnr16sBj5MiRTJkyJbCta9a00tJSvv/+ezIzM/X71YQxY8YcNIXFxo0b6dmzJxCGf/sPuyRZzLlz55oul8ucPXu2uW7dOvOqq64yk5KSzF27dkW6ae1CSUmJuWrVKnPVqlUmYP7tb38zV61aZW7dutU0TdN84IEHzKSkJPOtt94y16xZY5511llm7969zYqKigi3PDKuueYaMzEx0Vy4cKGZn58feJSXlwfOufrqq80ePXqYH3/8sbl8+XJz9OjR5ujRoyPY6si67bbbzEWLFpm5ubnmmjVrzNtuu800DMN8//33TdPU9WqJ+ndLmaauWX0333yzuXDhQjM3N9dcunSpOX78eDMtLc3cs2ePaZq6Vo1ZtmyZ6XA4zPvuu8/ctGmT+eKLL5qxsbHmCy+8EDgnlP/2K9wEyeOPP2726NHDdDqd5vHHH29+8cUXkW5Su/HJJ5+YwEGPqVOnmqZp3RJ45513munp6abL5TJPPfVUc8OGDZFtdAQ1dq0Ac9asWYFzKioqzN/+9rdmcnKyGRsba55zzjlmfn5+5BodYZdffrnZs2dP0+l0ml26dDFPPfXUQLAxTV2vlvhxuNE1q3PBBReYmZmZptPpNLt162ZecMEF5ubNmwPHda0a95///Mc85phjTJfLZQ4YMMB85plnGhwP5b/9hmma5uH3/4iIiIi0D6q5ERERkU5F4UZEREQ6FYUbERER6VQUbkRERKRTUbgRERGRTkXhRkRERDoVhRsRERHpVBRuREREpFNRuBERAQzDYP78+ZFuhogEgcKNiETcZZddhmEYBz1OP/30SDdNRDogR6QbICICcPrppzNr1qwG+1wuV4RaIyIdmXpuRKRdcLlcZGRkNHgkJycD1pDRU089xcSJE4mJiaFPnz68/vrrDd6/du1aTjnlFGJiYkhNTeWqq66itLS0wTnPPfccgwcPxuVykZmZyfTp0xsc37dvH+eccw6xsbH07duXt99+O7Q/tIiEhMKNiHQId955J5MnT+brr79mypQpXHjhhaxfvx6AsrIyJkyYQHJyMl999RWvvfYaH374YYPw8tRTTzFt2jSuuuoq1q5dy9tvv83RRx/d4Dvuvfdezj//fNasWcPPf/5zpkyZQkFBQVh/ThEJgqCsLS4ichimTp1q2u12My4ursHjvvvuM03TNAHz6quvbvCeUaNGmddcc41pmqb5zDPPmMnJyWZpaWng+DvvvGPabDZz165dpmmaZlZWlnn77bc32QbAvOOOOwKvS0tLTcB87733gvZzikh4qOZGRNqFcePG8dRTTzXYl5KSEtgePXp0g2OjR49m9erVAKxfv56cnBzi4uICx8eMGYPf72fDhg0YhsHOnTs59dRTm23D0KFDA9txcXG43W727NnT1h9JRCJE4UZE2oW4uLiDhomCJSYmpkXnRUVFNXhtGAZ+vz8UTRKREFLNjYh0CF988cVBrwcOHAjAwIED+frrrykrKwscX7p0KTabjf79+5OQkECvXr346KOPwtpmEYkM9dyISLvg8XjYtWtXg30Oh4O0tDQAXnvtNUaOHMlPf/pTXnzxRZYtW8a//vUvAKZMmcLdd9/N1KlTueeee9i7dy/XXnstl1xyCenp6QDcc889XH311XTt2pWJEydSUlLC0qVLufbaa8P7g4pIyCnciEi78L///Y/MzMwG+/r37893330HWHcyzZ07l9/+9rdkZmby8ssvM2jQIABiY2NZsGAB119/PccddxyxsbFMnjyZv/3tb4HPmjp1KpWVlTz88MPccsstpKWlcd5554XvBxSRsDFM0zQj3QgRkeYYhsG8efM4++yzI90UEekAVHMjIiIinYrCjYiIiHQqqrkRkXZPo+ci0hrquREREZFOReFGREREOhWFGxEREelUFG5ERESkU1G4ERERkU5F4UZEREQ6FYUbERER6VQUbkRERKRT+f/NySCIhdZJzwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x0_batch, x1_batch, x2_batch, x3_batch, x4_batch, \\\n",
    "            x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, \\\n",
    "            x10_batch, x11_batch, x12_batch, y_batch in dataloader:\n",
    "            \n",
    "            x0_batch, x1_batch, x2_batch, x3_batch, x4_batch, \\\n",
    "            x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, \\\n",
    "            x10_batch, x11_batch, x12_batch, y_batch = (\n",
    "                x0_batch.to(device),\n",
    "                x1_batch.to(device),\n",
    "                x2_batch.to(device),\n",
    "                x3_batch.to(device),\n",
    "                x4_batch.to(device),\n",
    "                x5_batch.to(device),\n",
    "                x6_batch.to(device),\n",
    "                x7_batch.to(device),\n",
    "                x8_batch.to(device),\n",
    "                x9_batch.to(device),\n",
    "                x10_batch.to(device),\n",
    "                x11_batch.to(device),\n",
    "                x12_batch.to(device),\n",
    "                y_batch.to(device)\n",
    "            )\n",
    "            \n",
    "            outputs = model(x0_batch, x1_batch, x2_batch, x3_batch, x4_batch, \n",
    "                             x5_batch, x6_batch, x7_batch, x8_batch, x9_batch, \n",
    "                             x10_batch, x11_batch, x12_batch)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # Compute metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    conf_matrix = confusion_matrix(all_targets, all_predictions)\n",
    "    class_report = classification_report(all_targets, all_predictions, zero_division=0)\n",
    "\n",
    "    return accuracy, conf_matrix, class_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9591280653950953\n",
      "\n",
      "Confusion Matrix:\n",
      "[[407   2   0  11   0]\n",
      " [  1  77   0   1   1]\n",
      " [  1   0  33   0   0]\n",
      " [  0   1  12 169   0]\n",
      " [  0   0   0   0  18]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       420\n",
      "           1       0.96      0.96      0.96        80\n",
      "           2       0.73      0.97      0.84        34\n",
      "           3       0.93      0.93      0.93       182\n",
      "           4       0.95      1.00      0.97        18\n",
      "\n",
      "    accuracy                           0.96       734\n",
      "   macro avg       0.91      0.97      0.94       734\n",
      "weighted avg       0.96      0.96      0.96       734\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy, conf_matrix, class_report = evaluate_model(model, test_dataloader)\n",
    "\n",
    "print(f'Validation Accuracy: {accuracy}\\n')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}\\n')\n",
    "print(f'Classification Report:\\n{class_report}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
